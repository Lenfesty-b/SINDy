{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9f365b3",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:98% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.io import loadmat\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pysindy as ps\n",
    "import pandas as pd\n",
    "from matplotlib import cm\n",
    "import time\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from statistics import mean \n",
    "from scipy.stats import ks_2samp\n",
    "import matplotlib.gridspec as gridspec\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:98% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc4978a9",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def confidenceInterval(alist, ciColumn, trials):\n",
    "    \"\"\"\n",
    "    Calculate confidence interval, mean, and standard deviation for a specified column in a list of datasets.\n",
    "    \n",
    "    Args:\n",
    "    alist (list): List of datasets.\n",
    "    ciColumn (int): Index of the column for confidence interval calculation.\n",
    "    trials (int): Not used in the function body and could be removed or repurposed.\n",
    "    \n",
    "    Returns:\n",
    "    tuple: lower and upper bounds of the confidence interval, mean, and standard deviation.\n",
    "    \"\"\"\n",
    "    mean_1 = mean_of_list(alist, ciColumn)  # Calculate mean for each point\n",
    "    std_1 = std_of_list(alist, ciColumn)  # Calculate standard deviation\n",
    "    confidence_low, confidence_high = bootstrap_confidence_interval_column(alist, ciColumn)  # Get confidence interval\n",
    "    return confidence_low, confidence_high, mean_1, std_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00858c35",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def bootstrap_confidence_interval_column(data, ciColumn, num_bootstrap_samples=1000, confidence_level=0.90):\n",
    "    \"\"\"\n",
    "    Generate bootstrap confidence intervals for a specified column across multiple datasets.\n",
    "    \n",
    "    Args:\n",
    "    data (list): List of datasets where each dataset is a list or a numpy array.\n",
    "    ciColumn (int): The index of the column for which to calculate the confidence interval.\n",
    "    num_bootstrap_samples (int): Number of bootstrap samples to generate.\n",
    "    confidence_level (float): Confidence level for the interval.\n",
    "    \n",
    "    Returns:\n",
    "    tuple: Lists of lower bounds, upper bounds of the confidence intervals.\n",
    "    \"\"\"\n",
    "    lower_bounds = []\n",
    "    upper_bounds = []\n",
    "    for dataset in data:\n",
    "        column_data = np.array(dataset)[:, ciColumn]\n",
    "        bootstrap_means = [np.mean(np.random.choice(column_data, size=len(column_data), replace=True)) for _ in range(num_bootstrap_samples)]\n",
    "        alpha = (1 - confidence_level) / 2\n",
    "        lower_bounds.append(np.percentile(bootstrap_means, 100 * alpha))\n",
    "        upper_bounds.append(np.percentile(bootstrap_means, 100 * (1 - alpha)))\n",
    "    return lower_bounds, upper_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "549ddf07",
   "metadata": {
    "code_folding": [
     0,
     17
    ]
   },
   "outputs": [],
   "source": [
    "def replace_column(matrix, new_column, snr_index, column_index):\n",
    "    \"\"\"\n",
    "    Replace a column in a matrix with a new column vector.\n",
    "    \n",
    "    Args:\n",
    "        matrix (list of lists): The original matrix.\n",
    "        new_column (list): The new column vector to replace the existing column.\n",
    "        snr_index (int): Index for the sub-list in matrix where the replacement should occur.\n",
    "        column_index (int): Index of the column to be replaced.\n",
    "    \n",
    "    Returns:\n",
    "        list of lists: The matrix with the updated column.\n",
    "    \"\"\"\n",
    "    if column_index < 0 or column_index >= len(matrix[0]):\n",
    "        raise ValueError(\"Invalid column_index\")\n",
    "    if len(new_column) != len(matrix[snr_index][column_index]):\n",
    "        raise ValueError(\"New column length must match the matrix height\")\n",
    "    for i in range(len(matrix[snr_index][column_index])):\n",
    "        matrix[snr_index][column_index][i] = new_column[i]\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7375ae54",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def flatten(data, column, column_sin):\n",
    "    \"\"\"\n",
    "    Flatten a specific column from a list of datasets. This function is intended to extract and flatten data\n",
    "    from a structured dataset where data points are organized in columns.\n",
    "    \n",
    "    Args:\n",
    "        data (list): List of datasets where each dataset is potentially a list of lists.\n",
    "        column (int): Index of the column to extract and flatten.\n",
    "        column_sin (int): Unused in this function but might be intended for future use to specify a second column.\n",
    "    \n",
    "    Returns:\n",
    "        list: A flat list of values extracted from the specified column across all datasets.\n",
    "    \"\"\"\n",
    "    flattened_data = []\n",
    "    for i in range(len(data)):\n",
    "        element = data[i][column]  # Extract the column for flattening\n",
    "        flattened_data.append(element)\n",
    "    flat_list = [item for sublist in flattened_data for item in sublist]  # Flatten the list of lists\n",
    "    return flat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3793e3db",
   "metadata": {
    "code_folding": [
     0,
     17
    ]
   },
   "outputs": [],
   "source": [
    "def normalise_decision_time(data,column_dt,column_dt_sindy,lcaddm=False):\n",
    "    \"\"\"\n",
    "    Normalize decision times in the data according to the maximum and minimum values found across all data.\n",
    "    \n",
    "    Args:\n",
    "    data (list): Data containing decision times.\n",
    "    column_dt (int): Index of the decision time column in each sub-list.\n",
    "    column_dt_sindy (int): Index of the decision time column in the SINDy model.\n",
    "    lcaddm (bool): Flag to indicate special processing condition.\n",
    "    \n",
    "    Returns:\n",
    "    list: Data with normalized decision times.\n",
    "    \"\"\"\n",
    "    model_dt_flat=flatten(data,column_dt,column_dt_sindy)\n",
    "    max_dt=max(model_dt_flat)\n",
    "    min_dt=min(model_dt_flat)\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        normalised=[]\n",
    "        normalised_sindy=[]\n",
    "        for c in range(len(data[i][column_dt])):\n",
    "            if i==4 and c==9999 and lcaddm==True:\n",
    "                norm_model_times = (mean(data[i][column_dt])- min_dt) / (max_dt - min_dt)\n",
    "                norm_model_times_sindy = (mean(data[i][column_dt_sindy]) - min_dt) / (max_dt - min_dt)\n",
    "                normalised.append(norm_model_times)\n",
    "                normalised_sindy.append(norm_model_times_sindy)\n",
    "            else:\n",
    "                norm_model_times = (data[i][column_dt][c] - min_dt) / (max_dt - min_dt)\n",
    "                norm_model_times_sindy = (data[i][column_dt_sindy][c] - min_dt) / (max_dt - min_dt)\n",
    "                normalised.append(norm_model_times)\n",
    "                normalised_sindy.append(norm_model_times_sindy)\n",
    "        #print(len(normalised))\n",
    "        data=replace_column(data, normalised, i, column_dt)\n",
    "        data=replace_column(data, normalised_sindy, i, column_dt_sindy)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da7a535c",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def cliffs_delta(x, y):\n",
    "    \"\"\"\n",
    "    Compute Cliff's Delta, a measure of effect size, comparing two samples.\n",
    "    \n",
    "    Args:\n",
    "    x (array): First sample.\n",
    "    y (array): Second sample.\n",
    "    \n",
    "    Returns:\n",
    "    float: Cliff's Delta value.\n",
    "    \"\"\"\n",
    "    all_values = np.concatenate((x, y))\n",
    "    ranks = np.argsort(all_values)\n",
    "    rx = np.mean(ranks[:len(x)])\n",
    "    ry = np.mean(ranks[len(x):])\n",
    "    delta = (rx - ry) / len(all_values)\n",
    "    return delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3fa0a2c",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def ks_statistical_analysis(data, column, column_sin, snr, no_column=False, data_sindy=None):\n",
    "    \"\"\"\n",
    "    Perform the Kolmogorov-Smirnov test and compute Cliff's Delta to assess the differences\n",
    "    between distributions in the provided datasets.\n",
    "    \n",
    "    Args:\n",
    "        data (list): A list of datasets.\n",
    "        column (int): Index of the primary column for comparison.\n",
    "        column_sin (int): Index of the secondary column for comparison.\n",
    "        snr (list): Signal-to-noise ratios or identifiers for the datasets.\n",
    "        no_column (bool): Indicates if the data lacks structured columns.\n",
    "        data_sindy (list, optional): Secondary dataset list for comparison.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: Contains D-statistics, p-values, significant points based on p-value,\n",
    "               and effect sizes (Cliff's Delta).\n",
    "    \"\"\"\n",
    "    p = np.empty(len(data))\n",
    "    d_stat = np.empty(len(data))  # KS statistic\n",
    "    effect_size = np.empty(len(data))  # cliff's d\n",
    "\n",
    "    if no_column:\n",
    "        for i in range(len(data)):\n",
    "            group1 = data[i]\n",
    "            group2 = data_sindy[i]\n",
    "            d_stat[i], p[i] = ks_2samp(group1, group2)\n",
    "            effect_size[i] = cliffs_delta(group1, group2)\n",
    "    else:\n",
    "        for i in range(len(data)):\n",
    "            group1 = data[i][column]\n",
    "            group2 = data[i][column_sin]\n",
    "            d_stat[i], p[i] = ks_2samp(group1, group2)\n",
    "            effect_size[i] = cliffs_delta(group1, group2)\n",
    "\n",
    "    significant_points = [snr[i] if p[i] < .05 else None for i in range(len(p))]\n",
    "    return d_stat, p, significant_points, effect_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0928673e",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def mean_of_list(alist, column, no_column=False):\n",
    "    \"\"\"\n",
    "    Calculate the mean of a specified column in a list of datasets, or of each dataset if no_column is True.\n",
    "    \n",
    "    Args:\n",
    "        alist (list): List of datasets, where each dataset can be a list of lists or a list of numbers.\n",
    "        column (int): Index of the column to compute the mean for.\n",
    "        no_column (bool): If True, computes the mean of the entire dataset (assumed to be flat).\n",
    "    \n",
    "    Returns:\n",
    "        list: List of means for each dataset.\n",
    "    \"\"\"\n",
    "    if no_column:\n",
    "        return [mean(dataset) for dataset in alist]\n",
    "    else:\n",
    "        return [mean(dataset[column]) for dataset in alist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a1d14dc",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def std_of_list(alist, column, no_column=False):\n",
    "    \"\"\"\n",
    "    Calculate the standard deviation of a specified column in a list of datasets, or of each dataset if no_column is True.\n",
    "    \n",
    "    Args:\n",
    "        alist (list): List of datasets.\n",
    "        column (int): Index of the column to compute the standard deviation for.\n",
    "        no_column (bool): If True, computes the standard deviation of the entire dataset (assumed to be flat).\n",
    "    \n",
    "    Returns:\n",
    "        list: List of standard deviations for each dataset.\n",
    "    \"\"\"\n",
    "    if no_column:\n",
    "        return [std(dataset) for dataset in alist]\n",
    "    else:\n",
    "        return [std(dataset[column]) for dataset in alist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e13afba",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def average_activity_multidimensional(data, trial_threshold=100):\n",
    "    # Check for NoneType values and track their locations\n",
    "    none_indices = []\n",
    "    \n",
    "    # Determine the number of populations and the maximum time length, checking for NoneType\n",
    "    num_populations = len(data[0])\n",
    "    max_length = 0\n",
    "    for sample_index, sample in enumerate(data):\n",
    "        for population_index, population in enumerate(sample):\n",
    "            if population is None:\n",
    "                none_indices.append((sample_index, population_index))\n",
    "            else:\n",
    "                max_length = max(max_length, len(population))\n",
    "\n",
    "    # Output the NoneType indices if any are found\n",
    "    if none_indices:\n",
    "        print(f\"NoneType found at indices: {none_indices}\")\n",
    "    else:\n",
    "        print(\"No NoneType found.\")\n",
    "\n",
    "    # Initialize an array to store padded data\n",
    "    padded_data = []\n",
    "    for sample in data:\n",
    "        padded_sample = [np.pad(population, (0, max_length - len(population)), 'constant', constant_values=np.nan) \n",
    "                         if population is not None else np.full(max_length, np.nan) for population in sample]\n",
    "        padded_data.append(padded_sample)\n",
    "    \n",
    "    # Convert the list of padded data to a numpy array for easy mean calculation\n",
    "    padded_data_np = np.array(padded_data)\n",
    "    average_activity = np.nanmean(padded_data_np, axis=0)\n",
    "    \n",
    "    # Calculate valid counts and determine the last valid index based on the trial threshold\n",
    "    valid_counts = np.sum(~np.isnan(padded_data_np), axis=0)\n",
    "    last_valid_indices = np.max(np.where(valid_counts >= trial_threshold, np.arange(valid_counts.shape[1]), 0), axis=1)\n",
    "    min_last_valid_index = np.min(last_valid_indices)\n",
    "    \n",
    "    # Truncate the average activity to the last valid index\n",
    "    truncated_averages = average_activity[:, :min_last_valid_index + 1]\n",
    "    \n",
    "    return truncated_averages.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0141066d",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def average_activity(data, trial_threshold=100):\n",
    "    \"\"\"\n",
    "    Calculate the average activity across data points, truncated to the last valid time point based on a minimum\n",
    "    trial threshold.\n",
    "\n",
    "    Args:\n",
    "        data (list of lists): Data containing time series or trials from multiple entities.\n",
    "        trial_threshold (int): Minimum number of trials required to consider a time point valid.\n",
    "\n",
    "    Returns:\n",
    "        list: Average activity for the data, truncated to the last valid time point where the trial count exceeds the threshold.\n",
    "    \"\"\"\n",
    "    # Find the maximum length across all data points for padding\n",
    "    max_length = max(len(item) for item in data)\n",
    "    \n",
    "    # Pad each data point with NaNs to the maximum length\n",
    "    padded_data = np.array([np.pad(item, (0, max_length - len(item)), 'constant', constant_values=np.nan) for item in data])\n",
    "    \n",
    "    # Calculate the mean, ignoring NaNs for an accurate calculation\n",
    "    average_activity = np.nanmean(padded_data, axis=0)\n",
    "    \n",
    "    # Count the number of non-NaN values at each time point\n",
    "    valid_counts = np.sum(~np.isnan(padded_data), axis=0)\n",
    "    \n",
    "    # Determine the last valid time point based on the trial threshold\n",
    "    last_valid_index = np.max(np.where(valid_counts >= trial_threshold)[0])\n",
    "    \n",
    "    # Truncate the average activity to this last valid index\n",
    "    truncated_average_activity = average_activity[:last_valid_index + 1]\n",
    "    return truncated_average_activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8713b5c9",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def rmse_coefs(model_data, model=\"DDM\"):\n",
    "    \n",
    "    if model == \"DDM\":\n",
    "        \n",
    "        drift=np.arange(0.00,.041,.001)\n",
    "        rmse=[]\n",
    "        for i in range(len(model_data)):\n",
    "            coefs=model_data[i][4]\n",
    "            rmse.append(np.sqrt(np.mean(((coefs)-drift[i])**2)))\n",
    "        return rmse\n",
    "    \n",
    "    elif model == \"LCADDM\":\n",
    "        \n",
    "        signal=np.arange(0.00,.041,.001)\n",
    "        rmse=[]\n",
    "        for i in range(len(model_data)):\n",
    "            coefs=model_data[i][4]\n",
    "            actual=[3,10,10,3,10,10]\n",
    "            actual[0]+=signal[i]\n",
    "            coef_mat=(coefs).reshape(-1)\n",
    "            rmse.append(np.sqrt(np.mean((coef_mat-actual)**2)))\n",
    "        return rmse\n",
    "        \n",
    "    elif model == \"LCA\":\n",
    "        \n",
    "        signal=np.arange(0.000, 1.21, 0.03)\n",
    "        rmse=[]\n",
    "        for i in range(len(model_data)):\n",
    "            coefs=model_data[i][4]\n",
    "            actual=[1.85,3,4,1.85,4,3]\n",
    "            actual[0]+=signal[i]\n",
    "            coef_mat=(coefs).reshape(-1)\n",
    "            rmse.append(np.sqrt(np.mean((coef_mat-actual)**2)))\n",
    "        return rmse\n",
    "    \n",
    "    elif model == \"NLB\":\n",
    "        \n",
    "        signal=np.arange(0.0000, 0.0081, 0.0002)\n",
    "        rmse=[]\n",
    "        for i in range(len(model_data)):\n",
    "            coefs=model_data[i][4]            \n",
    "            nlb_vals=np.array([signal[i],0.05,0,1,0,-1])\n",
    "            rmse.append(np.sqrt(np.mean(((coefs-nlb_vals)**2))))\n",
    "            \n",
    "        return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5ebe4d",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def rmse_coefs_poly(model_data, model=\"DDM\"):\n",
    "    \n",
    "    if model == \"DDM\":\n",
    "        \n",
    "        drift=np.arange(0.00,.041,.001)\n",
    "        rmse=[]\n",
    "        for i in range(len(model_data)):\n",
    "            if len(model_data[i][2])==2:\n",
    "                coefs=model_data[i][2]\n",
    "                rmse.append(np.sqrt(np.mean((coefs[0]-drift[i])**2+(coefs[1]-0)**2)))\n",
    "            elif len(model_data[i][2])>2:\n",
    "                coefs=model_data[i][2]\n",
    "                rmse.append(np.sqrt(np.mean((coefs[0]-drift[i])**2+(coefs[1]-0)**2+(coefs[2]-0)**2)))\n",
    "        return rmse\n",
    "    \n",
    "    elif model == \"LCADDM\":\n",
    "        \n",
    "        signal=np.arange(0.00,.041,.001)\n",
    "        rmse=[]\n",
    "        for i in range(len(model_data)):\n",
    "            \n",
    "            if len(model_data[i][2].reshape(-1))<6:\n",
    "                coefs=model_data[i][2]\n",
    "                actual=[3,3,10,10,10,10]\n",
    "                actual[0]+=signal[i]\n",
    "                coef_mat=(coefs).reshape(-1)\n",
    "                coef_mat_t=[coef_mat[0],coef_mat[1],0,0,0,0]\n",
    "                rmse.append(np.sqrt(np.mean((np.array(coef_mat_t)-np.array(actual))**2)))\n",
    "            elif len(model_data[i][2].reshape(-1))>6:\n",
    "                coefs=model_data[i][2]\n",
    "                actual=[3,10,10,0,0,0,3,10,10,0,0,0]\n",
    "                actual[0]+=signal[i]\n",
    "                coef_mat=(coefs).reshape(-1)\n",
    "                rmse.append(np.sqrt(np.mean((coef_mat-actual)**2)))\n",
    "        return rmse\n",
    "        \n",
    "    elif model == \"LCA\":\n",
    "        \n",
    "        signal=np.arange(0.000, 1.21, 0.03)\n",
    "        rmse=[]\n",
    "        for i in range(len(model_data)):\n",
    "            \n",
    "            if len(model_data[i][2].reshape(-1))<6:\n",
    "                coefs=model_data[i][2]\n",
    "                actual=[1.85,1.85,4,3,3,4]\n",
    "                actual[0]+=signal[i]\n",
    "                coef_mat=(coefs).reshape(-1)\n",
    "                coef_mat_t=[coef_mat[0],coef_mat[1],0,0,0,0]\n",
    "                rmse.append(np.sqrt(np.mean((np.array(coef_mat_t)-np.array(actual))**2)))\n",
    "            elif len(model_data[i][2].reshape(-1))>6:\n",
    "                coefs=model_data[i][2]\n",
    "                actual=[1.85,3,4,0,0,0,1.85,4,3,0,0,0]\n",
    "                actual[0]+=signal[i]\n",
    "                coef_mat=(coefs).reshape(-1)\n",
    "                rmse.append(np.sqrt(np.mean((coef_mat-actual)**2)))\n",
    "        return rmse\n",
    "    \n",
    "    elif model == \"NLB\":\n",
    "        \n",
    "        signal=np.arange(0.0000, 0.0081, 0.0002)\n",
    "        rmse=[]\n",
    "        for i in range(len(model_data)):\n",
    "            coefs=model_data[i][4]\n",
    "            if len(coefs)<6:\n",
    "                nlb_vals=np.array([signal[i],0.05,0,1,0,1])\n",
    "                coefs_t=[coefs[0],coefs[1],coefs[2],coefs[3],coefs[4],0]\n",
    "                rmse.append(np.sqrt(np.mean(((coefs_t-nlb_vals)**2))))\n",
    "            elif len(coefs)>6:\n",
    "                nlb_vals=np.array([signal[i],0.05,0,1,0,-1,0])\n",
    "                rmse.append(np.sqrt(np.mean(((coefs-nlb_vals)**2))))\n",
    "            \n",
    "        return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912a803a",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def rmse_coefs_ave(model_data, model=\"DDM\"):\n",
    "    if model == \"DDM\":\n",
    "        \n",
    "        drift=np.arange(0.00,.041,.001)\n",
    "        rmse=[]\n",
    "        for i in range(len(model_data)):\n",
    "            coefs=model_data[i][0]\n",
    "            rmse.append(np.mean(np.sqrt((np.mean(coefs)-drift[i])**2)))\n",
    "        return rmse\n",
    "        \n",
    "    elif model == \"LCADDM\":\n",
    "        \n",
    "        signal=np.arange(0.00,.041,.001)\n",
    "        rmse=[]\n",
    "        for i in range(len(model_data)):\n",
    "            coefs=model_data[i][0]\n",
    "            actual=[3,10,10,3,10,10]\n",
    "            actual[0]+=signal[i]\n",
    "            coef_mat=np.mean(coefs).reshape(-1)\n",
    "            rmse.append(np.sqrt(np.mean((coef_mat-actual)**2)))\n",
    "        return rmse\n",
    "        \n",
    "    elif model == \"LCA\":\n",
    "        \n",
    "        signal=np.arange(0.000, 1.21, 0.03)\n",
    "        rmse=[]\n",
    "        for i in range(len(model_data)):\n",
    "            coefs=model_data[i][0]\n",
    "            actual=[1.85,3,4,1.85,4,3]\n",
    "            actual[0]+=signal[i]\n",
    "            coef_mat=np.mean(coefs).reshape(-1)\n",
    "            rmse.append(np.sqrt(np.mean((coef_mat-actual)**2)))\n",
    "        return rmse\n",
    "    \n",
    "    elif model == \"NLB\":\n",
    "        \n",
    "        signal=np.arange(0.0000, 0.0081, 0.0002)\n",
    "        rmse=[]\n",
    "        for i in range(len(model_data)):\n",
    "            coefs=model_data[i][0]\n",
    "            nlb_vals=np.array([signal[i],0.05,0,1,0,-1])\n",
    "            rmse.append(np.sqrt(np.mean((np.mean(coefs,axis=0)-nlb_vals)**2)))\n",
    "        return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d510913",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def rmse_coefs_ave_poly(model_data, model=\"DDM\"):\n",
    "    \n",
    "    if model == \"DDM\":\n",
    "        \n",
    "        drift=np.arange(0.00,.041,.001)\n",
    "        rmse=[]\n",
    "        for i in range(len(model_data)):\n",
    "            coefs=np.mean(st_ddm_poly1[i][0],axis=0)\n",
    "            if len(coefs)==2:\n",
    "                rmse.append(np.sqrt(np.mean((coefs[0]-drift[i])**2+(coefs[1]-0)**2)))\n",
    "            elif len(coefs)>2:\n",
    "                rmse.append(np.sqrt(np.mean((coefs[0]-drift[i])**2+(coefs[1]-0)**2+(coefs[2]-0)**2)))\n",
    "        return rmse\n",
    "    \n",
    "    elif model == \"LCADDM\":\n",
    "        \n",
    "        signal=np.arange(0.00,.041,.001)\n",
    "        rmse=[]\n",
    "        for i in range(len(model_data)):\n",
    "            coefs=np.mean(model_data[i][0],axis=0)\n",
    "            if len(coefs.reshape(-1))<6:\n",
    "                actual=[3,3,10,10,10,10]\n",
    "                actual[0]+=signal[i]\n",
    "                coef_mat=(coefs).reshape(-1)\n",
    "                coef_mat_t=[coef_mat[0],coef_mat[1],0,0,0,0]\n",
    "                rmse.append(np.sqrt(np.mean((np.array(coef_mat_t)-np.array(actual))**2)))\n",
    "            elif len(coefs.reshape(-1))>6:\n",
    "                actual=[3,10,10,0,0,0,3,10,10,0,0,0]\n",
    "                actual[0]+=signal[i]\n",
    "                coef_mat=(coefs).reshape(-1)\n",
    "                rmse.append(np.sqrt(np.mean((coef_mat-actual)**2)))\n",
    "        return rmse\n",
    "        \n",
    "    elif model == \"LCA\":\n",
    "        \n",
    "        signal=np.arange(0.000, 1.21, 0.03)\n",
    "        rmse=[]\n",
    "        for i in range(len(model_data)):\n",
    "            coefs=np.mean(model_data[i][0],axis=0)\n",
    "            if len(coefs.reshape(-1))<6:\n",
    "                actual=[1.85,1.85,4,3,3,4]\n",
    "                actual[0]+=signal[i]\n",
    "                coef_mat=(coefs).reshape(-1)\n",
    "                coef_mat_t=[coef_mat[0],coef_mat[1],0,0,0,0]\n",
    "                rmse.append(np.sqrt(np.mean((np.array(coef_mat_t)-np.array(actual))**2)))\n",
    "            elif len(coefs.reshape(-1))>6:\n",
    "                actual=[1.85,3,4,0,0,0,1.85,4,3,0,0,0]\n",
    "                actual[0]+=signal[i]\n",
    "                coef_mat=(coefs).reshape(-1)\n",
    "                rmse.append(np.sqrt(np.mean((coef_mat-actual)**2)))\n",
    "        return rmse\n",
    "    \n",
    "    elif model == \"NLB\":\n",
    "        \n",
    "        signal=np.arange(0.0000, 0.0081, 0.0002)\n",
    "        rmse=[]\n",
    "        for i in range(len(model_data)):\n",
    "            coefs=np.mean(model_data[i][0],axis=0)\n",
    "            if len(coefs)<6:\n",
    "                nlb_vals=np.array([signal[i],0.05,0,1,0,-1])\n",
    "                coefs_t=[coefs[0],coefs[1],coefs[2],coefs[3],coefs[4],0]\n",
    "                rmse.append(np.sqrt(np.mean(((coefs_t-nlb_vals)**2))))\n",
    "            elif len(coefs)>6:\n",
    "                nlb_vals=np.array([signal[i],0.05,0,1,0,-1,0])\n",
    "                rmse.append(np.sqrt(np.mean(((coefs-nlb_vals)**2))))\n",
    "            \n",
    "        return rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45acb798",
   "metadata": {},
   "source": [
    "# Figure 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18754799",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#fig2. setup\n",
    "x_ddm=SnR_ddm\n",
    "ddm_acc=confidenceInterval(st_ddm,1,10000)\n",
    "ddm_acc=[np.array(ddm_acc[i])*100 for i in range(len(ddm_acc))]\n",
    "ddm_accsin=confidenceInterval(st_ddm,2,10000)\n",
    "ddm_accsin=[np.array(ddm_accsin[i])*100 for i in range(len(ddm_accsin))]\n",
    "c_ddm_acc,p_ddm_acc,sig_points_acc_ddm,effect_st_ddm=ks_statistical_analysis(st_ddm,1,2,x_ddm)\n",
    "\n",
    "ddm_time=confidenceInterval(st_ddm,3,10000)\n",
    "ddm_time=[np.array(ddm_time[i]) for i in range(len(ddm_time))]\n",
    "ddm_timesin=confidenceInterval(st_ddm,4,10000)\n",
    "ddm_timesin=[np.array(ddm_timesin[i]) for i in range(len(ddm_timesin))]\n",
    "c_ddm_time,p_ddm_time,sig_points_time_ddm,effect_st_ddm_t=ks_statistical_analysis(st_ddm,3,4,x_ddm)\n",
    "\n",
    "x_lcaddm=SnR_lcaddm\n",
    "lcaddm_acc=confidenceInterval(st_lcaddm,1,10000)\n",
    "lcaddm_acc=[np.array(lcaddm_acc[i])*100 for i in range(len(lcaddm_acc))]\n",
    "lcaddm_accsin=confidenceInterval(st_lcaddm,2,10000)\n",
    "lcaddm_accsin=[np.array(lcaddm_accsin[i])*100 for i in range(len(lcaddm_accsin))]\n",
    "c_lcaddm_acc,p_lcaddm_acc,sig_points_acc_lcaddm,effect_st_lcaddm=ks_statistical_analysis(st_lcaddm,1,2,x_lcaddm)\n",
    "\n",
    "lcaddm_time=confidenceInterval(st_lcaddm,3,10000)\n",
    "lcaddm_time=[np.array(lcaddm_time[i]) for i in range(len(lcaddm_time))]\n",
    "lcaddm_timesin=confidenceInterval(st_lcaddm,4,10000)\n",
    "lcaddm_timesin=[np.array(lcaddm_timesin[i]) for i in range(len(lcaddm_timesin))]\n",
    "c_lcaddm_time,p_lcaddm_time,sig_points_time_lcaddm,effect_st_lcaddm_t=ks_statistical_analysis(st_lcaddm,3,4,x_lcaddm)\n",
    "\n",
    "lcaddm_poly_acc=confidenceInterval(st_lcaddm_poly,1,10000)\n",
    "lcaddm_poly_acc=[np.array(lcaddm_poly_acc[i])*100 for i in range(len(lcaddm_poly_acc))]\n",
    "lcaddm_poly_accsin=confidenceInterval(st_lcaddm_poly,2,10000)\n",
    "lcaddm_poly_accsin=[np.array(lcaddm_poly_accsin[i])*100 for i in range(len(lcaddm_poly_accsin))]\n",
    "c_lcaddm_poly_acc,p_lcaddm_poly_acc,sig_points_acc_lcaddm_poly,effect_st_lcaddm_poly=ks_statistical_analysis(st_lcaddm_poly,1,2,x_lcaddm)\n",
    "\n",
    "lcaddm_poly_time=confidenceInterval(st_lcaddm_poly,3,10000)\n",
    "lcaddm_poly_time=[np.array(lcaddm_poly_time[i]) for i in range(len(lcaddm_poly_time))]\n",
    "lcaddm_poly_timesin=confidenceInterval(st_lcaddm_poly,4,10000)\n",
    "lcaddm_poly_timesin=[np.array(lcaddm_poly_timesin[i]) for i in range(len(lcaddm_poly_timesin))]\n",
    "c_lcaddm_poly_time,p_lcaddm_poly_time,sig_points_time_lcaddm_poly,effect_st_lcaddm_poly_t=ks_statistical_analysis(st_lcaddm_poly,3,4,x_lcaddm)\n",
    "\n",
    "x_lca=SnR_lca\n",
    "lca_acc=confidenceInterval(st_lca,1,10000)\n",
    "lca_acc=[np.array(lca_acc[i])*100 for i in range(len(lca_acc))]\n",
    "lca_accsin=confidenceInterval(st_lca,2,10000)\n",
    "lca_accsin=[np.array(lca_accsin[i])*100 for i in range(len(lca_accsin))]\n",
    "c_lca_acc,p_lca_acc,sig_points_acc_lca,effect_st_lca=ks_statistical_analysis(st_lca,1,2,x_lca)\n",
    "\n",
    "lca_time=confidenceInterval(st_lca,3,10000)\n",
    "lca_time=[np.array(lca_time[i]) for i in range(len(lca_time))]\n",
    "lca_timesin=confidenceInterval(st_lca,4,10000)\n",
    "lca_timesin=[np.array(lca_timesin[i]) for i in range(len(lca_timesin))]\n",
    "c_lca_time,p_lca_time,sig_points_time_lca,effect_st_lca_t=ks_statistical_analysis(st_lca,3,4,x_lca)\n",
    "\n",
    "x_nlb=SnR_nlb\n",
    "nlb_acc=confidenceInterval(st_nlb,1,10000)\n",
    "nlb_acc=[np.array(nlb_acc[i])*100 for i in range(len(nlb_acc))]\n",
    "nlb_accsin=confidenceInterval(st_nlb,2,10000)\n",
    "nlb_accsin=[np.array(nlb_accsin[i])*100 for i in range(len(nlb_accsin))]\n",
    "c_nlb_acc,p_nlb_acc,sig_points_acc_nlb,effect_st_nlb=ks_statistical_analysis(st_nlb,1,2,x_nlb)\n",
    "\n",
    "nlb_time=confidenceInterval(st_nlb,3,10000)\n",
    "nlb_time=[np.array(nlb_time[i]) for i in range(len(nlb_time))]\n",
    "nlb_timesin=confidenceInterval(st_nlb,4,10000)\n",
    "nlb_timesin=[np.array(nlb_timesin[i]) for i in range(len(nlb_timesin))]\n",
    "c_nlb_time,p_nlb_time,sig_points_time_nlb,effect_st_nlb_t=ks_statistical_analysis(st_nlb,3,4,x_nlb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cfdc0a",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "###fig 2 \n",
    "sns.set(font_scale=4)\n",
    "sns.set_style('white') # darkgrid, white grid, dark, white and ticks\n",
    "plt.rc('axes', titlesize=36)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=48)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=48)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=48)    # fontsize of the tick labels\n",
    "#plt.rc('legend', fontsize=16)    # legend fontsize\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.sans-serif'] = 'Arial'\n",
    "plt.rc('font', size=48)          # controls default text sizes\n",
    "# sns.set(font_scale=2)\n",
    "# Assuming st_ddm and other necessary data are already defined\n",
    "#ddm accuracy and rts\n",
    "\n",
    "\n",
    "data_sets = [{'time':np.arange(0,10000,.1),'letter':'A','label':'DDM','model':st_ddm,'x': x_ddm,'acc': ddm_acc,'accsin': ddm_accsin,'time': ddm_time,'timesin': ddm_timesin,'sig_points_acc': sig_points_acc_ddm,'sig_points_time': sig_points_time_ddm,'effect_st_acc': effect_st_ddm,'effect_st_time': effect_st_ddm_t},\n",
    "{'time':np.arange(0,10000,.01),'letter':'B','label':'LCA-DDM','model':st_lcaddm, 'x': x_lcaddm,'acc': lcaddm_acc,'accsin': lcaddm_accsin,'time': lcaddm_time,'timesin': lcaddm_timesin,'sig_points_acc': sig_points_acc_lcaddm,'sig_points_time': sig_points_time_lcaddm,'effect_st_acc': effect_st_lcaddm,'effect_st_time': effect_st_lcaddm_t,'acc_poly': lcaddm_poly_acc,'accsin_poly': lcaddm_poly_accsin,'time_poly': lcaddm_poly_time,'timesin_poly': lcaddm_poly_timesin,'sig_points_acc_poly': sig_points_acc_lcaddm_poly,'sig_points_time_poly': sig_points_time_lcaddm_poly,'effect_st_acc_poly': effect_st_lcaddm_poly,'effect_st_time_poly': effect_st_lcaddm_poly_t},\n",
    "{'time':np.arange(0,10000,.01),'letter':'C','label':'LCA','model':st_lca, 'x': x_lca,'acc': lca_acc,'accsin': lca_accsin,'time': lca_time,'timesin': lca_timesin,'sig_points_acc': sig_points_acc_lca,'sig_points_time': sig_points_time_lca,'effect_st_acc': effect_st_lca,'effect_st_time': effect_st_lca_t},\n",
    "{'time':np.arange(0,10000,.01),'letter':'D','label':'NLB','model':st_nlb, 'x': x_nlb,'acc': nlb_acc,'accsin': nlb_accsin,'time': nlb_time,'timesin': nlb_timesin,'sig_points_acc': sig_points_acc_nlb,'sig_points_time': sig_points_time_nlb,'effect_st_acc': effect_st_nlb,'effect_st_time': effect_st_nlb_t}\n",
    "]\n",
    "\n",
    "# Define your figure and gridspec\n",
    "fig = plt.figure(figsize=(35, 30))  # Adjust the figure size as needed\n",
    "gs = gridspec.GridSpec(4, 4, wspace=0.65)  # 4 rows, 4 columns, with column spans for the first plot in each row\n",
    "\n",
    "# Assuming data_sets is defined as provided\n",
    "\n",
    "for row, model_data in enumerate(data_sets ):  # Repeat data_sets twice since you have 4 rows and 2 models\n",
    "    # Accessing data for the current model\n",
    "    model_trials= model_data['model']\n",
    "    x = model_data['x']\n",
    "    acc = model_data['acc']\n",
    "    accsin = model_data['accsin']\n",
    "    time = model_data['time']\n",
    "    timesin = model_data['timesin']\n",
    "    sig_points_acc = model_data['sig_points_acc']\n",
    "    effect_st_acc = model_data['effect_st_acc']\n",
    "    sig_points_time = model_data['sig_points_time']\n",
    "    effect_st_time = model_data['effect_st_time']\n",
    "    label=model_data['label']\n",
    "    letter=model_data['letter']\n",
    "    if letter ==\"B\":\n",
    "        acc_poly = model_data['acc_poly']\n",
    "        acc_polysin = model_data['accsin_poly']\n",
    "        time_poly = model_data['time_poly']\n",
    "        timesin_poly = model_data['timesin_poly']\n",
    "        sig_points_acc_poly = model_data['sig_points_acc_poly']\n",
    "        effect_st_acc_poly = model_data['effect_st_acc_poly']\n",
    "        sig_points_time_poly = model_data['sig_points_time_poly']\n",
    "        effect_st_time_poly = model_data['effect_st_time_poly']\n",
    "    \n",
    "    \n",
    "    if len(model_trials[0][5][0])>2:\n",
    "        \n",
    "        if len(model_trials[0][5])>100:\n",
    "            a_test=np.arange(0,10000,.1)\n",
    "            # First plot: Trial Data Plot, taking double space\n",
    "            ax0 = fig.add_subplot(gs[row, :2])  # Span first two columns\n",
    "            ax0.plot(a_test[0:len(model_trials[40][5][125])],model_trials[40][5][125], color='blue', label=\"Model\", linewidth=7)\n",
    "            ax0.plot(a_test[0:len(model_trials[40][6][125])],model_trials[40][6][125], color='orange', label='SINDy', linewidth=7)\n",
    "            ax0.axhline(y=1, linestyle='dashed', linewidth=7, color='black', label='Threshold')\n",
    "            ax0.axhline(y=-1, linestyle='dashed', linewidth=7, color='black')\n",
    "            ax0.set_xlim(0)\n",
    "            ax0.set(ylabel=\"$X$\")\n",
    "            sns.despine()\n",
    "            ax0.legend(loc='best', fontsize=24)\n",
    "            ax0.spines['left'].set_linewidth(7)\n",
    "            ax0.spines['bottom'].set_linewidth(7)\n",
    "            ax0.set_title(letter, fontsize=48,fontweight='bold' )\n",
    "            ax0.title.set_position([-.1, 1.05]) \n",
    "        else:\n",
    "            a_test=np.arange(0,10000,.01)\n",
    "\n",
    "            # First plot: Trial Data Plot, taking double space\n",
    "            ax0 = fig.add_subplot(gs[row, :2])  # Span first two columns\n",
    "            ax0.plot(a_test[0:len(model_trials[40][5][2])],model_trials[40][5][2], color='blue', label=label, linewidth=7)\n",
    "            ax0.plot(a_test[0:len(model_trials[40][6][2])],model_trials[40][6][2], color='orange', label='SINDy', linewidth=7)\n",
    "            ax0.axhline(y=.75, linestyle='dashed', linewidth=7, color='black', label='Threshold')\n",
    "            ax0.axhline(y=-.75, linestyle='dashed', linewidth=7, color='black')\n",
    "            #ax0.set_ylabel('Decision variable')\n",
    "            ax0.set(ylabel=\"$X$\")\n",
    "            ax0.set_xlim(0)\n",
    "            sns.despine()\n",
    "#             ax0.legend(loc='best', fontsize=24)\n",
    "            ax0.spines['left'].set_linewidth(7)\n",
    "            ax0.spines['bottom'].set_linewidth(7)\n",
    "            ax0.set_title(letter, fontsize=48,fontweight='bold' )\n",
    "            ax0.title.set_position([-.1, 1.05]) \n",
    "    else:\n",
    "        # First plot: Trial Data Plot, taking double space\n",
    "        a_test=np.arange(0,10000,.01)\n",
    "        ax0 = fig.add_subplot(gs[row, :2])  # Span first two columns\n",
    "        ax0.plot(a_test[0:len(model_trials[40][5][0][0])],(model_trials[40][5][0][0]),color='blue', label=label,linewidth=7 )\n",
    "        ax0.plot(a_test[0:len(model_trials[40][5][0][1])],(model_trials[40][5][0][1]),color='blue', alpha=.5,linewidth=7 )\n",
    "        ax0.plot(a_test[0:len(model_trials[40][6][0][0])],(model_trials[40][6][0][0]),color='orange', label='SINDy',linewidth=7 )\n",
    "        ax0.plot(a_test[0:len(model_trials[40][6][0][1])],(model_trials[40][6][0][1]),color='orange', alpha=.5,linewidth=7 )\n",
    "        ax0.axhline(y=1, linestyle='dashed', linewidth=7, color='black',label='Threshold')\n",
    "        ax0.axvline(x=-1, linestyle='dashed', linewidth=7, color='grey',label='Error')\n",
    "        ax0.set(ylabel=\"$y_1$, $y_2$\")\n",
    "        ax0.set_xlim(0)\n",
    "        sns.despine()\n",
    "#         ax0.legend(loc='best', fontsize=24)\n",
    "        ax0.spines['left'].set_linewidth(7)\n",
    "        ax0.spines['bottom'].set_linewidth(7)\n",
    "        ax0.set_title(letter, fontsize=48,fontweight='bold' )\n",
    "        ax0.title.set_position([-.1, 1.05]) \n",
    "    \n",
    "    # Second plot: Accuracy Plot\n",
    "    ax1 = fig.add_subplot(gs[row, 2])\n",
    "    # Plotting accuracy data\n",
    "    ax1.plot(sig_points_acc, np.full(len(sig_points_acc), 40), '*', color='black')\n",
    "    ax1.plot(x, acc[2], '', color='blue', label=label,linewidth=4 )\n",
    "    ax1.plot(x, acc[0], color='blue',linewidth=3 )\n",
    "    ax1.plot(x, acc[1], color='blue',linewidth=3 )\n",
    "    ax1.fill_between(x, acc[0], acc[1], color='blue', alpha=0.25)\n",
    "    ax1.plot(x, accsin[2], '', color='orange', label=\"SINDy Model\",linewidth=4)\n",
    "    ax1.plot(x, accsin[0], color='orange',linewidth=3)\n",
    "    ax1.plot(x, accsin[1], color='orange',linewidth=3)\n",
    "    ax1.fill_between(x, accsin[0], accsin[1], color='orange', alpha=0.25)\n",
    "    if letter =='B':\n",
    "        ax1.plot(x, acc_polysin[2], '', color='gold', label=\"SINDy Model\")\n",
    "        ax1.plot(x, acc_polysin[0], color='gold')\n",
    "        ax1.plot(x, acc_polysin[1], color='gold')\n",
    "        ax1.fill_between(x, acc_polysin[0], acc_polysin[1], color='gold', alpha=0.25)\n",
    "        \n",
    "    # Add cliff's d annotations for accuracy\n",
    "#     for i, (x_val, d_value) in enumerate(zip(x, effect_st_acc)):\n",
    "#         if sig_points_acc[i] is not None:\n",
    "#             ax1.text(x_val, 45, f'd={d_value:.2f}', fontsize=4, ha='center', va='bottom', color='red')\n",
    "\n",
    "    # Third plot: Response Time Plot\n",
    "    ax2 = fig.add_subplot(gs[row, 3])\n",
    "    # Plotting response time data\n",
    "    ax2.plot(sig_points_time, np.full(len(sig_points_time), 0), '*', color='black')\n",
    "    ax2.plot(x, time[2], '', color='blue', label=\"Model Response Time\",linewidth=4)\n",
    "    ax2.plot(x, time[0], color='blue',linewidth=3)\n",
    "    ax2.plot(x, time[1], color='blue',linewidth=3)\n",
    "    ax2.fill_between(x, time[0], time[1], color='blue', alpha=0.25)\n",
    "    ax2.plot(x, timesin[2], '', color='orange', label=\"SINDy Response Time\",linewidth=4)\n",
    "    ax2.plot(x, timesin[0], color='orange',linewidth=3)\n",
    "    ax2.plot(x, timesin[1], color='orange',linewidth=3)\n",
    "    ax2.fill_between(x, timesin[0], timesin[1], color='orange', alpha=0.25)\n",
    "    if letter =='B':\n",
    "        ax2.plot(x, timesin_poly[2], '', color='gold', label=\"SINDy Response Time\")\n",
    "        ax2.plot(x, timesin_poly[0], color='gold')\n",
    "        ax2.plot(x, timesin_poly[1], color='gold')\n",
    "        ax2.fill_between(x, timesin_poly[0], timesin_poly[1], color='gold', alpha=0.25)\n",
    "    # Add cliff's d annotations for response time\n",
    "#     for i, (x_val, d_value) in enumerate(zip(x, effect_st_time)):\n",
    "#         if sig_points_time[i] is not None:\n",
    "#             ax2.text(x_val, 1, f'   d={d_value:.2f}  ', fontsize=4, ha='center', va='bottom', color='red')\n",
    "\n",
    "    # Apply styles\n",
    "    sns.despine(ax=ax1)\n",
    "    sns.despine(ax=ax2)\n",
    "    ax1.spines['left'].set_linewidth(7)\n",
    "    ax1.spines['bottom'].set_linewidth(7)\n",
    "    ax2.spines['left'].set_linewidth(7)\n",
    "    ax2.spines['bottom'].set_linewidth(7)\n",
    "    #ax1.legend(loc='best', fontsize=14)\n",
    "    #ax2.legend(loc='best', fontsize=14)\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "ax0.set_xlabel('Time (a.u.)')\n",
    "# ax1.supylabel('Choice accuracy (%)')\n",
    "# ax2.supylabel('Normalised decision time')\n",
    "fig.text(.85, .85, 'DDM', ha='center', va='center',zorder=50)\n",
    "fig.text(.86, .65, 'LCA-DDM', ha='center', va='center',zorder=50)\n",
    "fig.text(.85, .45, 'LCA', ha='center', va='center',zorder=50)\n",
    "fig.text(.85, .25, 'NLB', ha='center', va='center',zorder=50)\n",
    "\n",
    "\n",
    "fig.text(0.71, 0.525, 'Normalised decision time (a.u.)', ha='center', va='center', rotation='vertical',zorder=50)\n",
    "fig.text(0.50, 0.525, 'Choice accuracy (%)', ha='center', va='center', rotation='vertical',zorder=50)\n",
    "fig.text(.73, 0.09, 'Signal-to-noise ratio', ha='center', va='center',zorder=50)\n",
    "fig.text(0.075, 0.525, 'Decision variable', ha='center', va='center',rotation='vertical',zorder=50)\n",
    "\n",
    "# fig.supylabel('Decision variable')\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig('fig_2_single_trial_02_05.pdf', dpi=600, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd24a017",
   "metadata": {},
   "source": [
    "# Figure 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ccbd77",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#fig 3 data avg\n",
    "# Assuming ave_ddm and other necessary data are already defined\n",
    "#ddm accuracy and rts\n",
    "x_ddm=SnR_ddm\n",
    "ddm_acc=confidenceInterval(ave_ddm,1,10000)\n",
    "ddm_acc=[np.array(ddm_acc[i])*100 for i in range(len(ddm_acc))]\n",
    "ddm_accsin=confidenceInterval(ave_ddm,2,10000)\n",
    "ddm_accsin=[np.array(ddm_accsin[i])*100 for i in range(len(ddm_accsin))]\n",
    "c_ddm_acc,p_ddm_acc,sig_points_acc_ddm,effect_ave_ddm=ks_statistical_analysis(ave_ddm,1,2,x_ddm)\n",
    "\n",
    "x_ddm=SnR_ddm\n",
    "ddm_time=confidenceInterval(ave_ddm,3,10000)\n",
    "ddm_time=[np.array(ddm_time[i]) for i in range(len(ddm_time))]\n",
    "ddm_timesin=confidenceInterval(ave_ddm,4,10000)\n",
    "ddm_timesin=[np.array(ddm_timesin[i]) for i in range(len(ddm_timesin))]\n",
    "c_ddm_time,p_ddm_time,sig_points_time_ddm,effect_ave_ddm_t=ks_statistical_analysis(ave_ddm,3,4,x_ddm)\n",
    "\n",
    "x_lcaddm=SnR_lcaddm\n",
    "lcaddm_acc=confidenceInterval(ave_lcaddm,1,10000)\n",
    "lcaddm_acc=[np.array(lcaddm_acc[i])*100 for i in range(len(lcaddm_acc))]\n",
    "lcaddm_accsin=confidenceInterval(ave_lcaddm,2,10000)\n",
    "lcaddm_accsin=[np.array(lcaddm_accsin[i])*100 for i in range(len(lcaddm_accsin))]\n",
    "c_lcaddm_acc,p_lcaddm_acc,sig_points_acc_lcaddm,effect_ave_lcaddm=ks_statistical_analysis(ave_lcaddm,1,2,x_lcaddm)\n",
    "\n",
    "x_lcaddm=SnR_lcaddm\n",
    "lcaddm_time=confidenceInterval(ave_lcaddm,3,10000)\n",
    "lcaddm_time=[np.array(lcaddm_time[i]) for i in range(len(lcaddm_time))]\n",
    "lcaddm_timesin=confidenceInterval(ave_lcaddm,4,10000)\n",
    "lcaddm_timesin=[np.array(lcaddm_timesin[i]) for i in range(len(lcaddm_timesin))]\n",
    "c_lcaddm_time,p_lcaddm_time,sig_points_time_lcaddm,effect_ave_lcaddm_t=ks_statistical_analysis(ave_lcaddm,3,4,x_lcaddm)\n",
    "\n",
    "x_lca=SnR_lca\n",
    "lca_acc=confidenceInterval(ave_lca,1,10000)\n",
    "lca_acc=[np.array(lca_acc[i])*100 for i in range(len(lca_acc))]\n",
    "lca_accsin=confidenceInterval(ave_lca,2,10000)\n",
    "lca_accsin=[np.array(lca_accsin[i])*100 for i in range(len(lca_accsin))]\n",
    "c_lca_acc,p_lca_acc,sig_points_acc_lca,effect_ave_lca=ks_statistical_analysis(ave_lca,1,2,x_lca)\n",
    "\n",
    "x_lca=SnR_lca\n",
    "lca_time=confidenceInterval(ave_lca,3,10000)\n",
    "lca_time=[np.array(lca_time[i]) for i in range(len(lca_time))]\n",
    "lca_timesin=confidenceInterval(ave_lca,4,10000)\n",
    "lca_timesin=[np.array(lca_timesin[i]) for i in range(len(lca_timesin))]\n",
    "c_lca_time,p_lca_time,sig_points_time_lca,effect_ave_lca_t=ks_statistical_analysis(ave_lca,3,4,x_lca)\n",
    "\n",
    "x_nlb=SnR_nlb\n",
    "nlb_acc=confidenceInterval(ave_nlb,1,10000)\n",
    "nlb_acc=[np.array(nlb_acc[i])*100 for i in range(len(nlb_acc))]\n",
    "nlb_accsin=confidenceInterval(ave_nlb,2,10000)\n",
    "nlb_accsin=[np.array(nlb_accsin[i])*100 for i in range(len(nlb_accsin))]\n",
    "c_nlb_acc,p_nlb_acc,sig_points_acc_nlb,effect_ave_nlb=ks_statistical_analysis(ave_nlb,1,2,x_nlb)\n",
    "\n",
    "x_nlb=SnR_nlb\n",
    "nlb_time=confidenceInterval(ave_nlb,3,10000)\n",
    "nlb_time=[np.array(nlb_time[i]) for i in range(len(nlb_time))]\n",
    "nlb_timesin=confidenceInterval(ave_nlb,4,10000)\n",
    "nlb_timesin=[np.array(nlb_timesin[i]) for i in range(len(nlb_timesin))]\n",
    "c_nlb_time,p_nlb_time,sig_points_time_nlb,effect_ave_nlb_t=ks_statistical_analysis(ave_nlb,3,4,x_nlb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b52010",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#fig 3 data multi\n",
    "\n",
    "x_ddm=SnR_ddm\n",
    "ddm_acc=confidenceInterval(multi_ddm,0,10000)\n",
    "ddm_acc=[np.array(ddm_acc[i])*100 for i in range(len(ddm_acc))]\n",
    "ddm_accsin_multi=confidenceInterval(multi_ddm,2,10000)\n",
    "ddm_accsin_multi=[np.array(ddm_accsin_multi[i])*100 for i in range(len(ddm_accsin_multi))]\n",
    "c_ddm_acc,p_ddm_acc,sig_points_acc_ddm,effect_multi_acc_ddm=ks_statistical_analysis(multi_ddm,0,1,x_ddm)\n",
    "\n",
    "x_ddm=SnR_ddm\n",
    "ddm_time=confidenceInterval(multi_ddm,1,10000)\n",
    "ddm_time=[np.array(ddm_time[i]) for i in range(len(ddm_time))]\n",
    "ddm_timesin_multi=confidenceInterval(multi_ddm,3,10000)\n",
    "ddm_timesin_multi=[np.array(ddm_timesin_multi[i]) for i in range(len(ddm_timesin_multi))]\n",
    "c_ddm_time,p_ddm_time,sig_points_time_ddm,effect_multi_time_ddm=ks_statistical_analysis(multi_ddm,1,3,x_ddm)\n",
    "\n",
    "x_lcaddm=SnR_lcaddm\n",
    "lcaddm_acc=confidenceInterval(multi_lcaddm,0,10000)\n",
    "lcaddm_acc=[np.array(lcaddm_acc[i])*100 for i in range(len(lcaddm_acc))]\n",
    "lcaddm_accsin_multi=confidenceInterval(multi_lcaddm,2,10000)\n",
    "lcaddm_accsin_multi=[np.array(lcaddm_accsin_multi[i])*100 for i in range(len(lcaddm_accsin_multi))]\n",
    "c_lcaddm_acc,p_lcaddm_acc,sig_points_acc_lcaddm,effect_multi_acc_lcaddm=ks_statistical_analysis(multi_lcaddm,0,1,x_lcaddm)\n",
    "\n",
    "x_lcaddm=SnR_lcaddm\n",
    "lcaddm_time=confidenceInterval(multi_lcaddm,1,10000)\n",
    "lcaddm_time=[np.array(lcaddm_time[i]) for i in range(len(lcaddm_time))]\n",
    "lcaddm_timesin_multi=confidenceInterval(multi_lcaddm,3,10000)\n",
    "lcaddm_timesin_multi=[np.array(lcaddm_timesin_multi[i]) for i in range(len(lcaddm_timesin_multi))]\n",
    "c_lcaddm_time,p_lcaddm_time,sig_points_time_lcaddm,effect_multi_time_lcaddm=ks_statistical_analysis(multi_lcaddm,1,3,x_lcaddm)\n",
    "\n",
    "x_lca=SnR_lca\n",
    "lca_acc=confidenceInterval(multi_lca,0,10000)\n",
    "lca_acc=[np.array(lca_acc[i])*100 for i in range(len(lca_acc))]\n",
    "lca_accsin_multi=confidenceInterval(multi_lca,2,10000)\n",
    "lca_accsin_multi=[np.array(lca_accsin_multi[i])*100 for i in range(len(lca_accsin_multi))]\n",
    "c_lca_acc,p_lca_acc,sig_points_acc_lca,effect_multi_acc_lca=ks_statistical_analysis(multi_lca,0,1,x_lca)\n",
    "\n",
    "x_lca=SnR_lca\n",
    "lca_time=confidenceInterval(multi_lca,1,10000)\n",
    "lca_time=[np.array(lca_time[i]) for i in range(len(lca_time))]\n",
    "lca_timesin_multi=confidenceInterval(multi_lca,3,10000)\n",
    "lca_timesin_multi=[np.array(lca_timesin_multi[i]) for i in range(len(lca_timesin_multi))]\n",
    "c_lca_time,p_lca_time,sig_points_time_lca,effect_multi_time_lca=ks_statistical_analysis(multi_lca,1,3,x_lca)\n",
    "\n",
    "x_nlb=SnR_nlb\n",
    "nlb_acc=confidenceInterval(multi_nlb,0,10000)\n",
    "nlb_acc=[np.array(nlb_acc[i])*100 for i in range(len(nlb_acc))]\n",
    "nlb_accsin_multi=confidenceInterval(multi_nlb,2,10000)\n",
    "nlb_accsin_multi=[np.array(nlb_accsin_multi[i])*100 for i in range(len(nlb_accsin_multi))]\n",
    "c_nlb_acc,p_nlb_acc,sig_points_acc_nlb,effect_multi_time_nlb=ks_statistical_analysis(multi_nlb,0,1,x_nlb)\n",
    "\n",
    "x_nlb=SnR_nlb\n",
    "nlb_time=confidenceInterval(multi_nlb,1,10000)\n",
    "nlb_time=[np.array(nlb_time[i]) for i in range(len(nlb_time))]\n",
    "nlb_timesin_multi=confidenceInterval(multi_nlb,3,10000)\n",
    "nlb_timesin_multi=[np.array(nlb_timesin_multi[i]) for i in range(len(nlb_timesin_multi))]\n",
    "c_nlb_time,p_nlb_time,sig_points_time_nlb,effect_multi_time_nlb=ks_statistical_analysis(multi_nlb,1,3,x_nlb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2e2c93",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#fig 3#\n",
    "\n",
    "# /graph var fig3\n",
    "sns.set_style('white') # darkgrid, white grid, dark, white and ticks\n",
    "plt.rc('axes', titlesize=36)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=48)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=40)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=40)    # fontsize of the tick labels\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.sans-serif'] = 'Arial'\n",
    "#plt.rc('legend', fontsize=20)    # legend fontsize\n",
    "plt.rc('font', size=48)          # controls default text sizes\n",
    "\n",
    "data_sets = [\n",
    "{'label':'DDM','x': x_ddm,'acc': ddm_acc,'accsin': ddm_accsin,'time': ddm_time,'timesin': ddm_timesin,'sig_points_acc': sig_points_acc_ddm,'sig_points_time': sig_points_time_ddm,'effect_ave_acc': effect_ave_ddm,'effect_ave_time': effect_ave_ddm_t,'accsin_multi':ddm_accsin_multi,'timesin_multi':ddm_timesin_multi },\n",
    "{'label':'LCA-DDM', 'x': x_lcaddm,'acc': lcaddm_acc,'accsin': lcaddm_accsin,'time': lcaddm_time,'timesin': lcaddm_timesin,'sig_points_acc': sig_points_acc_lcaddm,'sig_points_time': sig_points_time_lcaddm,'effect_ave_acc': effect_ave_lcaddm,'effect_ave_time': effect_ave_lcaddm_t,'accsin_multi':lcaddm_accsin_multi,'timesin_multi':lcaddm_timesin_multi},\n",
    "{'label':'LCA', 'x': x_lca,'acc': lca_acc,'accsin': lca_accsin,'time': lca_time,'timesin': lca_timesin,'sig_points_acc': sig_points_acc_lca,'sig_points_time': sig_points_time_lca,'effect_ave_acc': effect_ave_lca,'effect_ave_time': effect_ave_lca_t,'accsin_multi':lca_accsin_multi,'timesin_multi':lca_timesin_multi},\n",
    "{'label':'NLB', 'x': x_nlb,'acc': nlb_acc,'accsin': nlb_accsin,'time': nlb_time,'timesin': nlb_timesin,'sig_points_acc': sig_points_acc_nlb,'sig_points_time': sig_points_time_nlb,'effect_ave_acc': effect_ave_nlb,'effect_ave_time': effect_ave_nlb_t,'accsin_multi':nlb_accsin_multi,'timesin_multi':nlb_timesin_multi},\n",
    "] \n",
    "\n",
    "# Define your figure and gridspec\n",
    "fig = plt.figure(figsize=(30, 25))  # Adjust the figure size as needed\n",
    "gs = gridspec.GridSpec(4, 2, wspace=0.25)  # Adjusted for 3 model groups, 2 plots (Accuracy, Response Time) each\n",
    "\n",
    "# Helper function to plot for each model group\n",
    "def plot_for_model_group(ax_acc, ax_time, model_group_data, x, label_prefix,letter):\n",
    "    i=0\n",
    "    for model_data in model_group_data:\n",
    "        \n",
    "        # Accuracy Plot\n",
    "        ax_acc.plot(model_data['sig_points_acc'], np.full(len(model_data['sig_points_acc']), 40), '*', color='black')\n",
    "        ax_acc.plot(x, model_data['acc'][2], '',  linewidth=4, color='blue', label=\"Model\")\n",
    "        ax_acc.plot(x, model_data['acc'][0],  linewidth=3, color='blue')\n",
    "        ax_acc.plot(x, model_data['acc'][1],  linewidth=3, color='blue')\n",
    "        ax_acc.fill_between(x, model_data['acc'][0], model_data['acc'][1],  linewidth=5, color='blue', alpha=0.25)\n",
    "        \n",
    "        ax_acc.plot(x, model_data['accsin'][2], '',  linewidth=4, color='orange', label=\"Trial-avg par SINDy\")\n",
    "        ax_acc.plot(x, model_data['accsin'][0],  linewidth=3, color='orange')\n",
    "        ax_acc.plot(x, model_data['accsin'][1],  linewidth=3, color='orange')\n",
    "        ax_acc.fill_between(x, model_data['accsin'][0], model_data['accsin'][1],  linewidth=5, color='orange', alpha=0.25)\n",
    "\n",
    "        ax_acc.plot(x, model_data['accsin_multi'][2], '',  linewidth=4, color='red', label=\"Multi-trial SINDy\")\n",
    "        ax_acc.plot(x, model_data['accsin_multi'][0],  linewidth=3, color='red', alpha=0.5)\n",
    "        ax_acc.plot(x, model_data['accsin_multi'][1],  linewidth=3, color='red', alpha=0.5)\n",
    "        ax_acc.fill_between(x, model_data['accsin_multi'][0], model_data['accsin_multi'][1],  linewidth=5, color='red', alpha=0.25)\n",
    "        ax_acc.set_title(letter, fontsize=48,fontweight='bold' )\n",
    "        ax_acc.title.set_position([-.15, 1.05]) \n",
    "\n",
    "        # Response Time Plot\n",
    "        ax_time.plot(model_data['sig_points_time'], np.full(len(model_data['sig_points_acc']), 0), '*', color='black')\n",
    "        ax_time.plot(x, model_data['time'][2], '',  linewidth=4, color='blue')#, label=f\"{model_data['label']} Model Time\")\n",
    "        ax_time.plot(x, model_data['time'][0],  linewidth=3, color='blue')\n",
    "        ax_time.plot(x, model_data['time'][1],  linewidth=3, color='blue')\n",
    "        ax_time.fill_between(x, model_data['time'][0], model_data['time'][1],  linewidth=5, color='blue', alpha=0.25)\n",
    "        \n",
    "        ax_time.plot(x, model_data['timesin'][2], '',  linewidth=4, color='orange', label=f\"{model_data['label']} SINDy Time\")\n",
    "        ax_time.plot(x, model_data['timesin'][0],  linewidth=3, color='orange')\n",
    "        ax_time.plot(x, model_data['timesin'][1],  linewidth=3, color='orange')\n",
    "        ax_time.fill_between(x, model_data['timesin'][0],model_data['timesin'][1],  linewidth=5, color='orange', alpha=0.25)\n",
    "        \n",
    "        ax_time.plot(x, model_data['timesin_multi'][2], '',  linewidth=4, color='red', label=f\"{model_data['label']} SINDy Time\")\n",
    "        ax_time.plot(x, model_data['timesin_multi'][0],  linewidth=3, color='red', alpha=0.5)\n",
    "        ax_time.plot(x, model_data['timesin_multi'][1],  linewidth=3, color='red', alpha=0.5)\n",
    "        ax_time.fill_between(x, model_data['timesin_multi'][0],model_data['timesin_multi'][1],  linewidth=5, color='red', alpha=0.25)\n",
    "        \n",
    "        i+=1\n",
    "    # Apply legend with label prefix to distinguish model groups\n",
    "    if label_prefix==\"DDM\":\n",
    "        ax_acc.legend( loc='best', fontsize=24)\n",
    "#     ax_time.legend(loc='best', fontsize=24)\n",
    "\n",
    "# Group data by model type\n",
    "ddm_models = [data for data in data_sets if 'DDM' in data['label'] and 'LCA' not in data['label']]\n",
    "lca_ddm_models = [data for data in data_sets if 'LCA-DDM' in data['label']]\n",
    "lca_models = [data for data in data_sets if 'LCA' in data['label'] and 'DDM' not in data['label']]\n",
    "nlb_models =[data for data in data_sets if 'NLB' in data['label']]\n",
    "\n",
    "# Plot data for each model group\n",
    "model_groups = [('DDM', ddm_models), ('LCA-DDM', lca_ddm_models), ('LCA', lca_models),('NLB',nlb_models)]\n",
    "letter=['A','B','C','D']\n",
    "for i, (label_prefix, model_group) in enumerate(model_groups):\n",
    "    ax_acc = fig.add_subplot(gs[i, 0])\n",
    "    ax_time = fig.add_subplot(gs[i, 1])\n",
    "#     print(model_group[0]['x'])\n",
    "    plot_for_model_group(ax_acc, ax_time, model_group, model_group[0]['x'], label_prefix,letter[i])\n",
    "\n",
    "    # Styling for each subplot, maintaining properties from the original code\n",
    "    for ax in [ax_acc, ax_time]:\n",
    "        sns.despine(ax=ax)\n",
    "        ax.spines['left'].set_linewidth(7)\n",
    "        ax.spines['bottom'].set_linewidth(7)\n",
    "\n",
    "\n",
    "# ax0.set_xlabel('Time (a.u.)')\n",
    "# ax1.supylabel('Choice accuracy (%)')\n",
    "# ax2.supylabel('Normalised decision time')\n",
    "fig.text(.85, .85, 'DDM', ha='center', va='center',zorder=50)\n",
    "fig.text(.85, .65, 'LCA-DDM', ha='center', va='center',zorder=50)\n",
    "fig.text(.85, .45, 'LCA', ha='center', va='center',zorder=50)\n",
    "fig.text(.85, .25, 'NLB', ha='center', va='center',zorder=50)\n",
    "fig.text(0.505, 0.525, 'Normalised decision time (a.u.)', ha='center', va='center', rotation='vertical',zorder=50)\n",
    "fig.text(0.045, 0.525, 'Choice accuracy (%)', ha='center', va='center', rotation='vertical',zorder=50)\n",
    "fig.text(0.49,0.08,'Signal-to-noise ratio', ha='center', va='center',zorder=50)\n",
    "# fig.supxlabel('Signal-tnoise ratio')        \n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"fig_average_choice_behaviour_11_10_lcaddm0_multi_ave.svg\", dpi=600,bbox_inches='tight') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8245ba",
   "metadata": {},
   "source": [
    "# Figure 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afadd330",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "##Fig 4. trial-averaged average trial activity figure\n",
    "\n",
    "\n",
    "sns.set_style('white') # darkgrid, white grid, dark, white and ticks\n",
    "plt.rc('axes', titlesize=36)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=36)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=42)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=42)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=24)    # legend fontsize\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.sans-serif'] = 'Arial'\n",
    "plt.rc('font', size=40) \n",
    "\n",
    "# Define your sample indices\n",
    "ddm_samples=[0,9,17,26]\n",
    "lcaddm_samples=[0,3,5,8]\n",
    "lca_samples=[0,2,5,7]\n",
    "nlb_samples=[0,6,12,18]\n",
    "\n",
    "samples = [ddm_samples, lcaddm_samples, lca_samples, nlb_samples]\n",
    "sample_titles=[\"Zero\",\"Low\",\"Medium\",\"High\"]\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(nrows=4, ncols=len(samples), figsize=(30, 25))\n",
    "\n",
    "# Titles for each model for clarity in the plots\n",
    "model_titles = ['DDM','LCA-DDM', 'LCA','NLB']\n",
    "\n",
    "model_axis = ['$X$','$y_1$, $y_2$', '$y_1$, $y_2$','$X_1$']\n",
    "# for model_index, model_data in enumerate([ave_ddm_nt,ave_lcaddm_nt, ave_lca_nt,ave_nt_nlb]):\n",
    "for model_index, model_data in enumerate([ave_ddm,ave_lcaddm, ave_lca,ave_nlb]):\n",
    "    for sample_index, sample in enumerate(samples[model_index]):\n",
    "        # Access the specific subplot for the current model and sample\n",
    "        ax = axs[model_index, sample_index] if len(samples[model_index]) > 1 else axs[model_index]\n",
    "        \n",
    "        # Fetch the data for this model and sample\n",
    "\n",
    "        if model_titles[model_index]=='LCA':\n",
    "            time_t=np.arange(0,10000,.01)\n",
    "            ave_act = average_activity_multidimensional(model_data[sample][5], trial_threshold=50)\n",
    "            ave_sin = average_activity_multidimensional(model_data[sample][6], trial_threshold=50)\n",
    "        elif model_titles[model_index]=='LCA-DDM':\n",
    "            time_t=np.arange(0,10000,.01)\n",
    "            ave_act = average_activity_multidimensional(model_data[sample][5], trial_threshold=24)\n",
    "            ave_sin = average_activity_multidimensional(model_data[sample][6], trial_threshold=24)\n",
    "        elif model_titles[model_index]==\"DDM\":\n",
    "            time_t=np.arange(0,10000,.1)\n",
    "            ave_act = average_activity(model_data[sample][5], trial_threshold=50)\n",
    "            ave_sin = average_activity(model_data[sample][6], trial_threshold=50)\n",
    "        elif model_titles[model_index]==\"NLB\":\n",
    "            time_t=np.arange(0,10000,.01)\n",
    "            ave_act = average_activity(model_data[sample][5], trial_threshold=10)\n",
    "            ave_sin = average_activity(model_data[sample][6], trial_threshold=10)\n",
    "        \n",
    "        # Plot the data for this model and sample\n",
    "        if model_titles[model_index]=='LCA-DDM' or model_titles[model_index]=='LCA':  # Check if data is not empty\n",
    "#             ax.plot(ave_lca_act[0], ave_lca_act[1], label='Population 1')\n",
    "              ax.plot(time_t[0:len(ave_act[0])],ave_act[0],color=\"blue\",linewidth=3, label=model_titles[model_index])\n",
    "              ax.plot(time_t[0:len(ave_act[1])],ave_act[1],color=\"blue\",alpha=.5,linewidth=5)\n",
    "              ax.plot(time_t[0:len(ave_sin[0])],ave_sin[0],color=\"orange\",linewidth=3, label='SINDy')\n",
    "              ax.plot(time_t[0:len(ave_sin[1])],ave_sin[1],color=\"orange\",alpha=.5,linewidth=5)\n",
    "\n",
    "              ax.set_ylim(-1,1)\n",
    "              ax.axhline(y=1, linestyle='dashed', linewidth=5, color='black', label='Threshold')\n",
    "#             ax.plot(ave_lca_act_sin[0], ave_lca_act_sin[1], linestyle=\"dashed\", label='Population 2')\n",
    "        else: \n",
    "            if model_titles[model_index]=='NLB':\n",
    "              ax.plot(time_t[0:len(ave_act)],ave_act,color=\"blue\",linewidth=5,label=model_titles[model_index])\n",
    "              ax.plot(time_t[0:len(ave_sin)],ave_sin,color=\"orange\",linewidth=5, label='SINDy')                    \n",
    "              ax.axhline(y=.75, linestyle='dashed', linewidth=5, color='black', label='Threshold')\n",
    "              ax.axhline(y=-.75, linestyle='dashed', linewidth=5, color='black', label='')\n",
    "              ax.set_ylim(-.85,.75)\n",
    "              #ax.set_xlim(0,2200)\n",
    "\n",
    "            else:\n",
    "#               ave_sin_threshold=np.where(ave_sin>1)\n",
    "#               ave_sin=ave_sin[0:ave_sin_threshold-1]\n",
    "              ax.plot(time_t[0:len(ave_act)],ave_act,color=\"blue\",linewidth=5,label=\"Model\")\n",
    "              ax.plot(time_t[0:len(ave_sin)],ave_sin,color=\"orange\",linewidth=5, label='SINDy')\n",
    "              ax.axhline(y=1, linestyle='dashed', linewidth=5, color='black', label='Threshold')\n",
    "              ax.axhline(y=-1, linestyle='dashed', linewidth=5, color='black', label='')\n",
    "              ax.set_ylim(-1.1,1)\n",
    "              #ax.set_xlim(0,1500)\n",
    "        \n",
    "        # Only add a legend to the first subplot for cleanliness\n",
    "        if sample_index == 0 and model_index==0:\n",
    "            ax.legend(loc='best', fontsize=30)\n",
    "\n",
    "        # Set title for the first row of subplots\n",
    "        if model_index == 0:\n",
    "            ax.set_title(f'{sample_titles[sample_index]}')\n",
    "            if sample_titles[sample_index]==\"Medium\" or sample_titles[sample_index]==\"High\" :\n",
    "                ax.set_xlim(-.85,75)\n",
    "\n",
    "        \n",
    "        # Labeling the rows with the model names\n",
    "        if sample_index == 0:\n",
    "            ax.set_ylabel(model_axis[model_index])\n",
    "            \n",
    "        sns.despine(ax=ax)\n",
    "        sns.despine(ax=ax)\n",
    "        ax.spines['left'].set_linewidth(7)\n",
    "        ax.spines['bottom'].set_linewidth(7)\n",
    "\n",
    "fig.text(.025, .95, 'A', ha='center', va='center',zorder=50,fontsize=48,fontweight='bold' )\n",
    "fig.text(.025, .71, 'B', ha='center', va='center',zorder=50,fontsize=48,fontweight='bold' )\n",
    "fig.text(.025, .48, 'C', ha='center', va='center',zorder=50,fontsize=48,fontweight='bold' )\n",
    "fig.text(.025, .255, 'D', ha='center', va='center',zorder=50,fontsize=48,fontweight='bold' )\n",
    "fig.text(.85, .81, 'DDM', ha='center', va='center',zorder=50)\n",
    "fig.text(.86, .575, 'LCA-DDM', ha='center', va='center',zorder=50)\n",
    "fig.text(.85, .35, 'LCA', ha='center', va='center',zorder=50)\n",
    "fig.text(.85, .12, 'NLB', ha='center', va='center',zorder=50)\n",
    "# Adjust layout to prevent overlap and ensure clarity\n",
    "fig.text(0.0,0.525,'Decision Varaible', ha='center', va='center',rotation='vertical',fontsize=48,zorder=50)\n",
    "fig.supxlabel('Time (a.u.)',fontsize=48,)        \n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"fig_average_activity_02_05.pdf\", dpi=600,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64093739",
   "metadata": {},
   "source": [
    "# Figure 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c96fc6",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "##Fig 5. multi-trail average trial activity figure\n",
    "\n",
    "sns.set_style('white') # darkgrid, white grid, dark, white and ticks\n",
    "plt.rc('axes', titlesize=36)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=36)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=42)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=42)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=24)    # legend fontsize\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.sans-serif'] = 'Arial'\n",
    "plt.rc('font', size=40) \n",
    "\n",
    "# Define your sample indices\n",
    "ddm_samples=[0,9,17,26]\n",
    "lcaddm_samples=[0,3,5,8]\n",
    "lca_samples=[0,2,5,7]\n",
    "nlb_samples=[0,6,12,18]\n",
    "\n",
    "samples = [ddm_samples, lcaddm_samples, lca_samples, nlb_samples]\n",
    "sample_titles=[\"Zero\",\"Low\",\"Medium\",\"High\"]\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(nrows=4, ncols=len(samples), figsize=(30, 25))\n",
    "\n",
    "# Titles for each model for clarity in the plots\n",
    "model_titles = ['DDM','LCA-DDM', 'LCA','NLB']\n",
    "\n",
    "model_axis = ['$X$','$y_1$, $y_2$', '$y_1$, $y_2$','$X_1$']\n",
    "\n",
    "\n",
    "for model_index, model_data in enumerate([ave_ddm,ave_lcaddm, ave_lca,ave_nlb]):\n",
    "    for sample_index, sample in enumerate(samples[model_index]):\n",
    "        # Access the specific subplot for the current model and sample\n",
    "        ax = axs[model_index, sample_index] if len(samples[model_index]) > 1 else axs[model_index]\n",
    "        \n",
    "        # Fetch the data for this model and sample\n",
    "\n",
    "        if model_titles[model_index]=='LCA':\n",
    "            time_t=np.arange(0,10000,.01)\n",
    "            ave_act = average_activity_multidimensional(model_data[sample][2], trial_threshold=10)\n",
    "            ave_sin = average_activity_multidimensional(model_data[sample][5], trial_threshold=10)\n",
    "        elif model_titles[model_index]=='LCA-DDM':\n",
    "            time_t=np.arange(0,10000,.01)\n",
    "            ave_act = average_activity_multidimensional(model_data[sample][2], trial_threshold=10)\n",
    "            ave_sin = average_activity_multidimensional(model_data[sample][5], trial_threshold=10)\n",
    "        elif model_titles[model_index]==\"DDM\":\n",
    "            time_t=np.arange(0,10000,.1)\n",
    "            ave_act = average_activity(model_data[sample][2], trial_threshold=10)\n",
    "            ave_sin = average_activity(model_data[sample][5], trial_threshold=10)\n",
    "        elif model_titles[model_index]==\"NLB\":\n",
    "            time_t=np.arange(0,10000,.01)\n",
    "            ave_act = average_activity(model_data[sample][0], trial_threshold=10)\n",
    "            ave_sin = average_activity(model_data[sample][1], trial_threshold=10)\n",
    "        \n",
    "        # Plot the data for this model and sample\n",
    "        if model_titles[model_index]=='LCA-DDM' or model_titles[model_index]=='LCA':  # Check if data is not empty\n",
    "#             ax.plot(ave_lca_act[0], ave_lca_act[1], label='Population 1')\n",
    "              ax.plot(time_t[0:len(ave_act[0])],ave_act[0],color=\"blue\",linewidth=3, label=model_titles[model_index])\n",
    "              ax.plot(time_t[0:len(ave_act[1])],ave_act[1],color=\"blue\",alpha=.5,linewidth=5)\n",
    "              ax.plot(time_t[0:len(ave_sin[0])],ave_sin[0],color=\"red\",linewidth=3, label='SINDy')\n",
    "              ax.plot(time_t[0:len(ave_sin[1])],ave_sin[1],color=\"red\",alpha=.5,linewidth=5)\n",
    "              if model_titles[model_index]=='LCA-DDM':\n",
    "                    ax.set_xlim(-1,1000)\n",
    "              ax.set_ylim(-1,1)\n",
    "              ax.axhline(y=1, linestyle='dashed', linewidth=5, color='black', label='Threshold')\n",
    "#             ax.plot(ave_lca_act_sin[0], ave_lca_act_sin[1], linestyle=\"dashed\", label='Population 2')\n",
    "        else: \n",
    "            if model_titles[model_index]=='NLB':\n",
    "              ax.plot(time_t[0:len(ave_act)],ave_act,color=\"blue\",linewidth=5,label=model_titles[model_index])\n",
    "              ax.plot(time_t[0:len(ave_sin)],ave_sin,color=\"red\",linewidth=5, label='SINDy')                    \n",
    "              ax.axhline(y=.75, linestyle='dashed', linewidth=5, color='black', label='Threshold')\n",
    "              ax.axhline(y=-.75, linestyle='dashed', linewidth=5, color='black', label='')\n",
    "              ax.set_ylim(-.85,.75)\n",
    "              #ax.set_xlim(0,2200)\n",
    "\n",
    "            else:\n",
    "#               ave_sin_threshold=np.where(ave_sin>1)\n",
    "#               ave_sin=ave_sin[0:ave_sin_threshold-1]\n",
    "              ax.plot(time_t[0:len(ave_act)],ave_act,color=\"blue\",linewidth=5,label=\"Model\")\n",
    "              ax.plot(time_t[0:len(ave_sin)],ave_sin,color=\"red\",linewidth=5, label='SINDy')\n",
    "              ax.axhline(y=1, linestyle='dashed', linewidth=5, color='black', label='Threshold')\n",
    "              ax.axhline(y=-1, linestyle='dashed', linewidth=5, color='black', label='')\n",
    "              ax.set_ylim(-1.1,1)\n",
    "              #ax.set_xlim(0,1500)\n",
    "        \n",
    "        # Only add a legend to the first subplot for cleanliness\n",
    "        if sample_index == 0 and model_index==0:\n",
    "            ax.legend(loc='best', fontsize=30)\n",
    "\n",
    "        # Set title for the first row of subplots\n",
    "        if model_index == 0:\n",
    "            ax.set_title(f'{sample_titles[sample_index]}')\n",
    "            if sample_titles[sample_index]==\"Medium\" or sample_titles[sample_index]==\"High\" :\n",
    "                ax.set_xlim(-.85,75)\n",
    "\n",
    "        \n",
    "        # Labeling the rows with the model names\n",
    "        if sample_index == 0:\n",
    "            ax.set_ylabel(model_axis[model_index])\n",
    "            \n",
    "        sns.despine(ax=ax)\n",
    "        sns.despine(ax=ax)\n",
    "        ax.spines['left'].set_linewidth(7)\n",
    "        ax.spines['bottom'].set_linewidth(7)\n",
    "\n",
    "fig.text(.025, .95, 'A', ha='center', va='center',zorder=50,fontsize=48,fontweight='bold' )\n",
    "fig.text(.025, .71, 'B', ha='center', va='center',zorder=50,fontsize=48,fontweight='bold' )\n",
    "fig.text(.025, .48, 'C', ha='center', va='center',zorder=50,fontsize=48,fontweight='bold' )\n",
    "fig.text(.025, .255, 'D', ha='center', va='center',zorder=50,fontsize=48,fontweight='bold' )\n",
    "fig.text(.85, .81, 'DDM', ha='center', va='center',zorder=50)\n",
    "fig.text(.86, .695, 'LCA-DDM', ha='center', va='center',zorder=50)\n",
    "fig.text(.85, .35, 'LCA', ha='center', va='center',zorder=50)\n",
    "fig.text(.85, .12, 'NLB', ha='center', va='center',zorder=50)\n",
    "# Adjust layout to prevent overlap and ensure clarity\n",
    "fig.text(0.0,0.525,'Decision Varaible', ha='center', va='center',rotation='vertical',fontsize=48,zorder=50)\n",
    "fig.text(0.5, 0.0, 'Time (a.u.)', ha='center', va='center', fontsize=48)      \n",
    "plt.tight_layout()\n",
    "plt.savefig(\"fig_average_activity_9_10.svg\", dpi=600,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422bcd3f",
   "metadata": {},
   "source": [
    "# Supplementary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa60a75",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "####supplementary figure data\n",
    "x_ddm=SnR_ddm\n",
    "x_lcaddm=SnR_lcaddm\n",
    "x_lca=SnR_lca\n",
    "x_nlb=SnR_nlb\n",
    "\n",
    "\n",
    "ddm_acc_poly=confidenceInterval(ave_ddm_poly1,1,10000)\n",
    "ddm_acc_poly=[np.array(ddm_acc_poly[i])*100 for i in range(len(ddm_acc_poly))]\n",
    "ddm_accsin_poly=confidenceInterval(ave_ddm_poly1,2,10000)\n",
    "ddm_accsin_poly=[np.array(ddm_accsin_poly[i])*100 for i in range(len(ddm_accsin_poly))]\n",
    "c_ddm_acc_poly,p_ddm_acc_poly,sig_points_acc_ddm_poly,effect_ave_ddm_poly=ks_statistical_analysis(ave_ddm_poly1,1,2,x_ddm)\n",
    "ddm_time_poly=confidenceInterval(ave_ddm_poly1,3,10000)\n",
    "ddm_time_poly=[np.array(ddm_time_poly[i]) for i in range(len(ddm_time_poly))]\n",
    "ddm_timesin_poly=confidenceInterval(ave_ddm_poly1,4,10000)\n",
    "ddm_timesin_poly=[np.array(ddm_timesin_poly[i]) for i in range(len(ddm_timesin_poly))]\n",
    "c_ddm_time_poly,p_ddm_time_poly,sig_points_time_ddm_poly,effect_ave_ddm_t_poly=ks_statistical_analysis(ave_ddm_poly1,3,4,x_ddm)\n",
    "\n",
    "ddm_acc_poly2=confidenceInterval(ave_ddm_poly2,1,10000)\n",
    "ddm_acc_poly2=[np.array(ddm_acc_poly2[i])*100 for i in range(len(ddm_acc_poly2))]\n",
    "ddm_accsin_poly2=confidenceInterval(ave_ddm_poly2,2,10000, non_binary=True)\n",
    "ddm_accsin_poly2=[np.array(ddm_accsin_poly2[i])*100 for i in range(len(ddm_accsin_poly2))]\n",
    "c_ddm_acc_poly2,p_ddm_acc_poly2,sig_points_acc_ddm_poly2,effect_ave_ddm_poly2=ks_statistical_analysis(ave_ddm_poly2,1,2,x_ddm)\n",
    "ddm_time_poly2=confidenceInterval(ave_ddm_poly2,3,10000)\n",
    "ddm_time_poly2=[np.array(ddm_time_poly2[i]) for i in range(len(ddm_time_poly2))]\n",
    "ddm_timesin_poly2=confidenceInterval(ave_ddm_poly2,4,10000, non_binary=True)\n",
    "ddm_timesin_poly2=[np.array(ddm_timesin_poly2[i]) for i in range(len(ddm_timesin_poly2))]\n",
    "c_ddm_time_poly2,p_ddm_time_poly2,sig_points_time_ddm_poly2,effect_ave_ddm_t_poly2=ks_statistical_analysis(ave_ddm_poly2,3,4,x_ddm)\n",
    "\n",
    "lcaddm_acc_poly=confidenceInterval(ave_lcaddm_poly0,1,10000)\n",
    "lcaddm_acc_poly=[np.array(lcaddm_acc_poly[i])*100 for i in range(len(lcaddm_acc_poly))]\n",
    "lcaddm_accsin_poly=confidenceInterval(ave_lcaddm_poly0,2,10000)\n",
    "lcaddm_accsin_poly=[np.array(lcaddm_accsin_poly[i])*100 for i in range(len(lcaddm_accsin_poly))]\n",
    "c_lcaddm_acc_poly,p_lcaddm_acc_poly,sig_points_acc_lcaddm_poly,effect_ave_lcaddm_poly=ks_statistical_analysis(ave_lcaddm_poly0,1,2,x_lcaddm)\n",
    "lcaddm_time_poly=confidenceInterval(ave_lcaddm_poly0,3,10000)\n",
    "lcaddm_time_poly=[np.array(lcaddm_time_poly[i]) for i in range(len(lcaddm_time_poly))]\n",
    "lcaddm_timesin_poly=confidenceInterval(ave_lcaddm_poly0,4,10000)\n",
    "lcaddm_timesin_poly=[np.array(lcaddm_timesin_poly[i]) for i in range(len(lcaddm_timesin_poly))]\n",
    "c_lcaddm_time_poly,p_lcaddm_time_poly,sig_points_time_lcaddm_poly,effect_ave_lcaddm_t_poly=ks_statistical_analysis(ave_lcaddm_poly0,3,4,x_lcaddm)\n",
    "\n",
    "lcaddm_acc_poly2=confidenceInterval(ave_lcaddm_poly2,1,10000)\n",
    "lcaddm_acc_poly2=[np.array(lcaddm_acc_poly2[i])*100 for i in range(len(lcaddm_acc_poly2))]\n",
    "lcaddm_accsin_poly2=confidenceInterval(ave_lcaddm_poly2,2,10000)\n",
    "lcaddm_accsin_poly2=[np.array(lcaddm_accsin_poly2[i])*100 for i in range(len(lcaddm_accsin_poly2))]\n",
    "c_lcaddm_acc_poly2,p_lcaddm_acc_poly2,sig_points_acc_lcaddm_poly2,effect_ave_lcaddm_poly2=ks_statistical_analysis(ave_lcaddm_poly2,1,2,x_lcaddm)\n",
    "lcaddm_time_poly2=confidenceInterval(ave_lcaddm_poly2,3,10000)\n",
    "lcaddm_time_poly2=[np.array(lcaddm_time_poly2[i]) for i in range(len(lcaddm_time_poly2))]\n",
    "lcaddm_timesin_poly2=confidenceInterval(ave_lcaddm_poly2,4,10000)\n",
    "lcaddm_timesin_poly2=[np.array(lcaddm_timesin_poly2[i]) for i in range(len(lcaddm_timesin_poly2))]\n",
    "c_lcaddm_time_poly2,p_lcaddm_time_poly2,sig_points_time_lcaddm_poly2,effect_ave_lcaddm_t_poly2=ks_statistical_analysis(ave_lcaddm_poly2,3,4,x_lcaddm)\n",
    "\n",
    "lca_acc_poly=confidenceInterval(ave_lca_poly0,1,10000)\n",
    "lca_acc_poly=[np.array(lca_acc_poly[i])*100 for i in range(len(lca_acc_poly))]\n",
    "lca_accsin_poly=confidenceInterval(ave_lca_poly0,2,10000)\n",
    "lca_accsin_poly=[np.array(lca_accsin_poly[i])*100 for i in range(len(lca_accsin_poly))]\n",
    "c_lca_acc_poly,p_lca_acc_poly,sig_points_acc_lca_poly,effect_ave_lca_poly=ks_statistical_analysis(ave_lca_poly0,1,2,x_lca)\n",
    "lca_time_poly=confidenceInterval(ave_lca_poly0,3,10000)\n",
    "lca_time_poly=[np.array(lca_time_poly[i]) for i in range(len(lca_time_poly))]\n",
    "lca_timesin_poly=confidenceInterval(ave_lca_poly0,4,10000)\n",
    "lca_timesin_poly=[np.array(lca_timesin_poly[i]) for i in range(len(lca_timesin_poly))]\n",
    "c_lca_time_poly,p_lca_time_poly,sig_points_time_lca_poly,effect_ave_lca_t_poly=ks_statistical_analysis(ave_lca_poly0,3,4,x_lca)\n",
    "\n",
    "lca_acc_poly2=confidenceInterval(ave_lca_poly2,1,10000)\n",
    "lca_acc_poly2=[np.array(lca_acc_poly2[i])*100 for i in range(len(lca_acc_poly2))]\n",
    "lca_accsin_poly2=confidenceInterval(ave_lca_poly2,2,10000)\n",
    "lca_accsin_poly2=[np.array(lca_accsin_poly2[i])*100 for i in range(len(lca_accsin_poly2))]\n",
    "c_lca_acc_poly2,p_lca_acc_poly2,sig_points_acc_lca_poly2,effect_ave_lca_poly2=ks_statistical_analysis(ave_lca_poly2,1,2,x_lca)\n",
    "lca_time_poly2=confidenceInterval(ave_lca_poly2,3,10000)\n",
    "lca_time_poly2=[np.array(lca_time_poly2[i])for i in range(len(lca_time_poly2))]\n",
    "lca_timesin_poly2=confidenceInterval(ave_lca_poly2,4,10000)\n",
    "lca_timesin_poly2=[np.array(lca_timesin_poly2[i]) for i in range(len(lca_timesin_poly2))]\n",
    "c_lca_time_poly2,p_lca_time_poly2,sig_points_time_lca_poly2,effect_ave_lca_t_poly2=ks_statistical_analysis(ave_lca_poly2,3,4,x_lca)\n",
    "\n",
    "nlb_acc_poly=confidenceInterval(ave_nlb_poly4,1,10000)\n",
    "nlb_acc_poly=[np.array(nlb_acc_poly[i])*100 for i in range(len(nlb_acc_poly))]\n",
    "nlb_accsin_poly=confidenceInterval(ave_nlb_poly4,2,10000)\n",
    "nlb_accsin_poly=[np.array(nlb_accsin_poly[i])*100 for i in range(len(nlb_accsin_poly))]\n",
    "c_nlb_acc_poly,p_nlb_acc_poly,sig_points_acc_nlb_poly,effect_ave_nlb_poly=ks_statistical_analysis(ave_nlb_poly4,1,2,x_nlb)\n",
    "nlb_time_poly=confidenceInterval(ave_nlb_poly4,3,10000)\n",
    "nlb_time_poly=[np.array(nlb_time_poly[i]) for i in range(len(nlb_time_poly))]\n",
    "nlb_timesin_poly=confidenceInterval(ave_nlb_poly4,4,10000)\n",
    "nlb_timesin_poly=[np.array(nlb_timesin_poly[i]) for i in range(len(nlb_timesin_poly))]\n",
    "c_nlb_time_poly,p_nlb_time_poly,sig_points_time_nlb_poly,effect_ave_nlb_t_poly=ks_statistical_analysis(ave_nlb_poly4,3,4,x_nlb)\n",
    "\n",
    "nlb_acc_poly6=confidenceInterval(ave_nlb_poly6,1,10000)\n",
    "nlb_acc_poly6=[np.array(nlb_acc_poly6[i])*100 for i in range(len(nlb_acc_poly6))]\n",
    "nlb_accsin_poly6=confidenceInterval(ave_nlb_poly6,2,10000, non_binary=True)\n",
    "nlb_accsin_poly6=[np.array(nlb_accsin_poly6[i])*100 for i in range(len(nlb_accsin_poly6))]\n",
    "c_nlb_acc_poly6,p_nlb_acc_poly6,sig_points_acc_nlb_poly6,effect_ave_nlb_poly6=ks_statistical_analysis(ave_nlb_poly6,1,2,x_nlb)\n",
    "nlb_time_poly6=confidenceInterval(ave_nlb_poly6,3,10000)\n",
    "nlb_time_poly6=[np.array(nlb_time_poly6[i]) for i in range(len(nlb_time_poly6))]\n",
    "nlb_timesin_poly6=confidenceInterval(ave_nlb_poly6,4,10000, non_binary=True)\n",
    "nlb_timesin_poly6=[np.array(nlb_timesin_poly6[i]) for i in range(len(nlb_timesin_poly6))]\n",
    "c_nlb_time_poly6,p_nlb_time_poly6,sig_points_time_nlb_poly6,effect_ave_nlb_t_poly6=ks_statistical_analysis(ave_nlb_poly6,3,4,x_nlb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae56634",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#fig supp1#\n",
    "data_sets1 = [\n",
    "{'label':'DDM Poly 1','x': x_ddm,'acc': ddm_acc_poly,'accsin': ddm_accsin_poly,'time': ddm_time_poly,'timesin': ddm_timesin_poly,'sig_points_acc': sig_points_acc_ddm_poly,'sig_points_time': sig_points_time_ddm_poly,'effect_ave_acc': effect_ave_ddm_poly,'effect_ave_time': effect_ave_ddm_t_poly},\n",
    "{'label':'DDM Poly 2','x': x_ddm,'acc': ddm_acc_poly2,'accsin': ddm_accsin_poly2,'time': ddm_time_poly2,'timesin': ddm_timesin_poly2,'sig_points_acc': sig_points_acc_ddm_poly2,'sig_points_time': sig_points_time_ddm_poly2,'effect_ave_acc': effect_ave_ddm_poly2,'effect_ave_time': effect_ave_ddm_t_poly2},\n",
    "{'label':'LCA-DDM Poly 0', 'x': x_lcaddm,'acc': lcaddm_acc_poly,'accsin': lcaddm_accsin_poly,'time': lcaddm_time_poly,'timesin': lcaddm_timesin_poly,'sig_points_acc': sig_points_acc_lcaddm_poly,'sig_points_time': sig_points_time_lcaddm_poly,'effect_ave_acc': effect_ave_lcaddm_poly,'effect_ave_time': effect_ave_lcaddm_t_poly},\n",
    "{'label':'LCA-DDM Poly 2 ', 'x': x_lcaddm,'acc': lcaddm_acc_poly2,'accsin': lcaddm_accsin_poly2,'time': lcaddm_time_poly2,'timesin': lcaddm_timesin_poly2,'sig_points_acc': sig_points_acc_lcaddm_poly2,'sig_points_time': sig_points_time_lcaddm_poly2,'effect_ave_acc': effect_ave_lcaddm_poly2,'effect_ave_time': effect_ave_lcaddm_t_poly2},\n",
    "{'label':'LCA Poly 0', 'x': x_lca,'acc': lca_acc_poly,'accsin': lca_accsin_poly,'time': lca_time_poly,'timesin': lca_timesin_poly,'sig_points_acc': sig_points_acc_lca_poly,'sig_points_time': sig_points_time_lca_poly,'effect_ave_acc': effect_ave_lca_poly,'effect_ave_time': effect_ave_lca_t_poly},\n",
    "{'label':'LCA Poly 0', 'x': x_lca,'acc': lca_acc_poly2,'accsin': lca_accsin_poly2,'time': lca_time_poly2,'timesin': lca_timesin_poly2,'sig_points_acc': sig_points_acc_lca_poly2,'sig_points_time': sig_points_time_lca_poly2,'effect_ave_acc': effect_ave_lca_poly2,'effect_ave_time': effect_ave_lca_t_poly2},\n",
    "{'label':'NLB Poly 4','x': x_nlb,'acc': nlb_acc_poly,'accsin': nlb_accsin_poly,'time': nlb_time_poly,'timesin': nlb_timesin_poly,'sig_points_acc': sig_points_acc_nlb_poly,'sig_points_time': sig_points_time_nlb_poly,'effect_ave_acc': effect_ave_nlb_poly,'effect_ave_time': effect_ave_nlb_t_poly},\n",
    "{'label':'NLB Poly 6','x': x_nlb,'acc': nlb_acc_poly6,'accsin': nlb_accsin_poly6,'time': nlb_time_poly6,'timesin': nlb_timesin_poly6,'sig_points_acc': sig_points_acc_nlb_poly6,'sig_points_time': sig_points_time_nlb_poly6,'effect_ave_acc': effect_ave_nlb_poly6,'effect_ave_time': effect_ave_nlb_t_poly6}]\n",
    "# Define your figure and gridspec\n",
    "fig = plt.figure(figsize=(35, 35))  # Adjust the figure size as needed\n",
    "gs = gridspec.GridSpec(8, 2, wspace=0.175,hspace=.65)  # 6 rows, 2 columns\n",
    "\n",
    "# Assuming data_sets1 is defined as provided\n",
    "for row, model_data in enumerate(data_sets1):  # Iterate over each dataset in data_sets1\n",
    "    # Accessing data for the current model\n",
    "    x = model_data['x']\n",
    "    acc = model_data['acc']\n",
    "    accsin = model_data['accsin']\n",
    "    time = model_data['time']\n",
    "    timesin = model_data['timesin']\n",
    "    sig_points_acc = model_data['sig_points_acc']\n",
    "    effect_st_acc = model_data['effect_ave_acc']\n",
    "    sig_points_time = model_data['sig_points_time']\n",
    "    effect_st_time = model_data['effect_ave_time']\n",
    "    label = model_data['label']\n",
    "\n",
    "    # Second plot: Accuracy Plot\n",
    "    ax1 = fig.add_subplot(gs[row, 0])\n",
    "    # Plotting accuracy data\n",
    "    #ax1.plot(sig_points_acc, np.full(len(sig_points_acc), 40), '*', color='black')\n",
    "    ax1.plot(x, acc[2], '', color='blue', label=\"Model\", linewidth=4)\n",
    "    ax1.plot(x, acc[0], color='blue', linewidth=3)\n",
    "    ax1.plot(x, acc[1], color='blue', linewidth=3)\n",
    "    ax1.fill_between(x, acc[0], acc[1], color='blue', alpha=0.25)\n",
    "    ax1.plot(x, accsin[2], '', color='orange', label=\"SINDy average\", linewidth=4)\n",
    "    ax1.plot(x, accsin[0], color='orange', linewidth=3)\n",
    "    ax1.plot(x, accsin[1], color='orange', linewidth=3)\n",
    "    ax1.fill_between(x, accsin[0], accsin[1], color='orange', alpha=0.25)\n",
    "\n",
    "        \n",
    "    \n",
    "    # Third plot: Response Time Plot\n",
    "    ax2 = fig.add_subplot(gs[row, 1])\n",
    "    # Plotting response time data\n",
    "    #ax2.plot(sig_points_time, np.full(len(sig_points_time), 0), '*', color='black')\n",
    "    ax2.plot(x, time[2], '', color='blue', label=\"Model Response Time\", linewidth=4)\n",
    "    ax2.plot(x, time[0], color='blue', linewidth=3)\n",
    "    ax2.plot(x, time[1], color='blue', linewidth=3)\n",
    "    ax2.fill_between(x, time[0], time[1], color='blue', alpha=0.25)\n",
    "    ax2.plot(x, timesin[2], '', color='orange', label=\"SINDy Response Time\", linewidth=4)\n",
    "    ax2.plot(x, timesin[0], color='orange', linewidth=3)\n",
    "    ax2.plot(x, timesin[1], color='orange', linewidth=3)\n",
    "    ax2.fill_between(x, timesin[0], timesin[1], color='orange', alpha=0.25)\n",
    "    if label==\"DDM Poly 2\" or label==\"NLB Poly 6\": \n",
    "        ax2.set_yscale('log')\n",
    "    \n",
    "\n",
    "    # Apply styles\n",
    "    sns.despine(ax=ax1)\n",
    "    sns.despine(ax=ax2)\n",
    "    ax1.spines['left'].set_linewidth(7)\n",
    "    ax1.spines['bottom'].set_linewidth(7)\n",
    "    ax2.spines['left'].set_linewidth(7)\n",
    "    ax2.spines['bottom'].set_linewidth(7)\n",
    "    \n",
    "    if row == 1:\n",
    "#         ax1.legend(loc='best', fontsize=14)\n",
    "        ax1.legend(loc=[0.75,.1], fontsize=26)\n",
    "\n",
    "# Add labels\n",
    "fig.text(0.5, 0.09, 'Signal-to-noise ratio', ha='center', va='center')\n",
    "fig.text(0.05, 0.5, 'Choice accuracy (%)', ha='center', va='center', rotation='vertical')\n",
    "fig.text(0.5, 0.5, 'Decision time (a.u.)', ha='center', va='center', rotation='vertical')\n",
    "\n",
    "# Add labels for the models\n",
    "fig.text(.875, .87, 'DDM Poly 1', ha='center', va='center', zorder=50)\n",
    "fig.text(.875, .78, 'DDM Poly 2 ', ha='center', va='center', zorder=50)\n",
    "fig.text(.875, .67, 'LCA-DDM Poly 1 ', ha='center', va='center', zorder=50)\n",
    "fig.text(.875, .58, 'LCA-DDM Poly 2 ', ha='center', va='center', zorder=50)\n",
    "fig.text(.875, .49, 'LCA Poly 0', ha='center', va='center', zorder=50)\n",
    "fig.text(.875, .39, 'LCA Poly 2', ha='center', va='center', zorder=50)\n",
    "fig.text(.875, .28, 'NLB Poly 4', ha='center', va='center', zorder=50)\n",
    "fig.text(.875, .19, 'NLB Poly 6', ha='center', va='center', zorder=50)\n",
    "\n",
    "fig.text(.08, .87, 'A', ha='center', va='center', zorder=50)\n",
    "fig.text(.08, .78, 'B', ha='center', va='center', zorder=50)\n",
    "fig.text(.08, .67, 'C', ha='center', va='center', zorder=50)\n",
    "fig.text(.08, .58, 'D', ha='center', va='center', zorder=50)\n",
    "fig.text(.08, .49, 'E', ha='center', va='center', zorder=50)\n",
    "fig.text(.08, .39, 'F', ha='center', va='center', zorder=50)\n",
    "fig.text(.08, .28, 'G', ha='center', va='center', zorder=50)\n",
    "fig.text(.08, .19, 'H', ha='center', va='center', zorder=50)\n",
    "\n",
    "# plt.savefig(\"fig_supp1_choice_behaviour_revised_07_10.svg\", dpi=600,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d20b2fd",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#fig s2 data \n",
    "\n",
    "ddm_acc_poly_multi=confidenceInterval(multi_ddm,0,10000)\n",
    "ddm_acc_poly_multi=[np.array(ddm_acc_poly_multi[i])*100 for i in range(len(ddm_acc_poly_multi))]\n",
    "ddm_accsin_poly_multi=confidenceInterval(multi_ddm,5,10000)\n",
    "ddm_accsin_poly_multi=[np.array(ddm_accsin_poly_multi[i])*100 for i in range(len(ddm_accsin_poly_multi))]\n",
    "c_ddm_acc_poly_m,p_ddm_acc_poly_m,sig_points_acc_ddm_poly_m,effect_multi_ddm_poly_multi=ks_statistical_analysis(multi_ddm,0,5,x_ddm)\n",
    "ddm_time_poly_multi=confidenceInterval(multi_ddm,1,10000)\n",
    "ddm_time_poly_multi=[np.array(ddm_time_poly_multi[i]) for i in range(len(ddm_time_poly_multi))]\n",
    "ddm_timesin_poly_multi=confidenceInterval(multi_ddm,6,10000)\n",
    "ddm_timesin_poly_multi=[np.array(ddm_timesin_poly_multi[i]) for i in range(len(ddm_timesin_poly_multi))]\n",
    "c_ddm_time_poly_m,p_ddm_time_poly_m,sig_points_time_ddm_poly_m,effect_multi_ddm_t_poly_multi=ks_statistical_analysis(multi_ddm,1,6,x_ddm)\n",
    "\n",
    "ddm_acc_poly2_multi=confidenceInterval(multi_ddm,0,10000)\n",
    "ddm_acc_poly2_multi=[np.array(ddm_acc_poly2_multi[i])*100 for i in range(len(ddm_acc_poly2_multi))]\n",
    "ddm_accsin_poly2_multi=confidenceInterval(multi_ddm,8,10000, non_binary=True)\n",
    "ddm_accsin_poly2_multi=[np.array(ddm_accsin_poly2_multi[i])*100 for i in range(len(ddm_accsin_poly2_multi))]\n",
    "c_ddm_acc_poly2_m,p_ddm_acc_poly2_m,sig_points_acc_ddm_poly2_m,effect_multi_ddm_poly2_multi=ks_statistical_analysis(multi_ddm,0,8,x_ddm)\n",
    "ddm_time_poly2_multi=confidenceInterval(multi_ddm,1,10000)\n",
    "ddm_time_poly2_multi=[np.array(ddm_time_poly2_multi[i]) for i in range(len(ddm_time_poly2_multi))]\n",
    "ddm_timesin_poly2_multi=confidenceInterval(multi_ddm,9,10000, non_binary=True)\n",
    "ddm_timesin_poly2_multi=[np.array(ddm_timesin_poly2_multi[i]) for i in range(len(ddm_timesin_poly2_multi))]\n",
    "c_ddm_time_poly2_m,p_ddm_time_poly2_m,sig_points_time_ddm_poly2_m,effect_multi_ddm_t_poly2_multi=ks_statistical_analysis(multi_ddm,1,9,x_ddm)\n",
    "\n",
    "lcaddm_acc_poly_multi=confidenceInterval(multi_lcaddm,0,10000)\n",
    "lcaddm_acc_poly_multi=[np.array(lcaddm_acc_poly_multi[i])*100 for i in range(len(lcaddm_acc_poly_multi))]\n",
    "lcaddm_accsin_poly_multi=confidenceInterval(multi_lcaddm,2,10000)\n",
    "lcaddm_accsin_poly_multi=[np.array(lcaddm_accsin_poly_multi[i])*100 for i in range(len(lcaddm_accsin_poly_multi))]\n",
    "c_lcaddm_acc_poly_m,p_lcaddm_acc_poly_m,sig_points_acc_lcaddm_poly_m,effect_multi_lcaddm_poly_multi=ks_statistical_analysis(multi_lcaddm,0,2,x_lcaddm)\n",
    "lcaddm_time_poly_multi=confidenceInterval(multi_lcaddm,1,10000)\n",
    "lcaddm_time_poly_multi=[np.array(lcaddm_time_poly_multi[i]) for i in range(len(lcaddm_time_poly_multi))]\n",
    "lcaddm_timesin_poly_multi=confidenceInterval(multi_lcaddm,3,10000)\n",
    "lcaddm_timesin_poly_multi=[np.array(lcaddm_timesin_poly_multi[i]) for i in range(len(lcaddm_timesin_poly_multi))]\n",
    "c_lcaddm_time_poly_m,p_lcaddm_time_poly_m,sig_points_time_lcaddm_poly_m,effect_multi_lcaddm_t_poly_multi=ks_statistical_analysis(multi_lcaddm,1,3,x_lcaddm)\n",
    "\n",
    "lcaddm_acc_poly2_multi=confidenceInterval(multi_lcaddm,0,10000)\n",
    "lcaddm_acc_poly2_multi=[np.array(lcaddm_acc_poly2_multi[i])*100 for i in range(len(lcaddm_acc_poly2_multi))]\n",
    "lcaddm_accsin_poly2_multi=confidenceInterval(multi_lcaddm,8,10000)\n",
    "lcaddm_accsin_poly2_multi=[np.array(lcaddm_accsin_poly2_multi[i])*100 for i in range(len(lcaddm_accsin_poly2_multi))]\n",
    "c_lcaddm_acc_poly2_m,p_lcaddm_acc_poly2_m,sig_points_acc_lcaddm_poly2_m,effect_multi_lcaddm_poly2_multi=ks_statistical_analysis(multi_lcaddm,0,8,x_lcaddm)\n",
    "lcaddm_time_poly2_multi=confidenceInterval(multi_lcaddm,1,10000)\n",
    "lcaddm_time_poly2_multi=[np.array(lcaddm_time_poly2_multi[i]) for i in range(len(lcaddm_time_poly2_multi))]\n",
    "lcaddm_timesin_poly2_multi=confidenceInterval(multi_lcaddm,9,10000)\n",
    "lcaddm_timesin_poly2_multi=[np.array(lcaddm_timesin_poly2_multi[i]) for i in range(len(lcaddm_timesin_poly2_multi))]\n",
    "c_lcaddm_time_poly2_m,p_lcaddm_time_poly2_m,sig_points_time_lcaddm_poly2_m,effect_multi_lcaddm_t_poly2_multi=ks_statistical_analysis(multi_lcaddm,1,9,x_lcaddm)\n",
    "\n",
    "lca_acc_poly_multi=confidenceInterval(multi_lca,0,10000)\n",
    "lca_acc_poly_multi=[np.array(lca_acc_poly_multi[i])*100 for i in range(len(lca_acc_poly_multi))]\n",
    "lca_accsin_poly_multi=confidenceInterval(multi_lca,5,10000)\n",
    "lca_accsin_poly_multi=[np.array(lca_accsin_poly_multi[i])*100 for i in range(len(lca_accsin_poly_multi))]\n",
    "c_lca_acc_poly_m,p_lca_acc_poly_m,sig_points_acc_lca_poly_m,effect_multi_lca_poly_multi=ks_statistical_analysis(multi_lca,0,5,x_lca)\n",
    "lca_time_poly_multi=confidenceInterval(multi_lca,1,10000)\n",
    "lca_time_poly_multi=[np.array(lca_time_poly_multi[i]) for i in range(len(lca_time_poly_multi))]\n",
    "lca_timesin_poly_multi=confidenceInterval(multi_lca,6,10000)\n",
    "lca_timesin_poly_multi=[np.array(lca_timesin_poly_multi[i]) for i in range(len(lca_timesin_poly_multi))]\n",
    "c_lca_time_poly_m,p_lca_time_poly_m,sig_points_time_lca_poly_m,effect_multi_lca_t_poly_multi=ks_statistical_analysis(multi_lca,1,6,x_lca)\n",
    "\n",
    "lca_acc_poly2_multi=confidenceInterval(multi_lca,0,10000)\n",
    "lca_acc_poly2_multi=[np.array(lca_acc_poly2_multi[i])*100 for i in range(len(lca_acc_poly2_multi))]\n",
    "lca_accsin_poly2_multi=confidenceInterval(multi_lca,8,10000)\n",
    "lca_accsin_poly2_multi=[np.array(lca_accsin_poly2_multi[i])*100 for i in range(len(lca_accsin_poly2_multi))]\n",
    "c_lca_acc_poly2_m,p_lca_acc_poly2_m,sig_points_acc_lca_poly2_m,effect_multi_lca_poly2_multi=ks_statistical_analysis(multi_lca,0,8,x_lca)\n",
    "lca_time_poly2_multi=confidenceInterval(multi_lca,1,10000)\n",
    "lca_time_poly2_multi=[np.array(lca_time_poly2_multi[i]) for i in range(len(lca_time_poly2_multi))]\n",
    "lca_timesin_poly2_multi=confidenceInterval(multi_lca,9,10000)\n",
    "lca_timesin_poly2_multi=[np.array(lca_timesin_poly2_multi[i]) for i in range(len(lca_timesin_poly2_multi))]\n",
    "c_lca_time_poly2_m,p_lca_time_poly2_m,sig_points_time_lca_poly2_m,effect_multi_lca_t_poly2_multi=ks_statistical_analysis(multi_lca,1,9,x_lca)\n",
    "\n",
    "nlb_acc_poly_multi=confidenceInterval(multi_nlb_poly4,0,10000)\n",
    "nlb_acc_poly_multi=[np.array(nlb_acc_poly_multi[i])*100 for i in range(len(nlb_acc_poly_multi))]\n",
    "nlb_accsin_poly_multi=confidenceInterval(multi_nlb_poly4,2,10000)\n",
    "nlb_accsin_poly_multi=[np.array(nlb_accsin_poly_multi[i])*100 for i in range(len(nlb_accsin_poly_multi))]\n",
    "c_nlb_acc_poly_m,p_nlb_acc_poly_m,sig_points_acc_nlb_poly_m,effect_multi_nlb_poly_multi=ks_statistical_analysis(multi_nlb_poly4,0,2,x_nlb)\n",
    "nlb_time_poly_multi=confidenceInterval(multi_nlb_poly4,1,10000)\n",
    "nlb_time_poly_multi=[np.array(nlb_time_poly_multi[i]) for i in range(len(nlb_time_poly_multi))]\n",
    "nlb_timesin_poly_multi=confidenceInterval(multi_nlb_poly4,3,10000)\n",
    "nlb_timesin_poly_multi=[np.array(nlb_timesin_poly_multi[i]) for i in range(len(nlb_timesin_poly_multi))]\n",
    "c_nlb_time_poly_m,p_nlb_time_poly_m,sig_points_time_nlb_poly_m,effect_multi_nlb_t_poly_multi=ks_statistical_analysis(multi_nlb_poly4,1,3,x_nlb)\n",
    "\n",
    "nlb_acc_poly6_multi=confidenceInterval(multi_nlb_poly6,0,10000)\n",
    "nlb_acc_poly6_multi=[np.array(nlb_acc_poly6_multi[i])*100 for i in range(len(nlb_acc_poly6_multi))]\n",
    "nlb_accsin_poly6_multi=confidenceInterval(multi_nlb_poly6,2,10000)\n",
    "nlb_accsin_poly6_multi=[np.array(nlb_accsin_poly6_multi[i])*100 for i in range(len(nlb_accsin_poly6_multi))]\n",
    "c_nlb_acc_poly6_m,p_nlb_acc_poly6_m,sig_points_acc_nlb_poly6_m,effect_multi_nlb_poly6_multi=ks_statistical_analysis(multi_nlb_poly6,0,2,x_nlb)\n",
    "nlb_time_poly6_multi=confidenceInterval(multi_nlb_poly6,1,10000)\n",
    "nlb_time_poly6_multi=[np.array(nlb_time_poly6_multi[i]) for i in range(len(nlb_time_poly6_multi))]\n",
    "nlb_timesin_poly6_multi=confidenceInterval(multi_nlb_poly6,3,10000)\n",
    "nlb_timesin_poly6_multi=[np.array(nlb_timesin_poly6_multi[i]) for i in range(len(nlb_timesin_poly6_multi))]\n",
    "c_nlb_time_poly6_m,p_nlb_time_poly6_m,sig_points_time_nlb_poly6_m,effect_multi_nlb_t_poly6_multi=ks_statistical_analysis(multi_nlb_poly6,1,3,x_nlb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f8c391",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#fig s2#\n",
    "data_sets1 = [\n",
    "{'label':'Multi-DDM Poly 1','x': x_ddm,'acc': ddm_acc_poly_multi,'accsin': ddm_accsin_poly_multi,'time': ddm_time_poly_multi,'timesin': ddm_timesin_poly_multi,'sig_points_acc': sig_points_acc_ddm_poly_m,'sig_points_time': sig_points_time_ddm_poly_m,'effect_ave_acc': effect_multi_ddm_poly_multi,'effect_ave_time': effect_multi_ddm_t_poly_multi},\n",
    "{'label':'Multi-DDM Poly 2','x': x_ddm,'acc': ddm_acc_poly2_multi,'accsin': ddm_accsin_poly2_multi,'time': ddm_time_poly2_multi,'timesin': ddm_timesin_poly2_multi,'sig_points_acc': sig_points_acc_ddm_poly2_m,'sig_points_time': sig_points_time_ddm_poly2_m,'effect_ave_acc': effect_multi_ddm_poly2_multi,'effect_ave_time': effect_multi_ddm_t_poly2_multi},\n",
    "{'label':'Multi-LCA-DDM Poly 0', 'x': x_lcaddm,'acc': lcaddm_acc_poly_multi,'accsin': lcaddm_accsin_poly_multi,'time': lcaddm_time_poly_multi,'timesin': lcaddm_timesin_poly_multi,'sig_points_acc': sig_points_acc_lcaddm_poly_m,'sig_points_time': sig_points_time_lcaddm_poly_m,'effect_ave_acc': effect_multi_lcaddm_poly_multi,'effect_ave_time': effect_multi_lcaddm_t_poly_multi},\n",
    "{'label':'Multi-LCA-DDM Poly 2 ', 'x': x_lcaddm,'acc': lcaddm_acc_poly2_multi,'accsin': lcaddm_accsin_poly2_multi,'time': lcaddm_time_poly2_multi,'timesin': lcaddm_timesin_poly2_multi,'sig_points_acc': sig_points_acc_lcaddm_poly2_m,'sig_points_time': sig_points_time_lcaddm_poly2_m,'effect_ave_acc': effect_multi_lcaddm_poly2_multi,'effect_ave_time': effect_multi_lcaddm_t_poly2_multi},\n",
    "{'label':'Multi-LCA Poly 0', 'x': x_lca,'acc': lca_acc_poly_multi,'accsin': lca_accsin_poly_multi,'time': lca_time_poly_multi,'timesin': lca_timesin_poly_multi,'sig_points_acc': sig_points_acc_lca_poly_m,'sig_points_time': sig_points_time_lca_poly_m,'effect_ave_acc': effect_multi_lca_poly_multi,'effect_ave_time': effect_multi_lca_t_poly_multi},\n",
    "{'label':'Multi-LCA Poly 0', 'x': x_lca,'acc': lca_acc_poly2_multi,'accsin': lca_accsin_poly2_multi,'time': lca_time_poly2_multi,'timesin': lca_timesin_poly2_multi,'sig_points_acc': sig_points_acc_lca_poly2_m,'sig_points_time': sig_points_time_lca_poly2_m,'effect_ave_acc': effect_multi_lca_poly2_multi,'effect_ave_time': effect_multi_lca_t_poly2_multi},\n",
    "{'label':'Multi-NLB Poly 4','x': x_nlb,'acc': nlb_acc_poly_multi,'accsin': nlb_accsin_poly_multi,'time': nlb_time_poly_multi,'timesin': nlb_timesin_poly_multi,'sig_points_acc': sig_points_acc_nlb_poly_m,'sig_points_time': sig_points_time_nlb_poly_m,'effect_ave_acc': effect_multi_nlb_poly_multi,'effect_ave_time': effect_multi_nlb_t_poly_multi},\n",
    "{'label':'Multi-NLB Poly 6','x': x_nlb,'acc': nlb_acc_poly6_multi,'accsin': nlb_accsin_poly6_multi,'time': nlb_time_poly6_multi,'timesin': nlb_timesin_poly6_multi,'sig_points_acc': sig_points_acc_nlb_poly6_m,'sig_points_time': sig_points_time_nlb_poly6_m,'effect_ave_acc': effect_multi_nlb_poly6_multi,'effect_ave_time': effect_multi_nlb_t_poly6_multi}] \n",
    "# Define your figure and gridspec\n",
    "fig = plt.figure(figsize=(35, 35))  # Adjust the figure size as needed\n",
    "gs = gridspec.GridSpec(8, 2, wspace=0.175,hspace=.65)  # 6 rows, 2 columns\n",
    "\n",
    "# Assuming data_sets1 is defined as provided\n",
    "for row, model_data in enumerate(data_sets1):  # Iterate over each dataset in data_sets1\n",
    "    # Accessing data for the current model\n",
    "    x = model_data['x']\n",
    "    acc = model_data['acc']\n",
    "    accsin = model_data['accsin']\n",
    "    time = model_data['time']\n",
    "    timesin = model_data['timesin']\n",
    "    sig_points_acc = model_data['sig_points_acc']\n",
    "    effect_st_acc = model_data['effect_ave_acc']\n",
    "    sig_points_time = model_data['sig_points_time']\n",
    "    effect_st_time = model_data['effect_ave_time']\n",
    "    label = model_data['label']\n",
    "\n",
    "    # Second plot: Accuracy Plot\n",
    "    ax1 = fig.add_subplot(gs[row, 0])\n",
    "    # Plotting accuracy data\n",
    "    #ax1.plot(sig_points_acc, np.full(len(sig_points_acc), 40), '*', color='black')\n",
    "    ax1.plot(x, acc[2], '', color='blue', label=\"Model\", linewidth=4)\n",
    "    ax1.plot(x, acc[0], color='blue', linewidth=3)\n",
    "    ax1.plot(x, acc[1], color='blue', linewidth=3)\n",
    "    ax1.fill_between(x, acc[0], acc[1], color='blue', alpha=0.25)\n",
    "    ax1.plot(x, accsin[2], '', color='red',label=\"SINDy multi-trial\" , linewidth=4)\n",
    "    ax1.plot(x, accsin[0], color='red', linewidth=3)\n",
    "    ax1.plot(x, accsin[1], color='red', linewidth=3)\n",
    "    ax1.fill_between(x, accsin[0], accsin[1], color='red', alpha=0.25)\n",
    "\n",
    "    \n",
    "    # Third plot: Response Time Plot\n",
    "    ax2 = fig.add_subplot(gs[row, 1])\n",
    "    # Plotting response time data\n",
    "    #ax2.plot(sig_points_time, np.full(len(sig_points_time), 0), '*', color='black')\n",
    "    ax2.plot(x, time[2], '', color='blue', label=\"Model Response Time\", linewidth=4)\n",
    "    ax2.plot(x, time[0], color='blue', linewidth=3)\n",
    "    ax2.plot(x, time[1], color='blue', linewidth=3)\n",
    "    ax2.fill_between(x, time[0], time[1], color='blue', alpha=0.25)\n",
    "    ax2.plot(x, timesin[2], '', color='red', label=\"SINDy Response Time\", linewidth=4)\n",
    "    ax2.plot(x, timesin[0], color='red', linewidth=3)\n",
    "    ax2.plot(x, timesin[1], color='red', linewidth=3)\n",
    "    ax2.fill_between(x, timesin[0], timesin[1], color='red', alpha=0.25)\n",
    "\n",
    "    if label==\"DDM Poly 2\" or label==\"NLB Poly 6\": \n",
    "        ax2.set_yscale('log')\n",
    "    \n",
    "\n",
    "    # Apply styles\n",
    "    sns.despine(ax=ax1)\n",
    "    sns.despine(ax=ax2)\n",
    "    ax1.spines['left'].set_linewidth(7)\n",
    "    ax1.spines['bottom'].set_linewidth(7)\n",
    "    ax2.spines['left'].set_linewidth(7)\n",
    "    ax2.spines['bottom'].set_linewidth(7)\n",
    "    \n",
    "    if row == 1:\n",
    "#         ax1.legend(loc='best', fontsize=14)\n",
    "        ax1.legend(loc=[0.025,.8], fontsize=26)\n",
    "\n",
    "# Add labels\n",
    "fig.text(0.5, 0.09, 'Signal-to-noise ratio', ha='center', va='center')\n",
    "fig.text(0.05, 0.5, 'Choice accuracy (%)', ha='center', va='center', rotation='vertical')\n",
    "fig.text(0.5, 0.5, 'Decision time (a.u.)', ha='center', va='center', rotation='vertical')\n",
    "\n",
    "# Add labels for the models\n",
    "fig.text(.875, .87, 'DDM Poly 1', ha='center', va='center', zorder=50)\n",
    "fig.text(.875, .78, 'DDM Poly 2 ', ha='center', va='center', zorder=50)\n",
    "fig.text(.875, .67, 'LCA-DDM Poly 1 ', ha='center', va='center', zorder=50)\n",
    "fig.text(.875, .58, 'LCA-DDM Poly 2 ', ha='center', va='center', zorder=50)\n",
    "fig.text(.875, .49, 'LCA Poly 0', ha='center', va='center', zorder=50)\n",
    "fig.text(.875, .39, 'LCA Poly 2', ha='center', va='center', zorder=50)\n",
    "fig.text(.875, .28, 'NLB Poly 4', ha='center', va='center', zorder=50)\n",
    "fig.text(.875, .19, 'NLB Poly 6', ha='center', va='center', zorder=50)\n",
    "\n",
    "fig.text(.08, .87, 'A', ha='center', va='center', zorder=50)\n",
    "fig.text(.08, .78, 'B', ha='center', va='center', zorder=50)\n",
    "fig.text(.08, .67, 'C', ha='center', va='center', zorder=50)\n",
    "fig.text(.08, .58, 'D', ha='center', va='center', zorder=50)\n",
    "fig.text(.08, .49, 'E', ha='center', va='center', zorder=50)\n",
    "fig.text(.08, .39, 'F', ha='center', va='center', zorder=50)\n",
    "fig.text(.08, .28, 'G', ha='center', va='center', zorder=50)\n",
    "fig.text(.08, .19, 'H', ha='center', va='center', zorder=50)\n",
    "# plt.savefig(\"fig_supp2_choice_behaviour_revised_07_10.svg\", dpi=600,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a26a345",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "####test out rmse plot for ebst and rest####\n",
    "# /graph var fig3\n",
    "sns.set_style('white') # darkgrid, white grid, dark, white and ticks\n",
    "plt.rc('axes', titlesize=36)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=48)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=36)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=36)    # fontsize of the tick labels\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.sans-serif'] = 'Arial'\n",
    "#plt.rc('legend', fontsize=20)    # legend fontsize\n",
    "plt.rc('font', size=48)   \n",
    "# Prepare data and labels for each plot\n",
    "models = [\"DDM\", \"LCADDM\", \"LCA\", \"NLB\"]  # Add \"FourthModel\" when you have data for it\n",
    "\n",
    "multi_data = [multi_ddm, multi_lcaddm, multi_lca, multi_nlb]  # Add multi_fourth when available\n",
    "st_data = [st_ddm, st_lcaddm, st_lca, st_nlb]  # Add st_fourth when available\n",
    "\n",
    "# Polynomial order fits data for both multi-trial and average\n",
    "multi_ddm_poly1=[multi_ddm[i][5:8] for i in range(41)]\n",
    "multi_lcaddm_poly1=[multi_lcaddm[i][5:8] for i in range(41)]\n",
    "multi_lca_poly1=[multi_lca[i][5:8] for i in range(41)]\n",
    "\n",
    "multi_data_poly1 = [multi_ddm_poly1, multi_lcaddm_poly1, multi_lca_poly1, multi_nlb_poly4]\n",
    "st_data_poly1 = [st_ddm_poly1, st_lcaddm_poly1, st_lca_poly1, st_nlb_poly1]\n",
    "\n",
    "multi_ddm_poly2=[multi_ddm[i][8:11] for i in range(41)]\n",
    "multi_lcaddm_poly2=[multi_lcaddm[i][8:11] for i in range(41)]\n",
    "multi_lca_poly2=[multi_lca[i][8:11] for i in range(41)]\n",
    "\n",
    "multi_data_poly2 = [multi_ddm_poly2, multi_lcaddm_poly2, multi_lca_poly2, multi_nlb_poly6]\n",
    "st_data_poly2 = [st_ddm_poly2, st_lcaddm_poly2, st_lca_poly2, st_nlb_poly2]\n",
    "\n",
    "x_data = [SnR_ddm, SnR_lcaddm, SnR_lca, SnR_nlb]  # Signal-to-noise ratio\n",
    "y_limits = [\n",
    "    [-0.02, .1],  # Limits for DDM (first row)\n",
    "    [8, 9.5],  # Limits for LCADDM (second row)\n",
    "    [2.5, 9],  # Limits for LCA (third row)\n",
    "    [-0.5, 10],  # Limits for NLB (fourth row)\n",
    "]\n",
    "# Number of plots\n",
    "n_plots = len(models)  # 4 rows, one per model\n",
    "\n",
    "# Create subplots with 4 rows and 3 columns (4 models, each with 3 comparisons)\n",
    "fig, axs = plt.subplots(n_plots, 3, figsize=(30, 25))  # 4 rows, 3 columns\n",
    "\n",
    "# Ensure axs is a 2D array even if there's only one subplot per row\n",
    "axs = axs.reshape(n_plots, 3)\n",
    "\n",
    "# Plot each model\n",
    "for i in range(n_plots):\n",
    "    # RMSE for multi-trial and average\n",
    "    rmse_multi = rmse_coefs(multi_data[i], model=models[i])\n",
    "    rmse_ave = rmse_coefs_ave(st_data[i], model=models[i])\n",
    "#     print(models[i])\n",
    "    # Polynomial fits (order 1 and 2, or other orders)\n",
    "    rmse_poly1_multi = rmse_coefs_poly(multi_data_poly1[i], model=models[i])\n",
    "    rmse_poly1_ave = rmse_coefs_ave_poly(st_data_poly1[i], model=models[i])\n",
    "    \n",
    "    rmse_poly2_multi = rmse_coefs_poly(multi_data_poly2[i], model=models[i])\n",
    "    rmse_poly2_ave = rmse_coefs_ave_poly(st_data_poly2[i], model=models[i])\n",
    "\n",
    "    x = x_data[i]\n",
    "\n",
    "    \n",
    "    # Column 1: Multi-trial vs. Average RMSE\n",
    "    axs[i, 0].plot(x, rmse_multi, 'o-', linewidth=5, color=\"green\", label=\"Trial-avg par SINDy\")\n",
    "    axs[i, 0].plot(x, rmse_ave, 'o-', linewidth=5, color=\"purple\", label=\"Multi-trial SINDy\")\n",
    "\n",
    "    # Column 2: Polynomial Order 1 - Multi vs. Average RMSE\n",
    "    axs[i, 1].plot(x, rmse_poly1_multi, 'o-', linewidth=5, color=\"green\", label=\"Poly Order 1 (Multi)\")\n",
    "    axs[i, 1].plot(x, rmse_poly1_ave, 'o-', linewidth=5, color=\"purple\", label=\"Poly Order 1 (Ave)\")\n",
    "    axs[i,1].yaxis.set_major_formatter(plt.FormatStrFormatter('%.3f'))\n",
    "    # Column 3: Polynomial Order 2 - Multi vs. Average RMSE\n",
    "    axs[i, 2].plot(x, rmse_poly2_multi, 'o-', linewidth=5, color=\"green\", label=\"Poly Order 2 (Multi)\")\n",
    "    axs[i, 2].plot(x, rmse_poly2_ave, 'o-', linewidth=5, color=\"purple\", label=\"Poly Order 2 (Ave)\")\n",
    "\n",
    "#         Set y-limits for the current row based on y_limits list\n",
    "    axs[i, 0].set_ylim(y_limits[i])  # Apply limits for multi vs. average RMSE\n",
    "    axs[i, 1].set_ylim(y_limits[i])  # Apply limits for polynomial order 1\n",
    "    if y_limits[i]==[8,9.5]:\n",
    "        y_limits[i]=[8,39]\n",
    "        axs[i, 2].set_ylim(y_limits[i])  # Apply limits for polynomial order 2\n",
    "    else:\n",
    "        axs[i, 2].set_ylim(y_limits[i])\n",
    "        \n",
    "    #set x and y labels for the last row\n",
    "#     if i == n_plots - 1:\n",
    "#         axs[i, 0].set_xlabel(\"Signal to noise ratio\")\n",
    "#         axs[i, 1].set_xlabel(\"Signal to noise ratio\")\n",
    "#         axs[i, 2].set_xlabel(\"Signal to noise ratio\")\n",
    "\n",
    "    # Set overall y-label for the first column\n",
    "\n",
    "\n",
    "    # Style adjustments for all plots\n",
    "    for j in range(3):\n",
    "        sns.despine(ax=axs[i, j])\n",
    "        axs[i, j].spines['left'].set_linewidth(5)\n",
    "        axs[i, j].spines['bottom'].set_linewidth(5)\n",
    "\n",
    "    # Add legends to the first row\n",
    "    if i == 0:\n",
    "        axs[i, 0].legend(fontsize=20)\n",
    "#         axs[i, 1].legend(fontsize=14)\n",
    "#         axs[i, 2].legend(fontsize=14)\n",
    "\n",
    "# Adjust layout for proper spacing\n",
    "fig.text(0.02, 0.5, \"RMSE\", ha='center', va='center', rotation='vertical')\n",
    "fig.text(0.5, .0,\"Signal-to-noise ratio\", ha='center',zorder=50)# plt.tight_layout()\n",
    "plt.tight_layout()\n",
    "# Optional: Save the combined figure\n",
    "# plt.savefig('rmse_multi_v_average_with_poly_fits.svg', dpi=600, bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
