{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9f365b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:98% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.io import loadmat\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pysindy as ps\n",
    "import pandas as pd\n",
    "from matplotlib import cm\n",
    "import time\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from statistics import mean \n",
    "from scipy.stats import ks_2samp\n",
    "import matplotlib.gridspec as gridspec\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:98% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc4978a9",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def confidenceInterval(alist, ciColumn, trials):\n",
    "    \"\"\"\n",
    "    Calculate confidence interval, mean, and standard deviation for a specified column in a list of datasets.\n",
    "    \n",
    "    Args:\n",
    "    alist (list): List of datasets.\n",
    "    ciColumn (int): Index of the column for confidence interval calculation.\n",
    "    trials (int): Not used in the function body and could be removed or repurposed.\n",
    "    \n",
    "    Returns:\n",
    "    tuple: lower and upper bounds of the confidence interval, mean, and standard deviation.\n",
    "    \"\"\"\n",
    "    mean_1 = mean_of_list(alist, ciColumn)  # Calculate mean for each point\n",
    "    std_1 = std_of_list(alist, ciColumn)  # Calculate standard deviation\n",
    "    confidence_low, confidence_high = bootstrap_confidence_interval_column(alist, ciColumn)  # Get confidence interval\n",
    "    return confidence_low, confidence_high, mean_1, std_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00858c35",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def bootstrap_confidence_interval_column(data, ciColumn, num_bootstrap_samples=1000, confidence_level=0.90):\n",
    "    \"\"\"\n",
    "    Generate bootstrap confidence intervals for a specified column across multiple datasets.\n",
    "    \n",
    "    Args:\n",
    "    data (list): List of datasets where each dataset is a list or a numpy array.\n",
    "    ciColumn (int): The index of the column for which to calculate the confidence interval.\n",
    "    num_bootstrap_samples (int): Number of bootstrap samples to generate.\n",
    "    confidence_level (float): Confidence level for the interval.\n",
    "    \n",
    "    Returns:\n",
    "    tuple: Lists of lower bounds, upper bounds of the confidence intervals.\n",
    "    \"\"\"\n",
    "    lower_bounds = []\n",
    "    upper_bounds = []\n",
    "    for dataset in data:\n",
    "        column_data = np.array(dataset)[:, ciColumn]\n",
    "        bootstrap_means = [np.mean(np.random.choice(column_data, size=len(column_data), replace=True)) for _ in range(num_bootstrap_samples)]\n",
    "        alpha = (1 - confidence_level) / 2\n",
    "        lower_bounds.append(np.percentile(bootstrap_means, 100 * alpha))\n",
    "        upper_bounds.append(np.percentile(bootstrap_means, 100 * (1 - alpha)))\n",
    "    return lower_bounds, upper_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "549ddf07",
   "metadata": {
    "code_folding": [
     0,
     17
    ]
   },
   "outputs": [],
   "source": [
    "def replace_column(matrix, new_column, snr_index, column_index):\n",
    "    \"\"\"\n",
    "    Replace a column in a matrix with a new column vector.\n",
    "    \n",
    "    Args:\n",
    "        matrix (list of lists): The original matrix.\n",
    "        new_column (list): The new column vector to replace the existing column.\n",
    "        snr_index (int): Index for the sub-list in matrix where the replacement should occur.\n",
    "        column_index (int): Index of the column to be replaced.\n",
    "    \n",
    "    Returns:\n",
    "        list of lists: The matrix with the updated column.\n",
    "    \"\"\"\n",
    "    if column_index < 0 or column_index >= len(matrix[0]):\n",
    "        raise ValueError(\"Invalid column_index\")\n",
    "    if len(new_column) != len(matrix[snr_index][column_index]):\n",
    "        raise ValueError(\"New column length must match the matrix height\")\n",
    "    for i in range(len(matrix[snr_index][column_index])):\n",
    "        matrix[snr_index][column_index][i] = new_column[i]\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7375ae54",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def flatten(data, column, column_sin):\n",
    "    \"\"\"\n",
    "    Flatten a specific column from a list of datasets. This function is intended to extract and flatten data\n",
    "    from a structured dataset where data points are organized in columns.\n",
    "    \n",
    "    Args:\n",
    "        data (list): List of datasets where each dataset is potentially a list of lists.\n",
    "        column (int): Index of the column to extract and flatten.\n",
    "        column_sin (int): Unused in this function but might be intended for future use to specify a second column.\n",
    "    \n",
    "    Returns:\n",
    "        list: A flat list of values extracted from the specified column across all datasets.\n",
    "    \"\"\"\n",
    "    flattened_data = []\n",
    "    for i in range(len(data)):\n",
    "        element = data[i][column]  # Extract the column for flattening\n",
    "        flattened_data.append(element)\n",
    "    flat_list = [item for sublist in flattened_data for item in sublist]  # Flatten the list of lists\n",
    "    return flat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3793e3db",
   "metadata": {
    "code_folding": [
     0,
     17
    ]
   },
   "outputs": [],
   "source": [
    "def normalise_decision_time(data,column_dt,column_dt_sindy,lcaddm=False):\n",
    "    \"\"\"\n",
    "    Normalize decision times in the data according to the maximum and minimum values found across all data.\n",
    "    \n",
    "    Args:\n",
    "    data (list): Data containing decision times.\n",
    "    column_dt (int): Index of the decision time column in each sub-list.\n",
    "    column_dt_sindy (int): Index of the decision time column in the SINDy model.\n",
    "    lcaddm (bool): Flag to indicate special processing condition.\n",
    "    \n",
    "    Returns:\n",
    "    list: Data with normalized decision times.\n",
    "    \"\"\"\n",
    "    model_dt_flat=flatten(data,column_dt,column_dt_sindy)\n",
    "    max_dt=max(model_dt_flat)\n",
    "    min_dt=min(model_dt_flat)\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        normalised=[]\n",
    "        normalised_sindy=[]\n",
    "        for c in range(len(data[i][column_dt])):\n",
    "            if i==4 and c==9999 and lcaddm==True:\n",
    "                norm_model_times = (mean(data[i][column_dt])- min_dt) / (max_dt - min_dt)\n",
    "                norm_model_times_sindy = (mean(data[i][column_dt_sindy]) - min_dt) / (max_dt - min_dt)\n",
    "                normalised.append(norm_model_times)\n",
    "                normalised_sindy.append(norm_model_times_sindy)\n",
    "            else:\n",
    "                norm_model_times = (data[i][column_dt][c] - min_dt) / (max_dt - min_dt)\n",
    "                norm_model_times_sindy = (data[i][column_dt_sindy][c] - min_dt) / (max_dt - min_dt)\n",
    "                normalised.append(norm_model_times)\n",
    "                normalised_sindy.append(norm_model_times_sindy)\n",
    "        #print(len(normalised))\n",
    "        data=replace_column(data, normalised, i, column_dt)\n",
    "        data=replace_column(data, normalised_sindy, i, column_dt_sindy)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da7a535c",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def cliffs_delta(x, y):\n",
    "    \"\"\"\n",
    "    Compute Cliff's Delta, a measure of effect size, comparing two samples.\n",
    "    \n",
    "    Args:\n",
    "    x (array): First sample.\n",
    "    y (array): Second sample.\n",
    "    \n",
    "    Returns:\n",
    "    float: Cliff's Delta value.\n",
    "    \"\"\"\n",
    "    all_values = np.concatenate((x, y))\n",
    "    ranks = np.argsort(all_values)\n",
    "    rx = np.mean(ranks[:len(x)])\n",
    "    ry = np.mean(ranks[len(x):])\n",
    "    delta = (rx - ry) / len(all_values)\n",
    "    return delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3fa0a2c",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def ks_statistical_analysis(data, column, column_sin, snr, no_column=False, data_sindy=None):\n",
    "    \"\"\"\n",
    "    Perform the Kolmogorov-Smirnov test and compute Cliff's Delta to assess the differences\n",
    "    between distributions in the provided datasets.\n",
    "    \n",
    "    Args:\n",
    "        data (list): A list of datasets.\n",
    "        column (int): Index of the primary column for comparison.\n",
    "        column_sin (int): Index of the secondary column for comparison.\n",
    "        snr (list): Signal-to-noise ratios or identifiers for the datasets.\n",
    "        no_column (bool): Indicates if the data lacks structured columns.\n",
    "        data_sindy (list, optional): Secondary dataset list for comparison.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: Contains D-statistics, p-values, significant points based on p-value,\n",
    "               and effect sizes (Cliff's Delta).\n",
    "    \"\"\"\n",
    "    p = np.empty(len(data))\n",
    "    d_stat = np.empty(len(data))  # KS statistic\n",
    "    effect_size = np.empty(len(data))  # cliff's d\n",
    "\n",
    "    if no_column:\n",
    "        for i in range(len(data)):\n",
    "            group1 = data[i]\n",
    "            group2 = data_sindy[i]\n",
    "            d_stat[i], p[i] = ks_2samp(group1, group2)\n",
    "            effect_size[i] = cliffs_delta(group1, group2)\n",
    "    else:\n",
    "        for i in range(len(data)):\n",
    "            group1 = data[i][column]\n",
    "            group2 = data[i][column_sin]\n",
    "            d_stat[i], p[i] = ks_2samp(group1, group2)\n",
    "            effect_size[i] = cliffs_delta(group1, group2)\n",
    "\n",
    "    significant_points = [snr[i] if p[i] < .05 else None for i in range(len(p))]\n",
    "    return d_stat, p, significant_points, effect_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0928673e",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def mean_of_list(alist, column, no_column=False):\n",
    "    \"\"\"\n",
    "    Calculate the mean of a specified column in a list of datasets, or of each dataset if no_column is True.\n",
    "    \n",
    "    Args:\n",
    "        alist (list): List of datasets, where each dataset can be a list of lists or a list of numbers.\n",
    "        column (int): Index of the column to compute the mean for.\n",
    "        no_column (bool): If True, computes the mean of the entire dataset (assumed to be flat).\n",
    "    \n",
    "    Returns:\n",
    "        list: List of means for each dataset.\n",
    "    \"\"\"\n",
    "    if no_column:\n",
    "        return [mean(dataset) for dataset in alist]\n",
    "    else:\n",
    "        return [mean(dataset[column]) for dataset in alist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a1d14dc",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def std_of_list(alist, column, no_column=False):\n",
    "    \"\"\"\n",
    "    Calculate the standard deviation of a specified column in a list of datasets, or of each dataset if no_column is True.\n",
    "    \n",
    "    Args:\n",
    "        alist (list): List of datasets.\n",
    "        column (int): Index of the column to compute the standard deviation for.\n",
    "        no_column (bool): If True, computes the standard deviation of the entire dataset (assumed to be flat).\n",
    "    \n",
    "    Returns:\n",
    "        list: List of standard deviations for each dataset.\n",
    "    \"\"\"\n",
    "    if no_column:\n",
    "        return [std(dataset) for dataset in alist]\n",
    "    else:\n",
    "        return [std(dataset[column]) for dataset in alist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b465d14",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def average_activity_multidimensional(data, trial_threshold=100):\n",
    "    \"\"\"\n",
    "    Calculate the average activity across multiple populations in multidimensional data, truncated to the last valid\n",
    "    time point based on a minimum trial threshold.\n",
    "\n",
    "    Args:\n",
    "        data (list of list of lists): Data containing multiple populations over multiple samples, structured as a list\n",
    "                                      of samples, where each sample contains lists of population activity data.\n",
    "        trial_threshold (int): The minimum number of valid trials required for a time point to be considered in the average.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of averages for each population, truncated to the minimum last valid time point across populations.\n",
    "    \"\"\"\n",
    "    # Determine the number of populations and the maximum time length\n",
    "    num_populations = len(data[0])\n",
    "    max_length = max(max(len(population) for population in sample) for sample in data)\n",
    "    \n",
    "    # Initialize an array to store padded data\n",
    "    padded_data = []\n",
    "    for sample in data:\n",
    "        padded_sample = [np.pad(population, (0, max_length - len(population)), 'constant', constant_values=np.nan) for population in sample]\n",
    "        padded_data.append(padded_sample)\n",
    "    \n",
    "    # Convert the list of padded data to a numpy array for easy mean calculation\n",
    "    padded_data_np = np.array(padded_data)\n",
    "    average_activity = np.nanmean(padded_data_np, axis=0)\n",
    "    \n",
    "    # Calculate valid counts and determine the last valid index based on the trial threshold\n",
    "    valid_counts = np.sum(~np.isnan(padded_data_np), axis=0)\n",
    "    last_valid_indices = np.max(np.where(valid_counts >= trial_threshold, np.arange(valid_counts.shape[1]), 0), axis=1)\n",
    "    min_last_valid_index = np.min(last_valid_indices)\n",
    "    \n",
    "    # Truncate the average activity to the last valid index\n",
    "    truncated_averages = average_activity[:, :min_last_valid_index + 1]\n",
    "    return truncated_averages.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0141066d",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def average_activity(data, trial_threshold=100):\n",
    "    \"\"\"\n",
    "    Calculate the average activity across data points, truncated to the last valid time point based on a minimum\n",
    "    trial threshold.\n",
    "\n",
    "    Args:\n",
    "        data (list of lists): Data containing time series or trials from multiple entities.\n",
    "        trial_threshold (int): Minimum number of trials required to consider a time point valid.\n",
    "\n",
    "    Returns:\n",
    "        list: Average activity for the data, truncated to the last valid time point where the trial count exceeds the threshold.\n",
    "    \"\"\"\n",
    "    # Find the maximum length across all data points for padding\n",
    "    max_length = max(len(item) for item in data)\n",
    "    \n",
    "    # Pad each data point with NaNs to the maximum length\n",
    "    padded_data = np.array([np.pad(item, (0, max_length - len(item)), 'constant', constant_values=np.nan) for item in data])\n",
    "    \n",
    "    # Calculate the mean, ignoring NaNs for an accurate calculation\n",
    "    average_activity = np.nanmean(padded_data, axis=0)\n",
    "    \n",
    "    # Count the number of non-NaN values at each time point\n",
    "    valid_counts = np.sum(~np.isnan(padded_data), axis=0)\n",
    "    \n",
    "    # Determine the last valid time point based on the trial threshold\n",
    "    last_valid_index = np.max(np.where(valid_counts >= trial_threshold)[0])\n",
    "    \n",
    "    # Truncate the average activity to this last valid index\n",
    "    truncated_average_activity = average_activity[:last_valid_index + 1]\n",
    "    return truncated_average_activity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdddb32a",
   "metadata": {},
   "source": [
    "# Figure 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7332c1",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#fig2. setup\n",
    "x_ddm=SnR_ddm\n",
    "ddm_acc=confidenceInterval(st_ddm,1,10000)\n",
    "ddm_acc=[np.array(ddm_acc[i])*100 for i in range(len(ddm_acc))]\n",
    "ddm_accsin=confidenceInterval(st_ddm,2,10000)\n",
    "ddm_accsin=[np.array(ddm_accsin[i])*100 for i in range(len(ddm_accsin))]\n",
    "c_ddm_acc,p_ddm_acc,sig_points_acc_ddm,effect_st_ddm=ks_statistical_analysis(st_ddm,1,2,x_ddm)\n",
    "\n",
    "ddm_time=confidenceInterval(st_ddm,3,10000)\n",
    "ddm_time=[np.array(ddm_time[i]) for i in range(len(ddm_time))]\n",
    "ddm_timesin=confidenceInterval(st_ddm,4,10000)\n",
    "ddm_timesin=[np.array(ddm_timesin[i]) for i in range(len(ddm_timesin))]\n",
    "c_ddm_time,p_ddm_time,sig_points_time_ddm,effect_st_ddm_t=ks_statistical_analysis(st_ddm,3,4,x_ddm)\n",
    "\n",
    "x_lcaddm=SnR_lcaddm\n",
    "lcaddm_acc=confidenceInterval(st_lcaddm,1,10000)\n",
    "lcaddm_acc=[np.array(lcaddm_acc[i])*100 for i in range(len(lcaddm_acc))]\n",
    "lcaddm_accsin=confidenceInterval(st_lcaddm,2,10000)\n",
    "lcaddm_accsin=[np.array(lcaddm_accsin[i])*100 for i in range(len(lcaddm_accsin))]\n",
    "c_lcaddm_acc,p_lcaddm_acc,sig_points_acc_lcaddm,effect_st_lcaddm=ks_statistical_analysis(st_lcaddm,1,2,x_lcaddm)\n",
    "\n",
    "lcaddm_time=confidenceInterval(st_lcaddm,3,10000)\n",
    "lcaddm_time=[np.array(lcaddm_time[i]) for i in range(len(lcaddm_time))]\n",
    "lcaddm_timesin=confidenceInterval(st_lcaddm,4,10000)\n",
    "lcaddm_timesin=[np.array(lcaddm_timesin[i]) for i in range(len(lcaddm_timesin))]\n",
    "c_lcaddm_time,p_lcaddm_time,sig_points_time_lcaddm,effect_st_lcaddm_t=ks_statistical_analysis(st_lcaddm,3,4,x_lcaddm)\n",
    "\n",
    "lcaddm_poly_acc=confidenceInterval(st_lcaddm_poly,1,10000)\n",
    "lcaddm_poly_acc=[np.array(lcaddm_poly_acc[i])*100 for i in range(len(lcaddm_poly_acc))]\n",
    "lcaddm_poly_accsin=confidenceInterval(st_lcaddm_poly,2,10000)\n",
    "lcaddm_poly_accsin=[np.array(lcaddm_poly_accsin[i])*100 for i in range(len(lcaddm_poly_accsin))]\n",
    "c_lcaddm_poly_acc,p_lcaddm_poly_acc,sig_points_acc_lcaddm_poly,effect_st_lcaddm_poly=ks_statistical_analysis(st_lcaddm_poly,1,2,x_lcaddm)\n",
    "\n",
    "lcaddm_poly_time=confidenceInterval(st_lcaddm_poly,3,10000)\n",
    "lcaddm_poly_time=[np.array(lcaddm_poly_time[i]) for i in range(len(lcaddm_poly_time))]\n",
    "lcaddm_poly_timesin=confidenceInterval(st_lcaddm_poly,4,10000)\n",
    "lcaddm_poly_timesin=[np.array(lcaddm_poly_timesin[i]) for i in range(len(lcaddm_poly_timesin))]\n",
    "c_lcaddm_poly_time,p_lcaddm_poly_time,sig_points_time_lcaddm_poly,effect_st_lcaddm_poly_t=ks_statistical_analysis(st_lcaddm_poly,3,4,x_lcaddm)\n",
    "\n",
    "x_lca=SnR_lca\n",
    "lca_acc=confidenceInterval(st_lca,1,10000)\n",
    "lca_acc=[np.array(lca_acc[i])*100 for i in range(len(lca_acc))]\n",
    "lca_accsin=confidenceInterval(st_lca,2,10000)\n",
    "lca_accsin=[np.array(lca_accsin[i])*100 for i in range(len(lca_accsin))]\n",
    "c_lca_acc,p_lca_acc,sig_points_acc_lca,effect_st_lca=ks_statistical_analysis(st_lca,1,2,x_lca)\n",
    "\n",
    "lca_time=confidenceInterval(st_lca,3,10000)\n",
    "lca_time=[np.array(lca_time[i]) for i in range(len(lca_time))]\n",
    "lca_timesin=confidenceInterval(st_lca,4,10000)\n",
    "lca_timesin=[np.array(lca_timesin[i]) for i in range(len(lca_timesin))]\n",
    "c_lca_time,p_lca_time,sig_points_time_lca,effect_st_lca_t=ks_statistical_analysis(st_lca,3,4,x_lca)\n",
    "\n",
    "x_nlb=SnR_nlb\n",
    "nlb_acc=confidenceInterval(st_nlb,1,10000)\n",
    "nlb_acc=[np.array(nlb_acc[i])*100 for i in range(len(nlb_acc))]\n",
    "nlb_accsin=confidenceInterval(st_nlb,2,10000)\n",
    "nlb_accsin=[np.array(nlb_accsin[i])*100 for i in range(len(nlb_accsin))]\n",
    "c_nlb_acc,p_nlb_acc,sig_points_acc_nlb,effect_st_nlb=ks_statistical_analysis(st_nlb,1,2,x_nlb)\n",
    "\n",
    "nlb_time=confidenceInterval(st_nlb,3,10000)\n",
    "nlb_time=[np.array(nlb_time[i]) for i in range(len(nlb_time))]\n",
    "nlb_timesin=confidenceInterval(st_nlb,4,10000)\n",
    "nlb_timesin=[np.array(nlb_timesin[i]) for i in range(len(nlb_timesin))]\n",
    "c_nlb_time,p_nlb_time,sig_points_time_nlb,effect_st_nlb_t=ks_statistical_analysis(st_nlb,3,4,x_nlb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fa64f4",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "###fig 2 \n",
    "sns.set(font_scale=4)\n",
    "sns.set_style('white') # darkgrid, white grid, dark, white and ticks\n",
    "plt.rc('axes', titlesize=36)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=48)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=48)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=48)    # fontsize of the tick labels\n",
    "#plt.rc('legend', fontsize=16)    # legend fontsize\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.sans-serif'] = 'Arial'\n",
    "plt.rc('font', size=48)          # controls default text sizes\n",
    "# sns.set(font_scale=2)\n",
    "# Assuming st_ddm and other necessary data are already defined\n",
    "#ddm accuracy and rts\n",
    "\n",
    "\n",
    "data_sets = [{'time':np.arange(0,10000,.1),'letter':'A','label':'DDM','model':st_ddm,'x': x_ddm,'acc': ddm_acc,'accsin': ddm_accsin,'time': ddm_time,'timesin': ddm_timesin,'sig_points_acc': sig_points_acc_ddm,'sig_points_time': sig_points_time_ddm,'effect_st_acc': effect_st_ddm,'effect_st_time': effect_st_ddm_t},\n",
    "{'time':np.arange(0,10000,.01),'letter':'B','label':'LCA-DDM','model':st_lcaddm, 'x': x_lcaddm,'acc': lcaddm_acc,'accsin': lcaddm_accsin,'time': lcaddm_time,'timesin': lcaddm_timesin,'sig_points_acc': sig_points_acc_lcaddm,'sig_points_time': sig_points_time_lcaddm,'effect_st_acc': effect_st_lcaddm,'effect_st_time': effect_st_lcaddm_t,'acc_poly': lcaddm_poly_acc,'accsin_poly': lcaddm_poly_accsin,'time_poly': lcaddm_poly_time,'timesin_poly': lcaddm_poly_timesin,'sig_points_acc_poly': sig_points_acc_lcaddm_poly,'sig_points_time_poly': sig_points_time_lcaddm_poly,'effect_st_acc_poly': effect_st_lcaddm_poly,'effect_st_time_poly': effect_st_lcaddm_poly_t},\n",
    "{'time':np.arange(0,10000,.01),'letter':'C','label':'LCA','model':st_lca, 'x': x_lca,'acc': lca_acc,'accsin': lca_accsin,'time': lca_time,'timesin': lca_timesin,'sig_points_acc': sig_points_acc_lca,'sig_points_time': sig_points_time_lca,'effect_st_acc': effect_st_lca,'effect_st_time': effect_st_lca_t},\n",
    "{'time':np.arange(0,10000,.01),'letter':'D','label':'NLB','model':st_nlb, 'x': x_nlb,'acc': nlb_acc,'accsin': nlb_accsin,'time': nlb_time,'timesin': nlb_timesin,'sig_points_acc': sig_points_acc_nlb,'sig_points_time': sig_points_time_nlb,'effect_st_acc': effect_st_nlb,'effect_st_time': effect_st_nlb_t}\n",
    "]\n",
    "\n",
    "# Define your figure and gridspec\n",
    "fig = plt.figure(figsize=(35, 30))  # Adjust the figure size as needed\n",
    "gs = gridspec.GridSpec(4, 4, wspace=0.65)  # 4 rows, 4 columns, with column spans for the first plot in each row\n",
    "\n",
    "# Assuming data_sets is defined as provided\n",
    "\n",
    "for row, model_data in enumerate(data_sets ):  # Repeat data_sets twice since you have 4 rows and 2 models\n",
    "    # Accessing data for the current model\n",
    "    model_trials= model_data['model']\n",
    "    x = model_data['x']\n",
    "    acc = model_data['acc']\n",
    "    accsin = model_data['accsin']\n",
    "    time = model_data['time']\n",
    "    timesin = model_data['timesin']\n",
    "    sig_points_acc = model_data['sig_points_acc']\n",
    "    effect_st_acc = model_data['effect_st_acc']\n",
    "    sig_points_time = model_data['sig_points_time']\n",
    "    effect_st_time = model_data['effect_st_time']\n",
    "    label=model_data['label']\n",
    "    letter=model_data['letter']\n",
    "    if letter ==\"B\":\n",
    "        acc_poly = model_data['acc_poly']\n",
    "        acc_polysin = model_data['accsin_poly']\n",
    "        time_poly = model_data['time_poly']\n",
    "        timesin_poly = model_data['timesin_poly']\n",
    "        sig_points_acc_poly = model_data['sig_points_acc_poly']\n",
    "        effect_st_acc_poly = model_data['effect_st_acc_poly']\n",
    "        sig_points_time_poly = model_data['sig_points_time_poly']\n",
    "        effect_st_time_poly = model_data['effect_st_time_poly']\n",
    "    \n",
    "    \n",
    "    if len(model_trials[0][5][0])>2:\n",
    "        \n",
    "        if len(model_trials[0][5])>100:\n",
    "            a_test=np.arange(0,10000,.1)\n",
    "            # First plot: Trial Data Plot, taking double space\n",
    "            ax0 = fig.add_subplot(gs[row, :2])  # Span first two columns\n",
    "            ax0.plot(a_test[0:len(model_trials[40][5][125])],model_trials[40][5][125], color='blue', label=\"Model\", linewidth=7)\n",
    "            ax0.plot(a_test[0:len(model_trials[40][6][125])],model_trials[40][6][125], color='orange', label='SINDy', linewidth=7)\n",
    "            ax0.axhline(y=1, linestyle='dashed', linewidth=7, color='black', label='Threshold')\n",
    "            ax0.axhline(y=-1, linestyle='dashed', linewidth=7, color='black')\n",
    "            ax0.set_xlim(0)\n",
    "            ax0.set(ylabel=\"$X$\")\n",
    "            sns.despine()\n",
    "            ax0.legend(loc='best', fontsize=24)\n",
    "            ax0.spines['left'].set_linewidth(7)\n",
    "            ax0.spines['bottom'].set_linewidth(7)\n",
    "            ax0.set_title(letter, fontsize=48,fontweight='bold' )\n",
    "            ax0.title.set_position([-.1, 1.05]) \n",
    "        else:\n",
    "            a_test=np.arange(0,10000,.01)\n",
    "\n",
    "            # First plot: Trial Data Plot, taking double space\n",
    "            ax0 = fig.add_subplot(gs[row, :2])  # Span first two columns\n",
    "            ax0.plot(a_test[0:len(model_trials[40][5][2])],model_trials[40][5][2], color='blue', label=label, linewidth=7)\n",
    "            ax0.plot(a_test[0:len(model_trials[40][6][2])],model_trials[40][6][2], color='orange', label='SINDy', linewidth=7)\n",
    "            ax0.axhline(y=.75, linestyle='dashed', linewidth=7, color='black', label='Threshold')\n",
    "            ax0.axhline(y=-.75, linestyle='dashed', linewidth=7, color='black')\n",
    "            #ax0.set_ylabel('Decision variable')\n",
    "            ax0.set(ylabel=\"$X$\")\n",
    "            ax0.set_xlim(0)\n",
    "            sns.despine()\n",
    "#             ax0.legend(loc='best', fontsize=24)\n",
    "            ax0.spines['left'].set_linewidth(7)\n",
    "            ax0.spines['bottom'].set_linewidth(7)\n",
    "            ax0.set_title(letter, fontsize=48,fontweight='bold' )\n",
    "            ax0.title.set_position([-.1, 1.05]) \n",
    "    else:\n",
    "        # First plot: Trial Data Plot, taking double space\n",
    "        a_test=np.arange(0,10000,.01)\n",
    "        ax0 = fig.add_subplot(gs[row, :2])  # Span first two columns\n",
    "        ax0.plot(a_test[0:len(model_trials[40][5][0][0])],(model_trials[40][5][0][0]),color='blue', label=label,linewidth=7 )\n",
    "        ax0.plot(a_test[0:len(model_trials[40][5][0][1])],(model_trials[40][5][0][1]),color='blue', alpha=.5,linewidth=7 )\n",
    "        ax0.plot(a_test[0:len(model_trials[40][6][0][0])],(model_trials[40][6][0][0]),color='orange', label='SINDy',linewidth=7 )\n",
    "        ax0.plot(a_test[0:len(model_trials[40][6][0][1])],(model_trials[40][6][0][1]),color='orange', alpha=.5,linewidth=7 )\n",
    "        ax0.axhline(y=1, linestyle='dashed', linewidth=7, color='black',label='Threshold')\n",
    "        ax0.axvline(x=-1, linestyle='dashed', linewidth=7, color='grey',label='Error')\n",
    "        ax0.set(ylabel=\"$y_1$, $y_2$\")\n",
    "        ax0.set_xlim(0)\n",
    "        sns.despine()\n",
    "#         ax0.legend(loc='best', fontsize=24)\n",
    "        ax0.spines['left'].set_linewidth(7)\n",
    "        ax0.spines['bottom'].set_linewidth(7)\n",
    "        ax0.set_title(letter, fontsize=48,fontweight='bold' )\n",
    "        ax0.title.set_position([-.1, 1.05]) \n",
    "    \n",
    "    # Second plot: Accuracy Plot\n",
    "    ax1 = fig.add_subplot(gs[row, 2])\n",
    "    # Plotting accuracy data\n",
    "    ax1.plot(sig_points_acc, np.full(len(sig_points_acc), 40), '*', color='black')\n",
    "    ax1.plot(x, acc[2], '', color='blue', label=label,linewidth=4 )\n",
    "    ax1.plot(x, acc[0], color='blue',linewidth=3 )\n",
    "    ax1.plot(x, acc[1], color='blue',linewidth=3 )\n",
    "    ax1.fill_between(x, acc[0], acc[1], color='blue', alpha=0.25)\n",
    "    ax1.plot(x, accsin[2], '', color='orange', label=\"SINDy Model\",linewidth=4)\n",
    "    ax1.plot(x, accsin[0], color='orange',linewidth=3)\n",
    "    ax1.plot(x, accsin[1], color='orange',linewidth=3)\n",
    "    ax1.fill_between(x, accsin[0], accsin[1], color='orange', alpha=0.25)\n",
    "    if letter =='B':\n",
    "        ax1.plot(x, acc_polysin[2], '', color='gold', label=\"SINDy Model\")\n",
    "        ax1.plot(x, acc_polysin[0], color='gold')\n",
    "        ax1.plot(x, acc_polysin[1], color='gold')\n",
    "        ax1.fill_between(x, acc_polysin[0], acc_polysin[1], color='gold', alpha=0.25)\n",
    "        \n",
    "    # Add cliff's d annotations for accuracy\n",
    "#     for i, (x_val, d_value) in enumerate(zip(x, effect_st_acc)):\n",
    "#         if sig_points_acc[i] is not None:\n",
    "#             ax1.text(x_val, 45, f'd={d_value:.2f}', fontsize=4, ha='center', va='bottom', color='red')\n",
    "\n",
    "    # Third plot: Response Time Plot\n",
    "    ax2 = fig.add_subplot(gs[row, 3])\n",
    "    # Plotting response time data\n",
    "    ax2.plot(sig_points_time, np.full(len(sig_points_time), 0), '*', color='black')\n",
    "    ax2.plot(x, time[2], '', color='blue', label=\"Model Response Time\",linewidth=4)\n",
    "    ax2.plot(x, time[0], color='blue',linewidth=3)\n",
    "    ax2.plot(x, time[1], color='blue',linewidth=3)\n",
    "    ax2.fill_between(x, time[0], time[1], color='blue', alpha=0.25)\n",
    "    ax2.plot(x, timesin[2], '', color='orange', label=\"SINDy Response Time\",linewidth=4)\n",
    "    ax2.plot(x, timesin[0], color='orange',linewidth=3)\n",
    "    ax2.plot(x, timesin[1], color='orange',linewidth=3)\n",
    "    ax2.fill_between(x, timesin[0], timesin[1], color='orange', alpha=0.25)\n",
    "    if letter =='B':\n",
    "        ax2.plot(x, timesin_poly[2], '', color='gold', label=\"SINDy Response Time\")\n",
    "        ax2.plot(x, timesin_poly[0], color='gold')\n",
    "        ax2.plot(x, timesin_poly[1], color='gold')\n",
    "        ax2.fill_between(x, timesin_poly[0], timesin_poly[1], color='gold', alpha=0.25)\n",
    "    # Add cliff's d annotations for response time\n",
    "#     for i, (x_val, d_value) in enumerate(zip(x, effect_st_time)):\n",
    "#         if sig_points_time[i] is not None:\n",
    "#             ax2.text(x_val, 1, f'   d={d_value:.2f}  ', fontsize=4, ha='center', va='bottom', color='red')\n",
    "\n",
    "    # Apply styles\n",
    "    sns.despine(ax=ax1)\n",
    "    sns.despine(ax=ax2)\n",
    "    ax1.spines['left'].set_linewidth(7)\n",
    "    ax1.spines['bottom'].set_linewidth(7)\n",
    "    ax2.spines['left'].set_linewidth(7)\n",
    "    ax2.spines['bottom'].set_linewidth(7)\n",
    "    #ax1.legend(loc='best', fontsize=14)\n",
    "    #ax2.legend(loc='best', fontsize=14)\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "ax0.set_xlabel('Time (a.u.)')\n",
    "# ax1.supylabel('Choice accuracy (%)')\n",
    "# ax2.supylabel('Normalised decision time')\n",
    "fig.text(.85, .85, 'DDM', ha='center', va='center',zorder=50)\n",
    "fig.text(.86, .65, 'LCA-DDM', ha='center', va='center',zorder=50)\n",
    "fig.text(.85, .45, 'LCA', ha='center', va='center',zorder=50)\n",
    "fig.text(.85, .25, 'NLB', ha='center', va='center',zorder=50)\n",
    "\n",
    "\n",
    "fig.text(0.71, 0.525, 'Normalised decision time (a.u.)', ha='center', va='center', rotation='vertical',zorder=50)\n",
    "fig.text(0.50, 0.525, 'Choice accuracy (%)', ha='center', va='center', rotation='vertical',zorder=50)\n",
    "fig.text(.73, 0.09, 'Signal-to-noise ratio', ha='center', va='center',zorder=50)\n",
    "fig.text(0.075, 0.525, 'Decision variable', ha='center', va='center',rotation='vertical',zorder=50)\n",
    "\n",
    "# fig.supylabel('Decision variable')\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig('fig_2_single_trial_02_05.pdf', dpi=600, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0f5093",
   "metadata": {},
   "source": [
    "# Figure 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f4810b",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "###fig 3 data\n",
    "# Assuming ave_ddm and other necessary data are already defined\n",
    "#ddm accuracy and rts\n",
    "x_ddm=SnR_ddm\n",
    "ddm_acc=confidenceInterval(ave_ddm,1,10000)\n",
    "ddm_acc=[np.array(ddm_acc[i])*100 for i in range(len(ddm_acc))]\n",
    "ddm_accsin=confidenceInterval(ave_ddm,2,10000)\n",
    "ddm_accsin=[np.array(ddm_accsin[i])*100 for i in range(len(ddm_accsin))]\n",
    "c_ddm_acc,p_ddm_acc,sig_points_acc_ddm,effect_ave_ddm=ks_statistical_analysis(ave_ddm,1,2,x_ddm)\n",
    "\n",
    "x_ddm=SnR_ddm\n",
    "ddm_time=confidenceInterval(ave_ddm,3,10000)\n",
    "ddm_time=[np.array(ddm_time[i]) for i in range(len(ddm_time))]\n",
    "ddm_timesin=confidenceInterval(ave_ddm,4,10000)\n",
    "ddm_timesin=[np.array(ddm_timesin[i]) for i in range(len(ddm_timesin))]\n",
    "c_ddm_time,p_ddm_time,sig_points_time_ddm,effect_ave_ddm_t=ks_statistical_analysis(ave_ddm,3,4,x_ddm)\n",
    "\n",
    "x_lcaddm=SnR_lcaddm\n",
    "lcaddm_acc=confidenceInterval(ave_lcaddm,1,10000)\n",
    "lcaddm_acc=[np.array(lcaddm_acc[i])*100 for i in range(len(lcaddm_acc))]\n",
    "lcaddm_accsin=confidenceInterval(ave_lcaddm,2,10000)\n",
    "lcaddm_accsin=[np.array(lcaddm_accsin[i])*100 for i in range(len(lcaddm_accsin))]\n",
    "c_lcaddm_acc,p_lcaddm_acc,sig_points_acc_lcaddm,effect_ave_lcaddm=ks_statistical_analysis(ave_lcaddm,1,2,x_lcaddm)\n",
    "\n",
    "x_lcaddm=SnR_lcaddm\n",
    "lcaddm_time=confidenceInterval(ave_lcaddm,3,10000)\n",
    "lcaddm_time=[np.array(lcaddm_time[i]) for i in range(len(lcaddm_time))]\n",
    "lcaddm_timesin=confidenceInterval(ave_lcaddm,4,10000)\n",
    "lcaddm_timesin=[np.array(lcaddm_timesin[i]) for i in range(len(lcaddm_timesin))]\n",
    "c_lcaddm_time,p_lcaddm_time,sig_points_time_lcaddm,effect_ave_lcaddm_t=ks_statistical_analysis(ave_lcaddm,3,4,x_lcaddm)\n",
    "\n",
    "x_lca=SnR_lca\n",
    "lca_acc=confidenceInterval(ave_lca,1,10000)\n",
    "lca_acc=[np.array(lca_acc[i])*100 for i in range(len(lca_acc))]\n",
    "lca_accsin=confidenceInterval(ave_lca,2,10000)\n",
    "lca_accsin=[np.array(lca_accsin[i])*100 for i in range(len(lca_accsin))]\n",
    "c_lca_acc,p_lca_acc,sig_points_acc_lca,effect_ave_lca=ks_statistical_analysis(ave_lca,1,2,x_lca)\n",
    "\n",
    "x_lca=SnR_lca\n",
    "lca_time=confidenceInterval(ave_lca,3,10000)\n",
    "lca_time=[np.array(lca_time[i]) for i in range(len(lca_time))]\n",
    "lca_timesin=confidenceInterval(ave_lca,4,10000)\n",
    "lca_timesin=[np.array(lca_timesin[i]) for i in range(len(lca_timesin))]\n",
    "c_lca_time,p_lca_time,sig_points_time_lca,effect_ave_lca_t=ks_statistical_analysis(ave_lca,3,4,x_lca)\n",
    "\n",
    "x_nlb=SnR_nlb\n",
    "nlb_acc=confidenceInterval(ave_nlb,1,10000)\n",
    "nlb_acc=[np.array(nlb_acc[i])*100 for i in range(len(nlb_acc))]\n",
    "nlb_accsin=confidenceInterval(ave_nlb,2,10000)\n",
    "nlb_accsin=[np.array(nlb_accsin[i])*100 for i in range(len(nlb_accsin))]\n",
    "c_nlb_acc,p_nlb_acc,sig_points_acc_nlb,effect_ave_nlb=ks_statistical_analysis(ave_nlb,1,2,x_nlb)\n",
    "\n",
    "x_nlb=SnR_nlb\n",
    "nlb_time=confidenceInterval(ave_nlb,3,10000)\n",
    "nlb_time=[np.array(nlb_time[i]) for i in range(len(nlb_time))]\n",
    "nlb_timesin=confidenceInterval(ave_nlb,4,10000)\n",
    "nlb_timesin=[np.array(nlb_timesin[i]) for i in range(len(nlb_timesin))]\n",
    "c_nlb_time,p_nlb_time,sig_points_time_nlb,effect_ave_nlb_t=ks_statistical_analysis(ave_nlb,3,4,x_nlb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b9efd0",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#fig 3#\n",
    "\n",
    "# /graph var fig3\n",
    "sns.set_style('white') # darkgrid, white grid, dark, white and ticks\n",
    "plt.rc('axes', titlesize=36)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=48)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=40)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=40)    # fontsize of the tick labels\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.sans-serif'] = 'Arial'\n",
    "#plt.rc('legend', fontsize=20)    # legend fontsize\n",
    "plt.rc('font', size=48)          # controls default text sizes\n",
    "\n",
    "data_sets = [\n",
    "{'label':'DDM','x': x_ddm,'acc': ddm_acc,'accsin': ddm_accsin,'time': ddm_time,'timesin': ddm_timesin,'sig_points_acc': sig_points_acc_ddm,'sig_points_time': sig_points_time_ddm,'effect_ave_acc': effect_ave_ddm,'effect_ave_time': effect_ave_ddm_t},\n",
    "{'label':'LCA-DDM', 'x': x_lcaddm,'acc': lcaddm_acc,'accsin': lcaddm_accsin,'time': lcaddm_time,'timesin': lcaddm_timesin,'sig_points_acc': sig_points_acc_lcaddm,'sig_points_time': sig_points_time_lcaddm,'effect_ave_acc': effect_ave_lcaddm,'effect_ave_time': effect_ave_lcaddm_t},\n",
    "{'label':'LCA', 'x': x_lca,'acc': lca_acc,'accsin': lca_accsin,'time': lca_time,'timesin': lca_timesin,'sig_points_acc': sig_points_acc_lca,'sig_points_time': sig_points_time_lca,'effect_ave_acc': effect_ave_lca,'effect_ave_time': effect_ave_lca_t},\n",
    "# {'label':'DDM polynomial 1','x': x_ddm,'acc': ddm_acc_poly,'accsin': ddm_accsin_poly,'time': ddm_time_poly,'timesin': ddm_timesin_poly,'sig_points_acc': sig_points_acc_ddm_poly,'sig_points_time': sig_points_time_ddm_poly,'effect_ave_acc': effect_ave_ddm_poly,'effect_ave_time': effect_ave_ddm_t_poly},\n",
    "# {'label':'LCA-DDM poly 0 ', 'x': x_lcaddm,'acc': lcaddm_acc_poly,'accsin': lcaddm_accsin_poly,'time': lcaddm_time_poly,'timesin': lcaddm_timesin_poly,'sig_points_acc': sig_points_acc_lcaddm_poly,'sig_points_time': sig_points_time_lcaddm_poly,'effect_ave_acc': effect_ave_lcaddm_poly,'effect_ave_time': effect_ave_lcaddm_t},\n",
    "# {'label':'LCA poly 0 ', 'x': x_lca,'acc': lca_acc_poly,'accsin': lca_accsin_poly,'time': lca_time_poly,'timesin': lca_timesin_poly,'sig_points_acc': sig_points_acc_lca_poly,'sig_points_time': sig_points_time_lca_poly,'effect_ave_acc': effect_ave_lca_poly,'effect_ave_time': effect_ave_lca_t_poly},\n",
    "{'label':'NLB','x': x_nlb,'acc': nlb_acc,'accsin': nlb_accsin,'time': nlb_time,'timesin': nlb_timesin,'sig_points_acc': sig_points_acc_nlb,'sig_points_time': sig_points_time_nlb,'effect_ave_acc': effect_ave_nlb,'effect_ave_time': effect_ave_nlb_t}\n",
    "\n",
    "    # {'label':'DDM poly 2','model':average_ddm_poly2,'x': x_ddm,'acc': ddm_acc_poly2,'accsin': ddm_accsin_poly2,'time': ddm_time_poly2,'timesin': ddm_timesin_poly2,'sig_points_acc': sig_points_acc_ddm_poly2,'sig_points_time': sig_points_time_ddm_poly2,'effect_ave_acc': effect_ave_ddm_poly2,'effect_ave_time': effect_ave_ddm_t_poly2},\n",
    "# {'label':'LCA-DDM poly 2','model':average_lcaddm_poly2, 'x': x_lcaddm,'acc': lcaddm_acc_poly2,'accsin': lcaddm_accsin_poly2,'time': lcaddm_time_poly2,'timesin': lcaddm_timesin_poly2,'sig_points_acc': sig_points_acc_lcaddm_poly2,'sig_points_time': sig_points_time_lcaddm_poly2,'effect_ave_acc': effect_ave_lcaddm_poly2,'effect_ave_time': effect_ave_lcaddm_t_poly2},\n",
    "# {'label':'LCA poly 2','model':average_lca_poly2, 'x': x_lca,'acc': lca_acc_poly2,'accsin': lca_accsin_poly2,'time': lca_time_poly2,'timesin': lca_timesin_poly2,'sig_points_acc': sig_points_acc_lca_poly2,'sig_points_time': sig_points_time_lca_poly2,'effect_ave_acc': effect_ave_lca_poly2,'effect_ave_time': effect_ave_lca_t_poly2}\n",
    "] \n",
    "\n",
    "# Define your figure and gridspec\n",
    "fig = plt.figure(figsize=(30, 25))  # Adjust the figure size as needed\n",
    "gs = gridspec.GridSpec(4, 2, wspace=0.25)  # Adjusted for 3 model groups, 2 plots (Accuracy, Response Time) each\n",
    "\n",
    "# Helper function to plot for each model group\n",
    "def plot_for_model_group(ax_acc, ax_time, model_group_data, x, label_prefix,letter):\n",
    "    i=0\n",
    "    for model_data in model_group_data:\n",
    "        \n",
    "        # Accuracy Plot\n",
    "        ax_acc.plot(model_data['sig_points_acc'], np.full(len(model_data['sig_points_acc']), 40), '*', color='black')\n",
    "        ax_acc.plot(x, model_data['acc'][2], '',  linewidth=4, color='blue', label=\"Model\")\n",
    "        ax_acc.plot(x, model_data['acc'][0],  linewidth=3, color='blue')\n",
    "        ax_acc.plot(x, model_data['acc'][1],  linewidth=3, color='blue')\n",
    "        ax_acc.fill_between(x, model_data['acc'][0], model_data['acc'][1],  linewidth=5, color='blue', alpha=0.25)\n",
    "        ax_acc.plot(x, model_data['accsin'][2], '',  linewidth=4, color='orange', label=\"SINDy\")\n",
    "        ax_acc.plot(x, model_data['accsin'][0],  linewidth=3, color='orange')\n",
    "        ax_acc.plot(x, model_data['accsin'][1],  linewidth=3, color='orange')\n",
    "        ax_acc.fill_between(x, model_data['accsin'][0], model_data['accsin'][1],  linewidth=5, color='orange', alpha=0.25)\n",
    "        ax_acc.set_title(letter, fontsize=48,fontweight='bold' )\n",
    "        ax_acc.title.set_position([-.15, 1.05]) \n",
    "\n",
    "        # Response Time Plot\n",
    "        ax_time.plot(model_data['sig_points_time'], np.full(len(model_data['sig_points_acc']), 0), '*', color='black')\n",
    "        ax_time.plot(x, model_data['time'][2], '',  linewidth=4, color='blue')#, label=f\"{model_data['label']} Model Time\")\n",
    "        ax_time.plot(x, model_data['time'][0],  linewidth=3, color='blue')\n",
    "        ax_time.plot(x, model_data['time'][1],  linewidth=3, color='blue')\n",
    "        ax_time.fill_between(x, model_data['time'][0], model_data['time'][1],  linewidth=5, color='blue', alpha=0.25)\n",
    "        ax_time.plot(x, model_data['timesin'][2], '',  linewidth=4, color='orange', label=f\"{model_data['label']} SINDy Time\")\n",
    "        ax_time.plot(x, model_data['timesin'][0],  linewidth=3, color='orange')\n",
    "        ax_time.plot(x, model_data['timesin'][1],  linewidth=3, color='orange')\n",
    "        ax_time.fill_between(x, model_data['timesin'][0],model_data['timesin'][1],  linewidth=5, color='orange', alpha=0.25)\n",
    "        i+=1\n",
    "    # Apply legend with label prefix to distinguish model groups\n",
    "    if label_prefix==\"DDM\":\n",
    "        ax_acc.legend( loc='best', fontsize=24)\n",
    "#     ax_time.legend(loc='best', fontsize=24)\n",
    "\n",
    "# Group data by model type\n",
    "ddm_models = [data for data in data_sets if 'DDM' in data['label'] and 'LCA' not in data['label']]\n",
    "lca_ddm_models = [data for data in data_sets if 'LCA-DDM' in data['label']]\n",
    "lca_models = [data for data in data_sets if 'LCA' in data['label'] and 'DDM' not in data['label']]\n",
    "nlb_models =[data for data in data_sets if 'NLB' in data['label']]\n",
    "\n",
    "# Plot data for each model group\n",
    "model_groups = [('DDM', ddm_models), ('LCA-DDM', lca_ddm_models), ('LCA', lca_models),('NLB',nlb_models)]\n",
    "letter=['A','B','C','D']\n",
    "for i, (label_prefix, model_group) in enumerate(model_groups):\n",
    "    ax_acc = fig.add_subplot(gs[i, 0])\n",
    "    ax_time = fig.add_subplot(gs[i, 1])\n",
    "    plot_for_model_group(ax_acc, ax_time, model_group, model_group[0]['x'], label_prefix,letter[i])\n",
    "\n",
    "    # Styling for each subplot, maintaining properties from the original code\n",
    "    for ax in [ax_acc, ax_time]:\n",
    "        sns.despine(ax=ax)\n",
    "        ax.spines['left'].set_linewidth(7)\n",
    "        ax.spines['bottom'].set_linewidth(7)\n",
    "\n",
    "\n",
    "# ax0.set_xlabel('Time (a.u.)')\n",
    "# ax1.supylabel('Choice accuracy (%)')\n",
    "# ax2.supylabel('Normalised decision time')\n",
    "fig.text(.85, .85, 'DDM', ha='center', va='center',zorder=50)\n",
    "fig.text(.85, .65, 'LCA-DDM', ha='center', va='center',zorder=50)\n",
    "fig.text(.85, .45, 'LCA', ha='center', va='center',zorder=50)\n",
    "fig.text(.85, .25, 'NLB', ha='center', va='center',zorder=50)\n",
    "fig.text(0.505, 0.525, 'Normalised decision time (a.u.)', ha='center', va='center', rotation='vertical',zorder=50)\n",
    "fig.text(0.045, 0.525, 'Choice accuracy (%)', ha='center', va='center', rotation='vertical',zorder=50)\n",
    "fig.text(0.49,0.08,'Signal-to-noise ratio', ha='center', va='center',zorder=50)\n",
    "# fig.supxlabel('Signal-tnoise ratio')        \n",
    "plt.tight_layout()\n",
    "#plt.savefig(\"fig_average_choice_behaviour_29_04.pdf\", dpi=600,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbebe347",
   "metadata": {},
   "source": [
    "# Figure 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b062c7f5",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "##Fig 4. average trial activity figure\n",
    "\n",
    "\n",
    "sns.set_style('white') # darkgrid, white grid, dark, white and ticks\n",
    "plt.rc('axes', titlesize=36)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=36)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=42)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=42)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=24)    # legend fontsize\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.sans-serif'] = 'Arial'\n",
    "plt.rc('font', size=40) \n",
    "\n",
    "# Define your sample indices\n",
    "ddm_samples=[0,9,17,26]\n",
    "lcaddm_samples=[0,3,5,8]\n",
    "lca_samples=[0,2,5,7]\n",
    "nlb_samples=[0,6,12,18]\n",
    "\n",
    "samples = [ddm_samples, lcaddm_samples, lca_samples, nlb_samples]\n",
    "sample_titles=[\"Zero\",\"Low\",\"Medium\",\"High\"]\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(nrows=4, ncols=len(samples), figsize=(30, 25))\n",
    "\n",
    "# Titles for each model for clarity in the plots\n",
    "model_titles = ['DDM','LCA-DDM', 'LCA','NLB']\n",
    "\n",
    "model_axis = ['$X$','$y_1$, $y_2$', '$y_1$, $y_2$','$X_1$']\n",
    "# for model_index, model_data in enumerate([ave_ddm_nt,ave_lcaddm_nt, ave_lca_nt,ave_nt_nlb]):\n",
    "for model_index, model_data in enumerate([ave_ddm,ave_lcaddm, ave_lca,ave_nlb]):\n",
    "    for sample_index, sample in enumerate(samples[model_index]):\n",
    "        # Access the specific subplot for the current model and sample\n",
    "        ax = axs[model_index, sample_index] if len(samples[model_index]) > 1 else axs[model_index]\n",
    "        \n",
    "        # Fetch the data for this model and sample\n",
    "\n",
    "        if model_titles[model_index]=='LCA':\n",
    "            time_t=np.arange(0,10000,.01)\n",
    "            ave_act = average_activity_multidimensional(model_data[sample][5], trial_threshold=50)\n",
    "            ave_sin = average_activity_multidimensional(model_data[sample][6], trial_threshold=50)\n",
    "        elif model_titles[model_index]=='LCA-DDM':\n",
    "            time_t=np.arange(0,10000,.01)\n",
    "            ave_act = average_activity_multidimensional(model_data[sample][5], trial_threshold=24)\n",
    "            ave_sin = average_activity_multidimensional(model_data[sample][6], trial_threshold=24)\n",
    "        elif model_titles[model_index]==\"DDM\":\n",
    "            time_t=np.arange(0,10000,.1)\n",
    "            ave_act = average_activity(model_data[sample][5], trial_threshold=50)\n",
    "            ave_sin = average_activity(model_data[sample][6], trial_threshold=50)\n",
    "        elif model_titles[model_index]==\"NLB\":\n",
    "            time_t=np.arange(0,10000,.01)\n",
    "            ave_act = average_activity(model_data[sample][5], trial_threshold=10)\n",
    "            ave_sin = average_activity(model_data[sample][6], trial_threshold=10)\n",
    "        \n",
    "        # Plot the data for this model and sample\n",
    "        if model_titles[model_index]=='LCA-DDM' or model_titles[model_index]=='LCA':  # Check if data is not empty\n",
    "#             ax.plot(ave_lca_act[0], ave_lca_act[1], label='Population 1')\n",
    "              ax.plot(time_t[0:len(ave_act[0])],ave_act[0],color=\"blue\",linewidth=3, label=model_titles[model_index])\n",
    "              ax.plot(time_t[0:len(ave_act[1])],ave_act[1],color=\"blue\",alpha=.5,linewidth=5)\n",
    "              ax.plot(time_t[0:len(ave_sin[0])],ave_sin[0],color=\"orange\",linewidth=3, label='SINDy')\n",
    "              ax.plot(time_t[0:len(ave_sin[1])],ave_sin[1],color=\"orange\",alpha=.5,linewidth=5)\n",
    "\n",
    "              ax.set_ylim(-1,1)\n",
    "              ax.axhline(y=1, linestyle='dashed', linewidth=5, color='black', label='Threshold')\n",
    "#             ax.plot(ave_lca_act_sin[0], ave_lca_act_sin[1], linestyle=\"dashed\", label='Population 2')\n",
    "        else: \n",
    "            if model_titles[model_index]=='NLB':\n",
    "              ax.plot(time_t[0:len(ave_act)],ave_act,color=\"blue\",linewidth=5,label=model_titles[model_index])\n",
    "              ax.plot(time_t[0:len(ave_sin)],ave_sin,color=\"orange\",linewidth=5, label='SINDy')                    \n",
    "              ax.axhline(y=.75, linestyle='dashed', linewidth=5, color='black', label='Threshold')\n",
    "              ax.axhline(y=-.75, linestyle='dashed', linewidth=5, color='black', label='')\n",
    "              ax.set_ylim(-.85,.75)\n",
    "              #ax.set_xlim(0,2200)\n",
    "\n",
    "            else:\n",
    "#               ave_sin_threshold=np.where(ave_sin>1)\n",
    "#               ave_sin=ave_sin[0:ave_sin_threshold-1]\n",
    "              ax.plot(time_t[0:len(ave_act)],ave_act,color=\"blue\",linewidth=5,label=\"Model\")\n",
    "              ax.plot(time_t[0:len(ave_sin)],ave_sin,color=\"orange\",linewidth=5, label='SINDy')\n",
    "              ax.axhline(y=1, linestyle='dashed', linewidth=5, color='black', label='Threshold')\n",
    "              ax.axhline(y=-1, linestyle='dashed', linewidth=5, color='black', label='')\n",
    "              ax.set_ylim(-1.1,1)\n",
    "              #ax.set_xlim(0,1500)\n",
    "        \n",
    "        # Only add a legend to the first subplot for cleanliness\n",
    "        if sample_index == 0 and model_index==0:\n",
    "            ax.legend(loc='best', fontsize=30)\n",
    "\n",
    "        # Set title for the first row of subplots\n",
    "        if model_index == 0:\n",
    "            ax.set_title(f'{sample_titles[sample_index]}')\n",
    "            if sample_titles[sample_index]==\"Medium\" or sample_titles[sample_index]==\"High\" :\n",
    "                ax.set_xlim(-.85,75)\n",
    "\n",
    "        \n",
    "        # Labeling the rows with the model names\n",
    "        if sample_index == 0:\n",
    "            ax.set_ylabel(model_axis[model_index])\n",
    "            \n",
    "        sns.despine(ax=ax)\n",
    "        sns.despine(ax=ax)\n",
    "        ax.spines['left'].set_linewidth(7)\n",
    "        ax.spines['bottom'].set_linewidth(7)\n",
    "\n",
    "fig.text(.025, .95, 'A', ha='center', va='center',zorder=50,fontsize=48,fontweight='bold' )\n",
    "fig.text(.025, .71, 'B', ha='center', va='center',zorder=50,fontsize=48,fontweight='bold' )\n",
    "fig.text(.025, .48, 'C', ha='center', va='center',zorder=50,fontsize=48,fontweight='bold' )\n",
    "fig.text(.025, .255, 'D', ha='center', va='center',zorder=50,fontsize=48,fontweight='bold' )\n",
    "fig.text(.85, .81, 'DDM', ha='center', va='center',zorder=50)\n",
    "fig.text(.86, .575, 'LCA-DDM', ha='center', va='center',zorder=50)\n",
    "fig.text(.85, .35, 'LCA', ha='center', va='center',zorder=50)\n",
    "fig.text(.85, .12, 'NLB', ha='center', va='center',zorder=50)\n",
    "# Adjust layout to prevent overlap and ensure clarity\n",
    "fig.text(0.0,0.525,'Decision Varaible', ha='center', va='center',rotation='vertical',fontsize=48,zorder=50)\n",
    "fig.supxlabel('Time (a.u.)',fontsize=48,)        \n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"fig_average_activity_02_05.pdf\", dpi=600,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0345203a",
   "metadata": {},
   "source": [
    "# Supplementary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e599b10",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "####supplementary figure data\n",
    "\n",
    "ddm_acc_poly=confidenceInterval(ave_ddm_poly1,1,10000)\n",
    "ddm_acc_poly=[np.array(ddm_acc_poly[i])*100 for i in range(len(ddm_acc_poly))]\n",
    "ddm_accsin_poly=confidenceInterval(ave_ddm_poly1,2,10000)\n",
    "ddm_accsin_poly=[np.array(ddm_accsin_poly[i])*100 for i in range(len(ddm_accsin_poly))]\n",
    "c_ddm_acc_poly,p_ddm_acc_poly,sig_points_acc_ddm_poly,effect_ave_ddm_poly=ks_statistical_analysis(ave_ddm_poly1,1,2,x_ddm)\n",
    "ddm_time_poly=confidenceInterval(ave_ddm_poly1,3,10000)\n",
    "ddm_time_poly=[np.array(ddm_time_poly[i]) for i in range(len(ddm_time_poly))]\n",
    "ddm_timesin_poly=confidenceInterval(ave_ddm_poly1,4,10000)\n",
    "ddm_timesin_poly=[np.array(ddm_timesin_poly[i]) for i in range(len(ddm_timesin_poly))]\n",
    "c_ddm_time_poly,p_ddm_time_poly,sig_points_time_ddm_poly,effect_ave_ddm_t_poly=ks_statistical_analysis(ave_ddm_poly1,3,4,x_ddm)\n",
    "\n",
    "ddm_acc_poly2=confidenceInterval(ave_ddm_poly2,1,10000)\n",
    "ddm_acc_poly2=[np.array(ddm_acc_poly2[i])*100 for i in range(len(ddm_acc_poly2))]\n",
    "ddm_accsin_poly2=confidenceInterval(ave_ddm_poly2,2,10000)\n",
    "ddm_accsin_poly2=[np.array(ddm_accsin_poly2[i])*100 for i in range(len(ddm_accsin_poly2))]\n",
    "c_ddm_acc_poly2,p_ddm_acc_poly2,sig_points_acc_ddm_poly2,effect_ave_ddm_poly2=ks_statistical_analysis(ave_ddm_poly2,1,2,x_ddm)\n",
    "ddm_time_poly2=confidenceInterval(ave_ddm_poly2,3,10000)\n",
    "ddm_time_poly2=[np.array(ddm_time_poly2[i]) for i in range(len(ddm_time_poly2))]\n",
    "ddm_timesin_poly2=confidenceInterval(ave_ddm_poly2,3,10000)\n",
    "ddm_timesin_poly2=[np.array(ddm_timesin_poly2[i]) for i in range(len(ddm_timesin_poly2))]\n",
    "c_ddm_time_poly2,p_ddm_time_poly2,sig_points_time_ddm_poly2,effect_ave_ddm_t_poly2=ks_statistical_analysis(ave_ddm_poly2,3,4,x_ddm)\n",
    "\n",
    "lcaddm_acc_poly=confidenceInterval(ave_lcaddm_poly0,1,10000)\n",
    "lcaddm_acc_poly=[np.array(lcaddm_acc_poly[i])*100 for i in range(len(lcaddm_acc_poly))]\n",
    "lcaddm_accsin_poly=confidenceInterval(ave_lcaddm_poly0,2,10000)\n",
    "lcaddm_accsin_poly=[np.array(lcaddm_accsin_poly[i])*100 for i in range(len(lcaddm_accsin_poly))]\n",
    "c_lcaddm_acc_poly,p_lcaddm_acc_poly,sig_points_acc_lcaddm_poly,effect_ave_lcaddm_poly=ks_statistical_analysis(ave_lcaddm_poly0,1,2,x_lcaddm)\n",
    "lcaddm_time_poly=confidenceInterval(ave_lcaddm_poly0,3,10000)\n",
    "lcaddm_time_poly=[np.array(lcaddm_time_poly[i]) for i in range(len(lcaddm_time_poly))]\n",
    "lcaddm_timesin_poly=confidenceInterval(ave_lcaddm_poly0,4,10000)\n",
    "lcaddm_timesin_poly=[np.array(lcaddm_timesin_poly[i]) for i in range(len(lcaddm_timesin_poly))]\n",
    "c_lcaddm_time_poly,p_lcaddm_time_poly,sig_points_time_lcaddm_poly,effect_ave_lcaddm_t_poly=ks_statistical_analysis(ave_lcaddm_poly0,3,4,x_lcaddm)\n",
    "\n",
    "lcaddm_acc_poly2=confidenceInterval(ave_lcaddm_poly2,1,10000)\n",
    "lcaddm_acc_poly2=[np.array(lcaddm_acc_poly2[i])*100 for i in range(len(lcaddm_acc_poly2))]\n",
    "lcaddm_accsin_poly2=confidenceInterval(ave_lcaddm_poly2,2,10000)\n",
    "lcaddm_accsin_poly2=[np.array(lcaddm_accsin_poly2[i])*100 for i in range(len(lcaddm_accsin_poly2))]\n",
    "c_lcaddm_acc_poly2,p_lcaddm_acc_poly2,sig_points_acc_lcaddm_poly2,effect_ave_lcaddm_poly2=ks_statistical_analysis(ave_lcaddm_poly2,1,2,x_lcaddm)\n",
    "lcaddm_time_poly2=confidenceInterval(ave_lcaddm_poly2,3,10000)\n",
    "lcaddm_time_poly2=[np.array(lcaddm_time_poly2[i]) for i in range(len(lcaddm_time_poly2))]\n",
    "lcaddm_timesin_poly2=confidenceInterval(ave_lcaddm_poly2,4,10000)\n",
    "lcaddm_timesin_poly2=[np.array(lcaddm_timesin_poly2[i]) for i in range(len(lcaddm_timesin_poly2))]\n",
    "c_lcaddm_time_poly2,p_lcaddm_time_poly2,sig_points_time_lcaddm_poly2,effect_ave_lcaddm_t_poly2=ks_statistical_analysis(ave_lcaddm_poly2,3,4,x_lcaddm)\n",
    "\n",
    "lca_acc_poly=confidenceInterval(ave_lca_poly0,1,10000)\n",
    "lca_acc_poly=[np.array(lca_acc_poly[i])*100 for i in range(len(lca_acc_poly))]\n",
    "lca_accsin_poly=confidenceInterval(ave_lca_poly0,2,10000)\n",
    "lca_accsin_poly=[np.array(lca_accsin_poly[i])*100 for i in range(len(lca_accsin_poly))]\n",
    "c_lca_acc_poly,p_lca_acc_poly,sig_points_acc_lca_poly,effect_ave_lca_poly=ks_statistical_analysis(ave_lca_poly0,1,2,x_lca)\n",
    "lca_time_poly=confidenceInterval(ave_lca_poly0,3,10000)\n",
    "lca_time_poly=[np.array(lca_time_poly[i]) for i in range(len(lca_time_poly))]\n",
    "lca_timesin_poly=confidenceInterval(ave_lca_poly0,4,10000)\n",
    "lca_timesin_poly=[np.array(lca_timesin_poly[i]) for i in range(len(lca_timesin_poly))]\n",
    "c_lca_time_poly,p_lca_time_poly,sig_points_time_lca_poly,effect_ave_lca_t_poly=ks_statistical_analysis(ave_lca_poly0,3,4,x_lca)\n",
    "\n",
    "lca_acc_poly2=confidenceInterval(ave_lca_poly2,1,10000)\n",
    "lca_acc_poly2=[np.array(lca_acc_poly2[i])*100 for i in range(len(lca_acc_poly2))]\n",
    "lca_accsin_poly2=confidenceInterval(ave_lca_poly2,2,10000)\n",
    "lca_accsin_poly2=[np.array(lca_accsin_poly2[i])*100 for i in range(len(lca_accsin_poly2))]\n",
    "c_lca_acc_poly2,p_lca_acc_poly2,sig_points_acc_lca_poly2,effect_ave_lca_poly2=ks_statistical_analysis(ave_lca_poly2,1,2,x_lca)\n",
    "lca_time_poly2=confidenceInterval(ave_lca_poly2,3,10000)\n",
    "lca_time_poly2=[np.array(lca_time_poly2[i])for i in range(len(lca_time_poly2))]\n",
    "lca_timesin_poly2=confidenceInterval(ave_lca_poly2,4,10000)\n",
    "lca_timesin_poly2=[np.array(lca_timesin_poly2[i]) for i in range(len(lca_timesin_poly2))]\n",
    "c_lca_time_poly2,p_lca_time_poly2,sig_points_time_lca_poly2,effect_ave_lca_t_poly2=ks_statistical_analysis(ave_lca_poly2,3,4,x_lca)\n",
    "\n",
    "nlb_acc_poly=confidenceInterval(ave_nlb_poly4,1,10000)\n",
    "nlb_acc_poly=[np.array(nlb_acc_poly[i])*100 for i in range(len(nlb_acc_poly))]\n",
    "nlb_accsin_poly=confidenceInterval(ave_nlb_poly4,2,10000)\n",
    "nlb_accsin_poly=[np.array(nlb_accsin_poly[i])*100 for i in range(len(nlb_accsin_poly))]\n",
    "c_nlb_acc_poly,p_nlb_acc_poly,sig_points_acc_nlb_poly,effect_ave_nlb_poly=ks_statistical_analysis(ave_nlb_poly4,1,2,x_nlb)\n",
    "nlb_time_poly=confidenceInterval(ave_nlb_poly4,3,10000)\n",
    "nlb_time_poly=[np.array(nlb_time_poly[i]) for i in range(len(nlb_time_poly))]\n",
    "nlb_timesin_poly=confidenceInterval(ave_nlb_poly4,4,10000)\n",
    "nlb_timesin_poly=[np.array(nlb_timesin_poly[i]) for i in range(len(nlb_timesin_poly))]\n",
    "c_nlb_time_poly,p_nlb_time_poly,sig_points_time_nlb_poly,effect_ave_nlb_t_poly=ks_statistical_analysis(ave_nlb_poly4,3,4,x_nlb)\n",
    "\n",
    "nlb_acc_poly6=confidenceInterval(ave_nlb_poly6,1,10000)\n",
    "nlb_acc_poly6=[np.array(nlb_acc_poly6[i])*100 for i in range(len(nlb_acc_poly6))]\n",
    "nlb_accsin_poly6=confidenceInterval(ave_nlb_poly6,2,10000)\n",
    "nlb_accsin_poly6=[np.array(nlb_accsin_poly6[i])*100 for i in range(len(nlb_accsin_poly6))]\n",
    "c_nlb_acc_poly6,p_nlb_acc_poly6,sig_points_acc_nlb_poly6,effect_ave_nlb_poly6=ks_statistical_analysis(ave_nlb_poly6,1,2,x_nlb)\n",
    "nlb_time_poly6=confidenceInterval(ave_nlb_poly6,3,10000)\n",
    "nlb_time_poly6=[np.array(nlb_time_poly6[i]) for i in range(len(nlb_time_poly6))]\n",
    "nlb_timesin_poly6=confidenceInterval(ave_nlb_poly6,4,10000)\n",
    "nlb_timesin_poly6=[np.array(nlb_timesin_poly6[i]) for i in range(len(nlb_timesin_poly6))]\n",
    "c_nlb_time_poly6,p_nlb_time_poly6,sig_points_time_nlb_poly6,effect_ave_nlb_t_poly6=ks_statistical_analysis(ave_nlb_poly6,3,4,x_nlb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a113806",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#fig supp#\n",
    "sns.set(font_scale=4)\n",
    "sns.set_style('white') # darkgrid, white grid, dark, white and ticks\n",
    "plt.rc('axes', titlesize=36)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=48)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=48)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=48)    # fontsize of the tick labels\n",
    "#plt.rc('legend', fontsize=16)    # legend fontsize\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.sans-serif'] = 'Arial'\n",
    "plt.rc('font', size=48)          # controls default text sizes\n",
    "data_sets1 = [\n",
    "{'label':'DDM Poly 1','x': x_ddm,'acc': ddm_acc_poly,'accsin': ddm_accsin_poly,'time': ddm_time_poly,'timesin': ddm_timesin_poly,'sig_points_acc': sig_points_acc_ddm_poly,'sig_points_time': sig_points_time_ddm_poly,'effect_ave_acc': effect_ave_ddm_poly,'effect_ave_time': effect_ave_ddm_t_poly},\n",
    "{'label':'DDM Poly 2','x': x_ddm,'acc': ddm_acc_poly2,'accsin': ddm_accsin_poly2,'time': ddm_time_poly2,'timesin': ddm_timesin_poly2,'sig_points_acc': sig_points_acc_ddm_poly2,'sig_points_time': sig_points_time_ddm_poly2,'effect_ave_acc': effect_ave_ddm_poly2,'effect_ave_time': effect_ave_ddm_t_poly2},\n",
    "{'label':'LCA-DDM Poly 0', 'x': x_lcaddm,'acc': lcaddm_acc_poly,'accsin': lcaddm_accsin_poly,'time': lcaddm_time_poly,'timesin': lcaddm_timesin_poly,'sig_points_acc': sig_points_acc_lcaddm_poly,'sig_points_time': sig_points_time_lcaddm_poly,'effect_ave_acc': effect_ave_lcaddm_poly,'effect_ave_time': effect_ave_lcaddm_t_poly},\n",
    "{'label':'LCA-DDM Poly 2 ', 'x': x_lcaddm,'acc': lcaddm_acc_poly2,'accsin': lcaddm_accsin_poly2,'time': lcaddm_time_poly2,'timesin': lcaddm_timesin_poly2,'sig_points_acc': sig_points_acc_lcaddm_poly2,'sig_points_time': sig_points_time_lcaddm_poly2,'effect_ave_acc': effect_ave_lcaddm_poly2,'effect_ave_time': effect_ave_lcaddm_t_poly2},\n",
    "{'label':'LCA Poly 0', 'x': x_lca,'acc': lca_acc_poly,'accsin': lca_accsin_poly,'time': lca_time_poly,'timesin': lca_timesin_poly,'sig_points_acc': sig_points_acc_lca_poly,'sig_points_time': sig_points_time_lca_poly,'effect_ave_acc': effect_ave_lca_poly,'effect_ave_time': effect_ave_lca_t_poly},\n",
    "{'label':'LCA Poly 0', 'x': x_lca,'acc': lca_acc_poly2,'accsin': lca_accsin_poly2,'time': lca_time_poly2,'timesin': lca_timesin_poly2,'sig_points_acc': sig_points_acc_lca_poly2,'sig_points_time': sig_points_time_lca_poly2,'effect_ave_acc': effect_ave_lca_poly2,'effect_ave_time': effect_ave_lca_t_poly2},\n",
    "{'label':'NLB Poly 4','x': x_nlb,'acc': nlb_acc_poly,'accsin': nlb_accsin_poly,'time': nlb_time_poly,'timesin': nlb_timesin_poly,'sig_points_acc': sig_points_acc_nlb_poly,'sig_points_time': sig_points_time_nlb_poly,'effect_ave_acc': effect_ave_nlb_poly,'effect_ave_time': effect_ave_nlb_t_poly},\n",
    "{'label':'NLB Poly 6','x': x_nlb,'acc': nlb_acc_poly6,'accsin': nlb_accsin_poly6,'time': nlb_time_poly6,'timesin': nlb_timesin_poly6,'sig_points_acc': sig_points_acc_nlb_poly6,'sig_points_time': sig_points_time_nlb_poly6,'effect_ave_acc': effect_ave_nlb_poly6,'effect_ave_time': effect_ave_nlb_t_poly6}] \n",
    "\n",
    "# Define your figure and gridspec\n",
    "fig = plt.figure(figsize=(35, 35))  # Adjust the figure size as needed\n",
    "gs = gridspec.GridSpec(8, 2, wspace=0.15,hspace=.65)  # 6 rows, 2 columns\n",
    "\n",
    "# Assuming data_sets1 is defined as provided\n",
    "for row, model_data in enumerate(data_sets1):  # Iterate over each dataset in data_sets1\n",
    "    # Accessing data for the current model\n",
    "    x = model_data['x']\n",
    "    acc = model_data['acc']\n",
    "    accsin = model_data['accsin']\n",
    "    time = model_data['time']\n",
    "    timesin = model_data['timesin']\n",
    "    sig_points_acc = model_data['sig_points_acc']\n",
    "    effect_st_acc = model_data['effect_ave_acc']\n",
    "    sig_points_time = model_data['sig_points_time']\n",
    "    effect_st_time = model_data['effect_ave_time']\n",
    "    label = model_data['label']\n",
    "\n",
    "    # Second plot: Accuracy Plot\n",
    "    ax1 = fig.add_subplot(gs[row, 0])\n",
    "    # Plotting accuracy data\n",
    "    #ax1.plot(sig_points_acc, np.full(len(sig_points_acc), 40), '*', color='black')\n",
    "    ax1.plot(x, acc[2], '', color='blue', label=\"Model\", linewidth=4)\n",
    "    ax1.plot(x, acc[0], color='blue', linewidth=3)\n",
    "    ax1.plot(x, acc[1], color='blue', linewidth=3)\n",
    "    ax1.fill_between(x, acc[0], acc[1], color='blue', alpha=0.25)\n",
    "    ax1.plot(x, accsin[2], '', color='orange', label=\"SINDy\", linewidth=4)\n",
    "    ax1.plot(x, accsin[0], color='orange', linewidth=3)\n",
    "    ax1.plot(x, accsin[1], color='orange', linewidth=3)\n",
    "    ax1.fill_between(x, accsin[0], accsin[1], color='orange', alpha=0.25)\n",
    "    \n",
    "    # Third plot: Response Time Plot\n",
    "    ax2 = fig.add_subplot(gs[row, 1])\n",
    "    # Plotting response time data\n",
    "    #ax2.plot(sig_points_time, np.full(len(sig_points_time), 0), '*', color='black')\n",
    "    ax2.plot(x, time[2], '', color='blue', label=\"Model Response Time\", linewidth=4)\n",
    "    ax2.plot(x, time[0], color='blue', linewidth=3)\n",
    "    ax2.plot(x, time[1], color='blue', linewidth=3)\n",
    "    ax2.fill_between(x, time[0], time[1], color='blue', alpha=0.25)\n",
    "    ax2.plot(x, timesin[2], '', color='orange', label=\"SINDy Response Time\", linewidth=4)\n",
    "    ax2.plot(x, timesin[0], color='orange', linewidth=3)\n",
    "    ax2.plot(x, timesin[1], color='orange', linewidth=3)\n",
    "    ax2.fill_between(x, timesin[0], timesin[1], color='orange', alpha=0.25)\n",
    "\n",
    "    # Apply styles\n",
    "    sns.despine(ax=ax1)\n",
    "    sns.despine(ax=ax2)\n",
    "    ax1.spines['left'].set_linewidth(7)\n",
    "    ax1.spines['bottom'].set_linewidth(7)\n",
    "    ax2.spines['left'].set_linewidth(7)\n",
    "    ax2.spines['bottom'].set_linewidth(7)\n",
    "    \n",
    "    if row == 0:\n",
    "#         ax1.legend(loc='best', fontsize=14)\n",
    "        ax1.legend(loc=[0.5,1], fontsize=26)\n",
    "\n",
    "# Add labels\n",
    "fig.text(0.5, 0.1, 'Signal-to-noise ratio', ha='center', va='center')\n",
    "fig.text(0.084, 0.5, 'Choice accuracy (%)', ha='center', va='center', rotation='vertical')\n",
    "fig.text(0.5, 0.5, 'Decision time (a.u.)', ha='center', va='center', rotation='vertical')\n",
    "\n",
    "# Add labels for the models\n",
    "fig.text(.875, .85, 'DDM Poly 1', ha='center', va='center', zorder=50)\n",
    "fig.text(.875, .755, 'DDM Poly 2 ', ha='center', va='center', zorder=50)\n",
    "fig.text(.875, .665, 'LCA-DDM Poly 0 ', ha='center', va='center', zorder=50)\n",
    "fig.text(.875, .575, 'LCA-DDM Poly 2 ', ha='center', va='center', zorder=50)\n",
    "fig.text(.875, .465, 'LCA Poly 0', ha='center', va='center', zorder=50)\n",
    "fig.text(.875, .351, 'LCA Poly 2', ha='center', va='center', zorder=50)\n",
    "fig.text(.875, .256, 'NLB Poly 4', ha='center', va='center', zorder=50)\n",
    "fig.text(.875, .156, 'NLB Poly 6', ha='center', va='center', zorder=50)\n",
    "# plt.savefig(\"fig_supp_choice_behaviour.tiff\", dpi=600,bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
